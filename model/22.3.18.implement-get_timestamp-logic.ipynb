{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import GRU, Dense, Dropout, Input, concatenate\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import Adam\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# variable\n",
    "words = [\n",
    "    'come quickly', 'emergency', 'father', 'fever', 'good luck',\n",
    "    'headache', 'hello', 'help', 'hi', 'hungry',\n",
    "    'like', 'mother', 'mother_father', 'mother_mother', 'not ok',\n",
    "    'quickly', 'sorry', 'tomorrow', 'yogurt'\n",
    "]\n",
    "data_per_word = 27\n",
    "data_length = 2 * data_per_word * len(words)\n",
    "timesteps = 50\n",
    "dimensions = 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_feature(frame):\n",
    "    finger_name = ['thumb', 'index', 'middle', 'ring', 'pinky']\n",
    "#     coordinate = ['x', 'y', 'z']\n",
    "    fingertip_pos = np.zeros([2, 5, 3]) # [cooridinates x fingers]\n",
    "    feature = np.zeros([22])\n",
    "    hand_pos = np.zeros([12])\n",
    "#     finger_tip = {}\n",
    "    if 'right' in frame['hands']:\n",
    "        hand_pos[0:6] = np.array([frame['hands']['right']['hand_palm_position'][0],\n",
    "                                  frame['hands']['right']['hand_palm_position'][1],\n",
    "                                  frame['hands']['right']['hand_palm_position'][2],\n",
    "                                  frame['hands']['right']['yaw'], \n",
    "                                  frame['hands']['right']['roll'], \n",
    "                                  frame['hands']['right']['pitch']])\n",
    "        for idx, finger in enumerate(finger_name):\n",
    "#             fingertip_pos[2 + idx, :] = np.array(frame['hands']['right']['fingers'][finger]['bones']['distal']['next_joint'])\n",
    "            fingertip_pos[0, idx, :] = np.array(frame['hands']['right']['fingers'][finger]['bones']['distal']['next_joint'])\n",
    "    if 'left' in frame['hands']:\n",
    "        hand_pos[6:12] = np.array([frame['hands']['left']['hand_palm_position'][0],\n",
    "                                   frame['hands']['left']['hand_palm_position'][1],\n",
    "                                   frame['hands']['left']['hand_palm_position'][2],\n",
    "                                   frame['hands']['left']['yaw'], \n",
    "                                   frame['hands']['left']['roll'], \n",
    "                                   frame['hands']['left']['pitch']])\n",
    "#         fingertip_pos[8, :] = np.array(frame['hands']['left']['hand_palm_position'])\n",
    "        for idx, finger in enumerate(finger_name):\n",
    "#             fingertip_pos[4 + 5 + idx, :] = np.array(frame['hands']['left']['fingers'][finger]['bones']['distal']['next_joint'])\n",
    "            fingertip_pos[1, idx, :] = np.array(frame['hands']['left']['fingers'][finger]['bones']['distal']['next_joint'])\n",
    "    fingertip_pos_shift = np.roll(fingertip_pos, 1, axis=1)\n",
    "    feature[0:10] = np.linalg.norm(fingertip_pos - fingertip_pos_shift, axis=2).reshape(10)\n",
    "    feature[10:22] = hand_pos\n",
    "\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_timestep_from_data(json_data, pick_frame_every_no):\n",
    "    timestep = np.zeros([0, dimensions])\n",
    "    curr_idx = 0\n",
    "    \n",
    "    for frame_no, frame in enumerate(json_data):\n",
    "        if frame_no % pick_frame_every_no != 0 or not frame['hands']: #check if frame[hands] is null\n",
    "            continue\n",
    "        feature = get_feature(frame)\n",
    "#             for idx, fingertip_pos in enumerate(fingertips_pos):\n",
    "        timestep = np.vstack((timestep, feature))\n",
    "        curr_idx += 1\n",
    "        \n",
    "    return timestep\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_timesteps(json_data, pick_frame_every_no): \n",
    "    timesteps = np.zeros([0, dimensions])\n",
    "    for frame_no, frame in enumerate(json_data):\n",
    "        if frame_no % pick_frame_every_no != 0 or not frame['hands']:\n",
    "            continue\n",
    "        feature = get_feature(frame)\n",
    "        timesteps = np.vstack((timesteps, feature))\n",
    "    return timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_fake_speedup_timesteps_1(percent, json_data, pick_frame_every_no):\n",
    "    return get_timesteps(json_data, pick_frame_every_no*(percent - 100)//100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_augmentation(percent, old_timesteps, old_pick_frame_every_no):\n",
    "    timesteps = np.zeros([0, dimensions])\n",
    "    pick_frame_every_no = old_pick_frame_every_no*(100+percent)//100\n",
    "    timesteps_length = (old_timesteps.shape[0] * old_pick_frame_every_no) // pick_frame_every_no\n",
    "    \n",
    "    for new_index in range(1, timesteps_length):\n",
    "        start_old_index = (new_index * pick_frame_every_no) // old_pick_frame_every_no\n",
    "        x1 = old_pick_frame_every_no*start_old_index\n",
    "        x2 = old_pick_frame_every_no*(start_old_index + 1)\n",
    "        h1, h2 = old_timesteps[start_old_index : start_old_index + 2]\n",
    "        _x = (new_index * pick_frame_every_no)\n",
    "        \n",
    "        feature = ((_x-x1)/(x2-x1))*(h2-h1) + h1\n",
    "        \n",
    "        timesteps = np.vstack((timesteps, feature))\n",
    "        \n",
    "    return timesteps\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_frame = 0\n",
    "for word_no, word in enumerate(words):\n",
    "    for data_no in range(data_per_word):\n",
    "        try:\n",
    "            with open(\"./record/{}/json_{}.txt\".format(word, data_no)) as json_data:\n",
    "                json_data = json.load(json_data)\n",
    "        except Exception as s:\n",
    "            print ('error log:', s)\n",
    "        \n",
    "        if max_frame < len(json_data):\n",
    "            max_frame = len(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pick_frame_every_no = max_frame // 50 + 1\n",
    "pick_frame_every_no = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "negative dimensions are not allowed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-4b9382cb1312>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0m_timesteps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_fake_speedup_timesteps_1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpick_frame_every_no\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0m__timesteps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_timesteps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtimesteps\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0m_timesteps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdimensions\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m__timesteps\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword_no\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: negative dimensions are not allowed"
     ]
    }
   ],
   "source": [
    "x = np.zeros([0, timesteps, dimensions])\n",
    "y = np.zeros([0])\n",
    "for word_no, word in enumerate(words):\n",
    "    for data_no in range(data_per_word):\n",
    "        try:\n",
    "            with open(\"./record/{}/json_{}.txt\".format(word, data_no)) as json_data:\n",
    "                json_data = json.load(json_data)\n",
    "        except Exception as s:\n",
    "            print ('error log:', s)\n",
    "        \n",
    "        _timesteps = get_timesteps(json_data, pick_frame_every_no)\n",
    "        __timesteps = np.vstack((_timesteps, np.zeros([timesteps - _timesteps.shape[0], dimensions])))\n",
    "        x = np.vstack((x, [__timesteps]))\n",
    "        y = np.append(y, word_no)\n",
    "        \n",
    "        _timesteps = get_fake_speedup_timesteps_1(+10, json_data, pick_frame_every_no)\n",
    "        __timesteps = np.vstack((_timesteps, np.zeros([timesteps - _timesteps.shape[0], dimensions])))\n",
    "        x = np.vstack((x, [__timesteps]))\n",
    "        y = np.append(y, word_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_std = x.std(axis=(0,1), keepdims=True)\n",
    "x_mean = x.mean(axis=(0,1), keepdims=True)\n",
    "x_norm = (x-x_mean)/x_std\n",
    "# x_norm = (x-x_min)/(x_max-x_min)\n",
    "# x_norm = 2*(x-(x_max+x_min)/2)/(x_max-x_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = np.zeros([data_length * 2 // 3, timesteps, dimensions])\n",
    "y_train = np.zeros([data_length * 2 // 3])\n",
    "x_test = np.zeros([data_length // 3, timesteps, dimensions])\n",
    "y_test = np.zeros([data_length // 3])\n",
    "for idx in range(data_length):\n",
    "    if idx % 3 == 2:\n",
    "        x_test[idx // 3] = x_norm[idx]\n",
    "        y_test[idx // 3] = y[idx]\n",
    "    else:\n",
    "        x_train[idx - idx // 3] = x_norm[idx]\n",
    "        y_train[idx - idx // 3] = y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shuffle_train = np.arange(len(x_train))\n",
    "np.random.shuffle(shuffle_train)\n",
    "x_train_shuffle = np.zeros([data_length * 2 // 3, timesteps, dimensions])\n",
    "y_train_shuffle = np.zeros([data_length * 2 // 3])\n",
    "for idx, item in enumerate(shuffle_train):\n",
    "    x_train_shuffle[idx] = x_train[item]\n",
    "    y_train_shuffle[idx] = y_train[item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# encoding label\n",
    "Y_train_shuffle = np_utils.to_categorical(y_train_shuffle, len(words))\n",
    "Y_test = np_utils.to_categorical(y_test, len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fingers = Input(shape=(timesteps, dimensions), name='fingers')\n",
    "fingers_layers = GRU(64, activation='tanh', recurrent_activation='hard_sigmoid', dropout=0.2, recurrent_dropout=0.2)(fingers)\n",
    "fingers_layers = Dense(64, activation='relu')(fingers_layers)\n",
    "fingers_layers = Dropout(0.2)(fingers_layers)\n",
    "fingers_layers = Dense(64, activation='relu')(fingers_layers)\n",
    "fingers_layers = Dropout(0.2)(fingers_layers)\n",
    "fingers_layers = Dense(64, activation='relu')(fingers_layers)\n",
    "fingers_layers = Dropout(0.2)(fingers_layers)\n",
    "output_layer = Dense(len(words), activation='softmax')(fingers_layers)\n",
    "model = Model(inputs=fingers, outputs=output_layer)\n",
    "adam = Adam(lr=0.01, decay=0.0005)\n",
    "model.compile(optimizer=adam,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(x_train_shuffle, Y_train_shuffle,validation_data=(x_test, Y_test), epochs=1000, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score, acc = model.evaluate(x_test, Y_test)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# list all data in history\n",
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
