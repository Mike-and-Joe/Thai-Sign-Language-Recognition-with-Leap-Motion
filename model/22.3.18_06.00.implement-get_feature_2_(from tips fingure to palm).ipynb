{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import GRU, Dense, Dropout, Input, concatenate\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import Adam\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# variable\n",
    "words = [\n",
    "    'come quickly', 'emergency', 'father', 'fever', 'good luck',\n",
    "    'headache', 'hello', 'help', 'hi', 'hungry',\n",
    "    'like', 'mother', 'mother_father', 'mother_mother', 'not ok',\n",
    "    'quickly', 'sorry', 'tomorrow', 'yogurt'\n",
    "]\n",
    "data_per_word = 27\n",
    "data_length = 2 * data_per_word * len(words)\n",
    "timesteps = 50\n",
    "dimensions = 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_feature(frame):\n",
    "    finger_name = ['thumb', 'index', 'middle', 'ring', 'pinky']\n",
    "#     coordinate = ['x', 'y', 'z']\n",
    "    fingertip_pos = np.zeros([2, 5, 3]) # [cooridinates x fingers]\n",
    "    feature = np.zeros([22])\n",
    "    hand_pos = np.zeros([12])\n",
    "#     finger_tip = {}\n",
    "    if 'right' in frame['hands']:\n",
    "        hand_pos[0:6] = np.array([frame['hands']['right']['hand_palm_position'][0],\n",
    "                                  frame['hands']['right']['hand_palm_position'][1],\n",
    "                                  frame['hands']['right']['hand_palm_position'][2],\n",
    "                                  frame['hands']['right']['yaw'], \n",
    "                                  frame['hands']['right']['roll'], \n",
    "                                  frame['hands']['right']['pitch']])\n",
    "        for idx, finger in enumerate(finger_name):\n",
    "#             fingertip_pos[2 + idx, :] = np.array(frame['hands']['right']['fingers'][finger]['bones']['distal']['next_joint'])\n",
    "            fingertip_pos[0, idx, :] = np.array(frame['hands']['right']['fingers'][finger]['bones']['distal']['next_joint'])\n",
    "    if 'left' in frame['hands']:\n",
    "        hand_pos[6:12] = np.array([frame['hands']['left']['hand_palm_position'][0],\n",
    "                                   frame['hands']['left']['hand_palm_position'][1],\n",
    "                                   frame['hands']['left']['hand_palm_position'][2],\n",
    "                                   frame['hands']['left']['yaw'], \n",
    "                                   frame['hands']['left']['roll'], \n",
    "                                   frame['hands']['left']['pitch']])\n",
    "#         fingertip_pos[8, :] = np.array(frame['hands']['left']['hand_palm_position'])\n",
    "        for idx, finger in enumerate(finger_name):\n",
    "#             fingertip_pos[4 + 5 + idx, :] = np.array(frame['hands']['left']['fingers'][finger]['bones']['distal']['next_joint'])\n",
    "            fingertip_pos[1, idx, :] = np.array(frame['hands']['left']['fingers'][finger]['bones']['distal']['next_joint'])\n",
    "    fingertip_pos_shift = np.roll(fingertip_pos, 1, axis=1)\n",
    "    feature[0:10] = np.linalg.norm(fingertip_pos - fingertip_pos_shift, axis=2).reshape(10)\n",
    "    feature[10:22] = hand_pos\n",
    "\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_euclid_dis_tips_and_palm_feature(frame):\n",
    "    finger_name = ['thumb', 'index', 'middle', 'ring', 'pinky']\n",
    "    hand_name = ['left', 'right']\n",
    "    \n",
    "    fingertip_pos = np.zeros([2, 5, 3])\n",
    "    \n",
    "    hand_palm_pos = np.zeros([2, 3])\n",
    "    hand_palm_rpy = np.zeros([2, 3])\n",
    "    dist_fingertip_palm = np.zeros([10])\n",
    "    \n",
    "    feature = np.zeros([2*3 + 2*3 + 10])\n",
    "    \n",
    "    for hand_idx, hand in enumerate(hand_name):\n",
    "        if not hand in frame['hands']:\n",
    "            continue\n",
    "        hand_palm_pos[hand_idx] = np.array(frame['hands'][hand]['hand_palm_position'])\n",
    "        hand_palm_rpy[hand_idx] = np.array([ frame['hands'][hand]['roll'],\n",
    "                                                    frame['hands'][hand]['pitch'],\n",
    "                                                    frame['hands'][hand]['yaw']])\n",
    "        for finger_idx, finger in enumerate(finger_name):\n",
    "            fingertip_pos[hand_idx, finger_idx] = (\n",
    "                np.array(frame['hands'][hand]['fingers'][finger]['bones']['distal']['next_joint'])\n",
    "            )\n",
    "            \n",
    "            dist_fingertip_palm[hand_idx*5 + finger_idx] = np.linalg.norm(\n",
    "                fingertip_pos[hand_idx, finger_idx] - hand_palm_pos[hand_idx]\n",
    "            )\n",
    "        \n",
    "    feature[0:6] = hand_palm_pos.reshape(6)\n",
    "    feature[6:12] = hand_palm_rpy.reshape(6)\n",
    "    feature[12:22] = dist_fingertip_palm.T\n",
    "    \n",
    "#     print(feature[12+5:12+6])\n",
    "#     print(frame['hands']['right']['fingers']['thumb']['bones']['distal']['next_joint'])\n",
    "#     print(hand_palm_pos[1])\n",
    "    return feature\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_timesteps(json_data, pick_frame_every_no): \n",
    "    timesteps = np.zeros([0, dimensions])\n",
    "    for frame_no, frame in enumerate(json_data):\n",
    "        if frame_no % pick_frame_every_no != 0 or not frame['hands']:\n",
    "            continue\n",
    "#         feature = get_feature(frame)\n",
    "        feature = get_euclid_dis_tips_and_palm_feature(frame)\n",
    "        timesteps = np.vstack((timesteps, feature))\n",
    "    return timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_fake_speedup_timesteps_1(percent, json_data, pick_frame_every_no):\n",
    "    return get_timesteps(json_data, pick_frame_every_no*(100+percent)//100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_fake_speedup_timesteps_2(percent, old_timesteps, old_pick_frame_every_no):\n",
    "    timesteps = np.zeros([0, dimensions])\n",
    "    pick_frame_every_no = old_pick_frame_every_no*(100+percent)//100\n",
    "    timesteps_length = (old_timesteps.shape[0] * old_pick_frame_every_no) // pick_frame_every_no\n",
    "    \n",
    "    for new_index in range(1, timesteps_length):\n",
    "        start_old_index = (new_index * pick_frame_every_no) // old_pick_frame_every_no\n",
    "        x1 = old_pick_frame_every_no*start_old_index\n",
    "        x2 = old_pick_frame_every_no*(start_old_index + 1)\n",
    "        h1, h2 = old_timesteps[start_old_index : start_old_index + 2]\n",
    "        _x = (new_index * pick_frame_every_no)\n",
    "        \n",
    "        feature = ((_x-x1)/(x2-x1))*(h2-h1) + h1\n",
    "        \n",
    "        timesteps = np.vstack((timesteps, feature))\n",
    "        \n",
    "    return timesteps\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_frame = 0\n",
    "for word_no, word in enumerate(words):\n",
    "    for data_no in range(data_per_word):\n",
    "        try:\n",
    "            with open(\"./record/{}/json_{}.txt\".format(word, data_no)) as json_data:\n",
    "                json_data = json.load(json_data)\n",
    "        except Exception as s:\n",
    "            print ('error log:', s)\n",
    "        \n",
    "        if max_frame < len(json_data):\n",
    "            max_frame = len(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "speedup = 10\n",
    "pick_frame_every_no = int((max_frame * (speedup < 0 and (100-speedup)/100 or 1)) // 50 + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.zeros([0, timesteps, dimensions])\n",
    "y = np.zeros([0])\n",
    "for word_no, word in enumerate(words):\n",
    "    for data_no in range(data_per_word):\n",
    "        try:\n",
    "            with open(\"./record/{}/json_{}.txt\".format(word, data_no)) as json_data:\n",
    "                json_data = json.load(json_data)\n",
    "        except Exception as s:\n",
    "            print ('error log:', s)\n",
    "        \n",
    "        _timesteps = get_timesteps(json_data, pick_frame_every_no)\n",
    "        __timesteps = np.vstack((_timesteps, np.zeros([timesteps - _timesteps.shape[0], dimensions])))\n",
    "        x = np.vstack((x, [__timesteps]))\n",
    "        y = np.append(y, word_no)\n",
    "        \n",
    "        _timesteps = get_fake_speedup_timesteps_2(+10, _timesteps, pick_frame_every_no)\n",
    "        __timesteps = np.vstack((_timesteps, np.zeros([timesteps - _timesteps.shape[0], dimensions])))\n",
    "        x = np.vstack((x, [__timesteps]))\n",
    "        y = np.append(y, word_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_std = x.std(axis=(0,1), keepdims=True)\n",
    "x_mean = x.mean(axis=(0,1), keepdims=True)\n",
    "x_norm = (x-x_mean)/x_std\n",
    "# x_norm = (x-x_min)/(x_max-x_min)\n",
    "# x_norm = 2*(x-(x_max+x_min)/2)/(x_max-x_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = np.zeros([data_length * 2 // 3, timesteps, dimensions])\n",
    "y_train = np.zeros([data_length * 2 // 3])\n",
    "x_test = np.zeros([data_length // 3, timesteps, dimensions])\n",
    "y_test = np.zeros([data_length // 3])\n",
    "for idx in range(data_length):\n",
    "    if idx % 3 == 2:\n",
    "        x_test[idx // 3] = x_norm[idx]\n",
    "        y_test[idx // 3] = y[idx]\n",
    "    else:\n",
    "        x_train[idx - idx // 3] = x_norm[idx]\n",
    "        y_train[idx - idx // 3] = y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shuffle_train = np.arange(len(x_train))\n",
    "np.random.shuffle(shuffle_train)\n",
    "x_train_shuffle = np.zeros([data_length * 2 // 3, timesteps, dimensions])\n",
    "y_train_shuffle = np.zeros([data_length * 2 // 3])\n",
    "for idx, item in enumerate(shuffle_train):\n",
    "    x_train_shuffle[idx] = x_train[item]\n",
    "    y_train_shuffle[idx] = y_train[item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# encoding label\n",
    "Y_train_shuffle = np_utils.to_categorical(y_train_shuffle, len(words))\n",
    "Y_test = np_utils.to_categorical(y_test, len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fingers = Input(shape=(timesteps, dimensions), name='fingers')\n",
    "fingers_layers = GRU(64, activation='tanh', recurrent_activation='hard_sigmoid', dropout=0.2, recurrent_dropout=0.2)(fingers)\n",
    "fingers_layers = Dense(64, activation='relu')(fingers_layers)\n",
    "fingers_layers = Dropout(0.2)(fingers_layers)\n",
    "fingers_layers = Dense(64, activation='relu')(fingers_layers)\n",
    "fingers_layers = Dropout(0.2)(fingers_layers)\n",
    "fingers_layers = Dense(64, activation='relu')(fingers_layers)\n",
    "fingers_layers = Dropout(0.2)(fingers_layers)\n",
    "output_layer = Dense(len(words), activation='softmax')(fingers_layers)\n",
    "model = Model(inputs=fingers, outputs=output_layer)\n",
    "adam = Adam(lr=0.01, decay=0.0005)\n",
    "model.compile(optimizer=adam,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 684 samples, validate on 342 samples\n",
      "Epoch 1/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 2.9750 - acc: 0.0351 - val_loss: 2.9466 - val_acc: 0.0526\n",
      "Epoch 2/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.9531 - acc: 0.0453 - val_loss: 2.9200 - val_acc: 0.0848\n",
      "Epoch 3/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.9176 - acc: 0.0599 - val_loss: 2.8508 - val_acc: 0.0848\n",
      "Epoch 4/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.8105 - acc: 0.0643 - val_loss: 2.6755 - val_acc: 0.1257\n",
      "Epoch 5/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.7626 - acc: 0.0746 - val_loss: 2.5874 - val_acc: 0.1082\n",
      "Epoch 6/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.7100 - acc: 0.0906 - val_loss: 2.5618 - val_acc: 0.1053\n",
      "Epoch 7/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.6849 - acc: 0.0906 - val_loss: 2.5156 - val_acc: 0.1228\n",
      "Epoch 8/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.6590 - acc: 0.1170 - val_loss: 2.4928 - val_acc: 0.1257\n",
      "Epoch 9/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.6440 - acc: 0.1023 - val_loss: 2.4575 - val_acc: 0.1404\n",
      "Epoch 10/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.6202 - acc: 0.1301 - val_loss: 2.4292 - val_acc: 0.2164\n",
      "Epoch 11/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.6405 - acc: 0.1184 - val_loss: 2.4266 - val_acc: 0.1696\n",
      "Epoch 12/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.7356 - acc: 0.1009 - val_loss: 2.6209 - val_acc: 0.1140\n",
      "Epoch 13/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.7195 - acc: 0.1243 - val_loss: 2.5596 - val_acc: 0.1287\n",
      "Epoch 14/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.6627 - acc: 0.1272 - val_loss: 2.4665 - val_acc: 0.1637\n",
      "Epoch 15/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.6470 - acc: 0.1111 - val_loss: 2.5855 - val_acc: 0.1140\n",
      "Epoch 16/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.5874 - acc: 0.1301 - val_loss: 2.4116 - val_acc: 0.1550\n",
      "Epoch 17/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.5686 - acc: 0.1287 - val_loss: 2.4384 - val_acc: 0.1696\n",
      "Epoch 18/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.5644 - acc: 0.1374 - val_loss: 2.3645 - val_acc: 0.1637\n",
      "Epoch 19/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.5485 - acc: 0.1272 - val_loss: 2.3286 - val_acc: 0.1754\n",
      "Epoch 20/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.5275 - acc: 0.1345 - val_loss: 2.3146 - val_acc: 0.2222\n",
      "Epoch 21/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.5107 - acc: 0.1608 - val_loss: 2.3322 - val_acc: 0.2164\n",
      "Epoch 22/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.4810 - acc: 0.1433 - val_loss: 2.3250 - val_acc: 0.2018\n",
      "Epoch 23/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.4659 - acc: 0.1637 - val_loss: 2.4541 - val_acc: 0.1696\n",
      "Epoch 24/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.5506 - acc: 0.1447 - val_loss: 2.4678 - val_acc: 0.1754\n",
      "Epoch 25/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.5864 - acc: 0.1330 - val_loss: 2.3993 - val_acc: 0.1959\n",
      "Epoch 26/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.5514 - acc: 0.1170 - val_loss: 2.4352 - val_acc: 0.1871\n",
      "Epoch 27/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.5601 - acc: 0.1360 - val_loss: 2.4731 - val_acc: 0.1579\n",
      "Epoch 28/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.5938 - acc: 0.1462 - val_loss: 2.4025 - val_acc: 0.1784\n",
      "Epoch 29/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.5465 - acc: 0.1330 - val_loss: 2.4104 - val_acc: 0.1667\n",
      "Epoch 30/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.5087 - acc: 0.1404 - val_loss: 2.3434 - val_acc: 0.1842\n",
      "Epoch 31/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.5177 - acc: 0.1550 - val_loss: 2.3900 - val_acc: 0.1754\n",
      "Epoch 32/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.4631 - acc: 0.1535 - val_loss: 2.3397 - val_acc: 0.1754\n",
      "Epoch 33/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.4934 - acc: 0.1404 - val_loss: 2.3037 - val_acc: 0.2076\n",
      "Epoch 34/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.4824 - acc: 0.1447 - val_loss: 2.3209 - val_acc: 0.1696\n",
      "Epoch 35/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 2.4704 - acc: 0.1506 - val_loss: 2.2727 - val_acc: 0.1842\n",
      "Epoch 36/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 2.4672 - acc: 0.1579 - val_loss: 2.2871 - val_acc: 0.2018\n",
      "Epoch 37/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.4891 - acc: 0.1404 - val_loss: 2.3058 - val_acc: 0.2368\n",
      "Epoch 38/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.4502 - acc: 0.1418 - val_loss: 2.2681 - val_acc: 0.2398\n",
      "Epoch 39/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.4333 - acc: 0.1711 - val_loss: 2.2663 - val_acc: 0.2047\n",
      "Epoch 40/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.4321 - acc: 0.1535 - val_loss: 2.2583 - val_acc: 0.2222\n",
      "Epoch 41/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.4221 - acc: 0.1681 - val_loss: 2.2684 - val_acc: 0.1784\n",
      "Epoch 42/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.4057 - acc: 0.1769 - val_loss: 2.2475 - val_acc: 0.2164\n",
      "Epoch 43/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.4251 - acc: 0.1506 - val_loss: 2.2377 - val_acc: 0.1988\n",
      "Epoch 44/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.4195 - acc: 0.1725 - val_loss: 2.2305 - val_acc: 0.2105\n",
      "Epoch 45/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.4710 - acc: 0.1696 - val_loss: 2.2667 - val_acc: 0.2164\n",
      "Epoch 46/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.4432 - acc: 0.1667 - val_loss: 2.2536 - val_acc: 0.2398\n",
      "Epoch 47/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.3893 - acc: 0.1769 - val_loss: 2.2281 - val_acc: 0.2456\n",
      "Epoch 48/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.3765 - acc: 0.1974 - val_loss: 2.2039 - val_acc: 0.2368\n",
      "Epoch 49/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.3592 - acc: 0.1769 - val_loss: 2.1894 - val_acc: 0.2251\n",
      "Epoch 50/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.3728 - acc: 0.1988 - val_loss: 2.1575 - val_acc: 0.2281\n",
      "Epoch 51/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.2795 - acc: 0.2047 - val_loss: 2.1266 - val_acc: 0.2544\n",
      "Epoch 52/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.3270 - acc: 0.1842 - val_loss: 2.1377 - val_acc: 0.2661\n",
      "Epoch 53/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.3268 - acc: 0.2105 - val_loss: 2.0909 - val_acc: 0.2719\n",
      "Epoch 54/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.3765 - acc: 0.1711 - val_loss: 2.1021 - val_acc: 0.2953\n",
      "Epoch 55/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.3520 - acc: 0.1959 - val_loss: 2.0952 - val_acc: 0.2544\n",
      "Epoch 56/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.3270 - acc: 0.1886 - val_loss: 2.0732 - val_acc: 0.2982\n",
      "Epoch 57/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.3076 - acc: 0.1784 - val_loss: 2.0642 - val_acc: 0.2661\n",
      "Epoch 58/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.2934 - acc: 0.2061 - val_loss: 2.0605 - val_acc: 0.2778\n",
      "Epoch 59/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.2694 - acc: 0.2091 - val_loss: 2.0503 - val_acc: 0.3041\n",
      "Epoch 60/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.2797 - acc: 0.2178 - val_loss: 2.0260 - val_acc: 0.3129\n",
      "Epoch 61/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 2s 3ms/step - loss: 2.2411 - acc: 0.2325 - val_loss: 2.0598 - val_acc: 0.2836\n",
      "Epoch 62/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.2439 - acc: 0.1944 - val_loss: 2.0222 - val_acc: 0.2865\n",
      "Epoch 63/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.2944 - acc: 0.2047 - val_loss: 2.0304 - val_acc: 0.2719\n",
      "Epoch 64/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.3304 - acc: 0.1915 - val_loss: 2.0232 - val_acc: 0.3041\n",
      "Epoch 65/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.2597 - acc: 0.2368 - val_loss: 2.0175 - val_acc: 0.3216\n",
      "Epoch 66/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.2409 - acc: 0.2105 - val_loss: 2.0229 - val_acc: 0.2719\n",
      "Epoch 67/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.2313 - acc: 0.2091 - val_loss: 1.9847 - val_acc: 0.3187\n",
      "Epoch 68/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.2663 - acc: 0.2105 - val_loss: 2.0254 - val_acc: 0.3012\n",
      "Epoch 69/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.2766 - acc: 0.2281 - val_loss: 2.0028 - val_acc: 0.3012\n",
      "Epoch 70/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.2745 - acc: 0.2295 - val_loss: 1.9901 - val_acc: 0.3421\n",
      "Epoch 71/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.2430 - acc: 0.2120 - val_loss: 1.9791 - val_acc: 0.3216\n",
      "Epoch 72/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.2371 - acc: 0.2178 - val_loss: 1.9665 - val_acc: 0.3129\n",
      "Epoch 73/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.2309 - acc: 0.2237 - val_loss: 1.9741 - val_acc: 0.3246\n",
      "Epoch 74/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.2355 - acc: 0.2003 - val_loss: 1.9532 - val_acc: 0.3158\n",
      "Epoch 75/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.2664 - acc: 0.2135 - val_loss: 1.9544 - val_acc: 0.3099\n",
      "Epoch 76/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.2100 - acc: 0.2354 - val_loss: 1.9528 - val_acc: 0.3158\n",
      "Epoch 77/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.2411 - acc: 0.2061 - val_loss: 1.9418 - val_acc: 0.3567\n",
      "Epoch 78/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.1813 - acc: 0.2427 - val_loss: 1.9474 - val_acc: 0.3158\n",
      "Epoch 79/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.2002 - acc: 0.2442 - val_loss: 1.9253 - val_acc: 0.2895\n",
      "Epoch 80/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.2153 - acc: 0.2529 - val_loss: 1.9435 - val_acc: 0.3041\n",
      "Epoch 81/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.1887 - acc: 0.2456 - val_loss: 1.9372 - val_acc: 0.3450\n",
      "Epoch 82/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.1453 - acc: 0.2442 - val_loss: 1.9334 - val_acc: 0.2982\n",
      "Epoch 83/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.1833 - acc: 0.2412 - val_loss: 1.9185 - val_acc: 0.3275\n",
      "Epoch 84/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.2042 - acc: 0.2018 - val_loss: 1.8945 - val_acc: 0.3246\n",
      "Epoch 85/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.2078 - acc: 0.2164 - val_loss: 1.9029 - val_acc: 0.3158\n",
      "Epoch 86/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.1961 - acc: 0.2339 - val_loss: 1.8936 - val_acc: 0.3509\n",
      "Epoch 87/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.2054 - acc: 0.2164 - val_loss: 1.8989 - val_acc: 0.3363\n",
      "Epoch 88/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.1796 - acc: 0.2471 - val_loss: 1.8709 - val_acc: 0.3450\n",
      "Epoch 89/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.1287 - acc: 0.2281 - val_loss: 1.8984 - val_acc: 0.3216\n",
      "Epoch 90/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 2.1590 - acc: 0.2398 - val_loss: 1.8911 - val_acc: 0.3450\n",
      "Epoch 91/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.2016 - acc: 0.2251 - val_loss: 1.8868 - val_acc: 0.3626\n",
      "Epoch 92/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.1738 - acc: 0.2368 - val_loss: 1.8699 - val_acc: 0.3918\n",
      "Epoch 93/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.1061 - acc: 0.2529 - val_loss: 1.8427 - val_acc: 0.3713\n",
      "Epoch 94/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.1149 - acc: 0.2632 - val_loss: 1.8309 - val_acc: 0.3655\n",
      "Epoch 95/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.1292 - acc: 0.2442 - val_loss: 1.8312 - val_acc: 0.3480loss: 2.0852 - acc: 0 - ETA: 0s - loss: 2.1342 - acc\n",
      "Epoch 96/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.1206 - acc: 0.2310 - val_loss: 1.7963 - val_acc: 0.3596\n",
      "Epoch 97/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.1147 - acc: 0.2617 - val_loss: 1.8100 - val_acc: 0.3743\n",
      "Epoch 98/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.1556 - acc: 0.2325 - val_loss: 1.8453 - val_acc: 0.3421\n",
      "Epoch 99/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.1025 - acc: 0.2705 - val_loss: 1.8347 - val_acc: 0.3684\n",
      "Epoch 100/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.1137 - acc: 0.2602 - val_loss: 1.8245 - val_acc: 0.3743\n",
      "Epoch 101/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.1553 - acc: 0.2602 - val_loss: 1.8297 - val_acc: 0.3772\n",
      "Epoch 102/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.0336 - acc: 0.2632 - val_loss: 1.7591 - val_acc: 0.3392\n",
      "Epoch 103/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.1406 - acc: 0.2456 - val_loss: 1.8071 - val_acc: 0.3801\n",
      "Epoch 104/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.0958 - acc: 0.2617 - val_loss: 1.7761 - val_acc: 0.3450\n",
      "Epoch 105/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.0963 - acc: 0.2705 - val_loss: 1.7979 - val_acc: 0.3626\n",
      "Epoch 106/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.0943 - acc: 0.2573 - val_loss: 1.7687 - val_acc: 0.3421\n",
      "Epoch 107/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.0594 - acc: 0.2778 - val_loss: 1.7148 - val_acc: 0.3480\n",
      "Epoch 108/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.0495 - acc: 0.2661 - val_loss: 1.7450 - val_acc: 0.3830\n",
      "Epoch 109/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.0468 - acc: 0.2924 - val_loss: 1.7680 - val_acc: 0.3860\n",
      "Epoch 110/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.0996 - acc: 0.2617 - val_loss: 1.7256 - val_acc: 0.3713\n",
      "Epoch 111/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.1143 - acc: 0.2851 - val_loss: 1.7732 - val_acc: 0.3392\n",
      "Epoch 112/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.0444 - acc: 0.2529 - val_loss: 1.7456 - val_acc: 0.3918\n",
      "Epoch 113/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.0266 - acc: 0.2705 - val_loss: 1.7158 - val_acc: 0.3713\n",
      "Epoch 114/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.1149 - acc: 0.2485 - val_loss: 1.7849 - val_acc: 0.4006\n",
      "Epoch 115/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.0743 - acc: 0.2749 - val_loss: 1.7700 - val_acc: 0.3918\n",
      "Epoch 116/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.0953 - acc: 0.2880 - val_loss: 1.7163 - val_acc: 0.3977\n",
      "Epoch 117/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.0907 - acc: 0.2661 - val_loss: 1.7792 - val_acc: 0.3538\n",
      "Epoch 118/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.0885 - acc: 0.2851 - val_loss: 1.7375 - val_acc: 0.3801\n",
      "Epoch 119/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.0809 - acc: 0.2880 - val_loss: 1.7372 - val_acc: 0.3801\n",
      "Epoch 120/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.0613 - acc: 0.2617 - val_loss: 1.7370 - val_acc: 0.3801\n",
      "Epoch 121/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 2s 3ms/step - loss: 2.0865 - acc: 0.2515 - val_loss: 1.7763 - val_acc: 0.3684\n",
      "Epoch 122/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.1148 - acc: 0.2719 - val_loss: 1.8248 - val_acc: 0.3743\n",
      "Epoch 123/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.1270 - acc: 0.2661 - val_loss: 1.7775 - val_acc: 0.3684\n",
      "Epoch 124/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.1316 - acc: 0.2734 - val_loss: 1.7921 - val_acc: 0.3889\n",
      "Epoch 125/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.1170 - acc: 0.2383 - val_loss: 1.7403 - val_acc: 0.4152\n",
      "Epoch 126/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.0978 - acc: 0.2632 - val_loss: 1.7420 - val_acc: 0.3918\n",
      "Epoch 127/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.1284 - acc: 0.2500 - val_loss: 1.7135 - val_acc: 0.3830\n",
      "Epoch 128/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.0242 - acc: 0.2865 - val_loss: 1.6868 - val_acc: 0.3918\n",
      "Epoch 129/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.0388 - acc: 0.2705 - val_loss: 1.7009 - val_acc: 0.3684\n",
      "Epoch 130/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.0526 - acc: 0.2880 - val_loss: 1.6870 - val_acc: 0.4006\n",
      "Epoch 131/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.0624 - acc: 0.2778 - val_loss: 1.7055 - val_acc: 0.3304\n",
      "Epoch 132/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.9820 - acc: 0.2909 - val_loss: 1.6850 - val_acc: 0.3860\n",
      "Epoch 133/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.0609 - acc: 0.2807 - val_loss: 1.6972 - val_acc: 0.4006\n",
      "Epoch 134/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.9199 - acc: 0.2909 - val_loss: 1.6584 - val_acc: 0.4035\n",
      "Epoch 135/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.0241 - acc: 0.2705 - val_loss: 1.7181 - val_acc: 0.3801\n",
      "Epoch 136/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.9948 - acc: 0.2939 - val_loss: 1.6751 - val_acc: 0.3977\n",
      "Epoch 137/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.0324 - acc: 0.2924 - val_loss: 1.6757 - val_acc: 0.3918\n",
      "Epoch 138/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.0147 - acc: 0.2807 - val_loss: 1.6797 - val_acc: 0.3596\n",
      "Epoch 139/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.0500 - acc: 0.2982 - val_loss: 1.6544 - val_acc: 0.3801\n",
      "Epoch 140/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.0130 - acc: 0.3012 - val_loss: 1.7024 - val_acc: 0.4035\n",
      "Epoch 141/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.9856 - acc: 0.3012 - val_loss: 1.6499 - val_acc: 0.4123\n",
      "Epoch 142/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.9790 - acc: 0.2982 - val_loss: 1.6245 - val_acc: 0.4064\n",
      "Epoch 143/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.0349 - acc: 0.2822 - val_loss: 1.6419 - val_acc: 0.4152\n",
      "Epoch 144/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.0034 - acc: 0.2968 - val_loss: 1.6839 - val_acc: 0.4152\n",
      "Epoch 145/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.9709 - acc: 0.2836 - val_loss: 1.6590 - val_acc: 0.4035\n",
      "Epoch 146/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.0251 - acc: 0.3099 - val_loss: 1.6403 - val_acc: 0.4152\n",
      "Epoch 147/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.0200 - acc: 0.2675 - val_loss: 1.6566 - val_acc: 0.4269\n",
      "Epoch 148/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.9363 - acc: 0.2865 - val_loss: 1.6105 - val_acc: 0.4415\n",
      "Epoch 149/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.9859 - acc: 0.3216 - val_loss: 1.6384 - val_acc: 0.3977\n",
      "Epoch 150/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.9714 - acc: 0.3099 - val_loss: 1.6474 - val_acc: 0.4064\n",
      "Epoch 151/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.9737 - acc: 0.2895 - val_loss: 1.6120 - val_acc: 0.4298\n",
      "Epoch 152/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.0224 - acc: 0.2836 - val_loss: 1.6185 - val_acc: 0.4152\n",
      "Epoch 153/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.9333 - acc: 0.2953 - val_loss: 1.5913 - val_acc: 0.4561\n",
      "Epoch 154/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.9424 - acc: 0.3012 - val_loss: 1.5775 - val_acc: 0.4561\n",
      "Epoch 155/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.9503 - acc: 0.2939 - val_loss: 1.5933 - val_acc: 0.4415\n",
      "Epoch 156/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.9518 - acc: 0.3158 - val_loss: 1.5955 - val_acc: 0.4152\n",
      "Epoch 157/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.9420 - acc: 0.2778 - val_loss: 1.5813 - val_acc: 0.4240\n",
      "Epoch 158/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.0075 - acc: 0.3158 - val_loss: 1.6067 - val_acc: 0.4269\n",
      "Epoch 159/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.9564 - acc: 0.2778 - val_loss: 1.5926 - val_acc: 0.4327\n",
      "Epoch 160/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.9420 - acc: 0.3143 - val_loss: 1.5731 - val_acc: 0.4503\n",
      "Epoch 161/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.9911 - acc: 0.3129 - val_loss: 1.5697 - val_acc: 0.4620\n",
      "Epoch 162/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.9221 - acc: 0.3246 - val_loss: 1.5557 - val_acc: 0.4708\n",
      "Epoch 163/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.9359 - acc: 0.2807 - val_loss: 1.5536 - val_acc: 0.4883\n",
      "Epoch 164/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.9524 - acc: 0.2880 - val_loss: 1.5493 - val_acc: 0.4415\n",
      "Epoch 165/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.9245 - acc: 0.2968 - val_loss: 1.5727 - val_acc: 0.4240\n",
      "Epoch 166/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.9211 - acc: 0.3026 - val_loss: 1.5600 - val_acc: 0.4883\n",
      "Epoch 167/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.9634 - acc: 0.3275 - val_loss: 1.6022 - val_acc: 0.4561\n",
      "Epoch 168/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8988 - acc: 0.3056 - val_loss: 1.5573 - val_acc: 0.4766\n",
      "Epoch 169/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8771 - acc: 0.3319 - val_loss: 1.5392 - val_acc: 0.4444\n",
      "Epoch 170/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.9299 - acc: 0.3289 - val_loss: 1.5435 - val_acc: 0.4357\n",
      "Epoch 171/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.9233 - acc: 0.3216 - val_loss: 1.5379 - val_acc: 0.4474\n",
      "Epoch 172/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.9282 - acc: 0.3304 - val_loss: 1.5476 - val_acc: 0.4152\n",
      "Epoch 173/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8793 - acc: 0.3436 - val_loss: 1.5211 - val_acc: 0.4503\n",
      "Epoch 174/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8823 - acc: 0.3070 - val_loss: 1.5156 - val_acc: 0.4649\n",
      "Epoch 175/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.9206 - acc: 0.3392 - val_loss: 1.5414 - val_acc: 0.4678\n",
      "Epoch 176/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.9486 - acc: 0.3143 - val_loss: 1.5199 - val_acc: 0.4591\n",
      "Epoch 177/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8573 - acc: 0.3567 - val_loss: 1.5028 - val_acc: 0.4298\n",
      "Epoch 178/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8626 - acc: 0.3231 - val_loss: 1.4817 - val_acc: 0.4708\n",
      "Epoch 179/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8876 - acc: 0.3216 - val_loss: 1.5168 - val_acc: 0.4561\n",
      "Epoch 180/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8833 - acc: 0.3377 - val_loss: 1.5154 - val_acc: 0.4649\n",
      "Epoch 181/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 2s 3ms/step - loss: 1.9045 - acc: 0.3246 - val_loss: 1.5138 - val_acc: 0.4795\n",
      "Epoch 182/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.9031 - acc: 0.3143 - val_loss: 1.4956 - val_acc: 0.4883\n",
      "Epoch 183/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8719 - acc: 0.3465 - val_loss: 1.4564 - val_acc: 0.4825\n",
      "Epoch 184/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.9268 - acc: 0.2953 - val_loss: 1.4866 - val_acc: 0.4591\n",
      "Epoch 185/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8232 - acc: 0.3406 - val_loss: 1.4735 - val_acc: 0.4912\n",
      "Epoch 186/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8985 - acc: 0.3289 - val_loss: 1.5029 - val_acc: 0.4561\n",
      "Epoch 187/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8408 - acc: 0.3538 - val_loss: 1.4757 - val_acc: 0.4766\n",
      "Epoch 188/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8984 - acc: 0.3099 - val_loss: 1.4647 - val_acc: 0.4737\n",
      "Epoch 189/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7697 - acc: 0.3611 - val_loss: 1.4088 - val_acc: 0.4708\n",
      "Epoch 190/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8769 - acc: 0.3436 - val_loss: 1.4445 - val_acc: 0.4766\n",
      "Epoch 191/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8561 - acc: 0.3480 - val_loss: 1.4489 - val_acc: 0.4795\n",
      "Epoch 192/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8489 - acc: 0.3465 - val_loss: 1.4331 - val_acc: 0.4766\n",
      "Epoch 193/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8630 - acc: 0.3377 - val_loss: 1.4426 - val_acc: 0.4503\n",
      "Epoch 194/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8561 - acc: 0.3260 - val_loss: 1.4146 - val_acc: 0.4591\n",
      "Epoch 195/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8750 - acc: 0.3026 - val_loss: 1.4563 - val_acc: 0.4912\n",
      "Epoch 196/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8895 - acc: 0.3304 - val_loss: 1.4763 - val_acc: 0.4678\n",
      "Epoch 197/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8747 - acc: 0.3377 - val_loss: 1.4297 - val_acc: 0.4737\n",
      "Epoch 198/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8255 - acc: 0.3567 - val_loss: 1.4227 - val_acc: 0.4971\n",
      "Epoch 199/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8452 - acc: 0.3480 - val_loss: 1.4499 - val_acc: 0.4971\n",
      "Epoch 200/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8843 - acc: 0.3216 - val_loss: 1.4631 - val_acc: 0.4766\n",
      "Epoch 201/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8212 - acc: 0.3596 - val_loss: 1.4300 - val_acc: 0.4708\n",
      "Epoch 202/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8434 - acc: 0.3509 - val_loss: 1.4132 - val_acc: 0.4532\n",
      "Epoch 203/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8173 - acc: 0.3216 - val_loss: 1.4059 - val_acc: 0.4912\n",
      "Epoch 204/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.9091 - acc: 0.3158 - val_loss: 1.4484 - val_acc: 0.4854\n",
      "Epoch 205/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8436 - acc: 0.3406 - val_loss: 1.4414 - val_acc: 0.5175\n",
      "Epoch 206/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8338 - acc: 0.3289 - val_loss: 1.4344 - val_acc: 0.5058\n",
      "Epoch 207/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8185 - acc: 0.3363 - val_loss: 1.4186 - val_acc: 0.5029\n",
      "Epoch 208/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8128 - acc: 0.3363 - val_loss: 1.4082 - val_acc: 0.4854\n",
      "Epoch 209/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7897 - acc: 0.3596 - val_loss: 1.4227 - val_acc: 0.4561\n",
      "Epoch 210/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8469 - acc: 0.3319 - val_loss: 1.4157 - val_acc: 0.4942\n",
      "Epoch 211/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8526 - acc: 0.3319 - val_loss: 1.4106 - val_acc: 0.4825\n",
      "Epoch 212/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8169 - acc: 0.3319 - val_loss: 1.4107 - val_acc: 0.4912\n",
      "Epoch 213/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7606 - acc: 0.3655 - val_loss: 1.3936 - val_acc: 0.4942\n",
      "Epoch 214/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8314 - acc: 0.3260 - val_loss: 1.4116 - val_acc: 0.5000\n",
      "Epoch 215/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8193 - acc: 0.3406 - val_loss: 1.4213 - val_acc: 0.5029\n",
      "Epoch 216/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7872 - acc: 0.3392 - val_loss: 1.4234 - val_acc: 0.5088\n",
      "Epoch 217/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7533 - acc: 0.3523 - val_loss: 1.3897 - val_acc: 0.4912\n",
      "Epoch 218/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7940 - acc: 0.3509 - val_loss: 1.3881 - val_acc: 0.5058\n",
      "Epoch 219/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8246 - acc: 0.3421 - val_loss: 1.3843 - val_acc: 0.5088\n",
      "Epoch 220/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8164 - acc: 0.3538 - val_loss: 1.4185 - val_acc: 0.4912\n",
      "Epoch 221/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8039 - acc: 0.3816 - val_loss: 1.3978 - val_acc: 0.4825\n",
      "Epoch 222/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7907 - acc: 0.3728 - val_loss: 1.3952 - val_acc: 0.4971\n",
      "Epoch 223/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8611 - acc: 0.3246 - val_loss: 1.4007 - val_acc: 0.5292\n",
      "Epoch 224/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7806 - acc: 0.3538 - val_loss: 1.3753 - val_acc: 0.5263\n",
      "Epoch 225/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8043 - acc: 0.3757 - val_loss: 1.3808 - val_acc: 0.5351\n",
      "Epoch 226/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7878 - acc: 0.3450 - val_loss: 1.3999 - val_acc: 0.5088\n",
      "Epoch 227/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8312 - acc: 0.3480 - val_loss: 1.4084 - val_acc: 0.4971\n",
      "Epoch 228/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8392 - acc: 0.3421 - val_loss: 1.4275 - val_acc: 0.5146\n",
      "Epoch 229/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7394 - acc: 0.3655 - val_loss: 1.3915 - val_acc: 0.5205\n",
      "Epoch 230/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7912 - acc: 0.3523 - val_loss: 1.3551 - val_acc: 0.5117\n",
      "Epoch 231/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8400 - acc: 0.3582 - val_loss: 1.3790 - val_acc: 0.5263\n",
      "Epoch 232/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7604 - acc: 0.3538 - val_loss: 1.3804 - val_acc: 0.4942\n",
      "Epoch 233/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 1.7478 - acc: 0.3523 - val_loss: 1.3767 - val_acc: 0.5234\n",
      "Epoch 234/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 1.7219 - acc: 0.3626 - val_loss: 1.3452 - val_acc: 0.5146\n",
      "Epoch 235/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7573 - acc: 0.3655 - val_loss: 1.3481 - val_acc: 0.5146\n",
      "Epoch 236/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8098 - acc: 0.3450 - val_loss: 1.3573 - val_acc: 0.5058\n",
      "Epoch 237/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8176 - acc: 0.3392 - val_loss: 1.3437 - val_acc: 0.4942\n",
      "Epoch 238/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6847 - acc: 0.3670 - val_loss: 1.3482 - val_acc: 0.5029\n",
      "Epoch 239/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7678 - acc: 0.3699 - val_loss: 1.3511 - val_acc: 0.5351\n",
      "Epoch 240/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8265 - acc: 0.3655 - val_loss: 1.3652 - val_acc: 0.5146\n",
      "Epoch 241/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8191 - acc: 0.3348 - val_loss: 1.3896 - val_acc: 0.5292\n",
      "Epoch 242/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7909 - acc: 0.3567 - val_loss: 1.3901 - val_acc: 0.5409\n",
      "Epoch 243/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7656 - acc: 0.3743 - val_loss: 1.3807 - val_acc: 0.5175\n",
      "Epoch 244/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7897 - acc: 0.3406 - val_loss: 1.3725 - val_acc: 0.4971\n",
      "Epoch 245/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7916 - acc: 0.3494 - val_loss: 1.3877 - val_acc: 0.4971\n",
      "Epoch 246/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7235 - acc: 0.3991 - val_loss: 1.3755 - val_acc: 0.5058\n",
      "Epoch 247/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7365 - acc: 0.3553 - val_loss: 1.3593 - val_acc: 0.5117\n",
      "Epoch 248/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7795 - acc: 0.3699 - val_loss: 1.3817 - val_acc: 0.5058\n",
      "Epoch 249/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8357 - acc: 0.3392 - val_loss: 1.3935 - val_acc: 0.5175\n",
      "Epoch 250/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8045 - acc: 0.3743 - val_loss: 1.3909 - val_acc: 0.4912\n",
      "Epoch 251/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7719 - acc: 0.3611 - val_loss: 1.3662 - val_acc: 0.5029\n",
      "Epoch 252/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7638 - acc: 0.3772 - val_loss: 1.3755 - val_acc: 0.5088\n",
      "Epoch 253/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8061 - acc: 0.3509 - val_loss: 1.3964 - val_acc: 0.4942\n",
      "Epoch 254/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7534 - acc: 0.3699 - val_loss: 1.3821 - val_acc: 0.4912\n",
      "Epoch 255/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8097 - acc: 0.3260 - val_loss: 1.3923 - val_acc: 0.4825\n",
      "Epoch 256/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8206 - acc: 0.3246 - val_loss: 1.3761 - val_acc: 0.4854\n",
      "Epoch 257/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7572 - acc: 0.3655 - val_loss: 1.3629 - val_acc: 0.4795\n",
      "Epoch 258/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7191 - acc: 0.3713 - val_loss: 1.3523 - val_acc: 0.4883\n",
      "Epoch 259/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7384 - acc: 0.3699 - val_loss: 1.3543 - val_acc: 0.5000\n",
      "Epoch 260/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8465 - acc: 0.3363 - val_loss: 1.3642 - val_acc: 0.5029\n",
      "Epoch 261/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7507 - acc: 0.3626 - val_loss: 1.3499 - val_acc: 0.4912\n",
      "Epoch 262/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7357 - acc: 0.3640 - val_loss: 1.3558 - val_acc: 0.5234\n",
      "Epoch 263/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7509 - acc: 0.3626 - val_loss: 1.3529 - val_acc: 0.5175\n",
      "Epoch 264/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7177 - acc: 0.3713 - val_loss: 1.3611 - val_acc: 0.5029\n",
      "Epoch 265/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7573 - acc: 0.3480 - val_loss: 1.3400 - val_acc: 0.5117\n",
      "Epoch 266/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7891 - acc: 0.3582 - val_loss: 1.3584 - val_acc: 0.5117\n",
      "Epoch 267/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7944 - acc: 0.3640 - val_loss: 1.3631 - val_acc: 0.5175\n",
      "Epoch 268/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7312 - acc: 0.3611 - val_loss: 1.3948 - val_acc: 0.5029\n",
      "Epoch 269/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8243 - acc: 0.3392 - val_loss: 1.4152 - val_acc: 0.4883\n",
      "Epoch 270/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8220 - acc: 0.3553 - val_loss: 1.3940 - val_acc: 0.5088195 - acc: 0.3\n",
      "Epoch 271/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7457 - acc: 0.3889 - val_loss: 1.3846 - val_acc: 0.4971\n",
      "Epoch 272/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7919 - acc: 0.3611 - val_loss: 1.3714 - val_acc: 0.4971\n",
      "Epoch 273/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7856 - acc: 0.3480 - val_loss: 1.3665 - val_acc: 0.5000\n",
      "Epoch 274/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8310 - acc: 0.3377 - val_loss: 1.3834 - val_acc: 0.5029\n",
      "Epoch 275/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7694 - acc: 0.3713 - val_loss: 1.3823 - val_acc: 0.5058\n",
      "Epoch 276/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7621 - acc: 0.3523 - val_loss: 1.3807 - val_acc: 0.5146\n",
      "Epoch 277/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7801 - acc: 0.3743 - val_loss: 1.3846 - val_acc: 0.5058\n",
      "Epoch 278/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8168 - acc: 0.3246 - val_loss: 1.4387 - val_acc: 0.4942\n",
      "Epoch 279/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7251 - acc: 0.3816 - val_loss: 1.3850 - val_acc: 0.4971\n",
      "Epoch 280/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8026 - acc: 0.3553 - val_loss: 1.4155 - val_acc: 0.4971\n",
      "Epoch 281/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7590 - acc: 0.3670 - val_loss: 1.3993 - val_acc: 0.4942\n",
      "Epoch 282/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8639 - acc: 0.3553 - val_loss: 1.3931 - val_acc: 0.4883\n",
      "Epoch 283/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 1.7408 - acc: 0.3947 - val_loss: 1.3856 - val_acc: 0.5000\n",
      "Epoch 284/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7576 - acc: 0.3553 - val_loss: 1.3877 - val_acc: 0.5000\n",
      "Epoch 285/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7607 - acc: 0.3743 - val_loss: 1.4328 - val_acc: 0.4912\n",
      "Epoch 286/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8025 - acc: 0.3977 - val_loss: 1.3968 - val_acc: 0.5029\n",
      "Epoch 287/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7602 - acc: 0.3538 - val_loss: 1.3799 - val_acc: 0.5029\n",
      "Epoch 288/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7804 - acc: 0.3728 - val_loss: 1.3572 - val_acc: 0.5000\n",
      "Epoch 289/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7285 - acc: 0.3845 - val_loss: 1.3855 - val_acc: 0.4971\n",
      "Epoch 290/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7535 - acc: 0.3509 - val_loss: 1.3781 - val_acc: 0.4942\n",
      "Epoch 291/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7920 - acc: 0.3947 - val_loss: 1.3873 - val_acc: 0.5029\n",
      "Epoch 292/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7811 - acc: 0.3699 - val_loss: 1.3892 - val_acc: 0.4971\n",
      "Epoch 293/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7505 - acc: 0.3772 - val_loss: 1.3582 - val_acc: 0.5029\n",
      "Epoch 294/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6996 - acc: 0.3830 - val_loss: 1.3647 - val_acc: 0.5117\n",
      "Epoch 295/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7432 - acc: 0.3670 - val_loss: 1.3500 - val_acc: 0.4912\n",
      "Epoch 296/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7888 - acc: 0.3582 - val_loss: 1.3767 - val_acc: 0.5029\n",
      "Epoch 297/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7642 - acc: 0.3684 - val_loss: 1.3810 - val_acc: 0.5058\n",
      "Epoch 298/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8016 - acc: 0.3684 - val_loss: 1.3744 - val_acc: 0.5088\n",
      "Epoch 299/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7155 - acc: 0.3889 - val_loss: 1.3662 - val_acc: 0.5000\n",
      "Epoch 300/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7883 - acc: 0.3567 - val_loss: 1.4082 - val_acc: 0.4971\n",
      "Epoch 301/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7473 - acc: 0.3684 - val_loss: 1.3890 - val_acc: 0.5058\n",
      "Epoch 302/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7836 - acc: 0.3509 - val_loss: 1.4185 - val_acc: 0.4883\n",
      "Epoch 303/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7255 - acc: 0.3509 - val_loss: 1.3463 - val_acc: 0.5088\n",
      "Epoch 304/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7059 - acc: 0.3743 - val_loss: 1.3572 - val_acc: 0.4971\n",
      "Epoch 305/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7780 - acc: 0.3567 - val_loss: 1.3650 - val_acc: 0.5058\n",
      "Epoch 306/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7762 - acc: 0.3626 - val_loss: 1.3527 - val_acc: 0.4912\n",
      "Epoch 307/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7151 - acc: 0.3421 - val_loss: 1.3484 - val_acc: 0.4971\n",
      "Epoch 308/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7828 - acc: 0.3772 - val_loss: 1.3755 - val_acc: 0.5117\n",
      "Epoch 309/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8037 - acc: 0.3494 - val_loss: 1.3857 - val_acc: 0.5058\n",
      "Epoch 310/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7457 - acc: 0.3830 - val_loss: 1.3790 - val_acc: 0.5146\n",
      "Epoch 311/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7108 - acc: 0.3830 - val_loss: 1.3482 - val_acc: 0.5058\n",
      "Epoch 312/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6856 - acc: 0.3889 - val_loss: 1.3375 - val_acc: 0.5292\n",
      "Epoch 313/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7245 - acc: 0.3728 - val_loss: 1.3336 - val_acc: 0.5146\n",
      "Epoch 314/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7304 - acc: 0.3523 - val_loss: 1.3309 - val_acc: 0.5205\n",
      "Epoch 315/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7828 - acc: 0.3553 - val_loss: 1.3495 - val_acc: 0.5146\n",
      "Epoch 316/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7893 - acc: 0.3509 - val_loss: 1.3855 - val_acc: 0.4795\n",
      "Epoch 317/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7721 - acc: 0.3640 - val_loss: 1.3848 - val_acc: 0.4971\n",
      "Epoch 318/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7841 - acc: 0.3450 - val_loss: 1.3960 - val_acc: 0.5117\n",
      "Epoch 319/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7754 - acc: 0.3684 - val_loss: 1.3807 - val_acc: 0.5175\n",
      "Epoch 320/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7241 - acc: 0.3611 - val_loss: 1.3743 - val_acc: 0.5380\n",
      "Epoch 321/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7678 - acc: 0.3538 - val_loss: 1.3655 - val_acc: 0.5175\n",
      "Epoch 322/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7202 - acc: 0.3713 - val_loss: 1.3578 - val_acc: 0.5117\n",
      "Epoch 323/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7540 - acc: 0.3582 - val_loss: 1.3662 - val_acc: 0.5058\n",
      "Epoch 324/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7724 - acc: 0.3406 - val_loss: 1.3600 - val_acc: 0.5205\n",
      "Epoch 325/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7900 - acc: 0.3596 - val_loss: 1.3663 - val_acc: 0.5088\n",
      "Epoch 326/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6857 - acc: 0.3816 - val_loss: 1.3584 - val_acc: 0.5292\n",
      "Epoch 327/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8319 - acc: 0.3523 - val_loss: 1.3720 - val_acc: 0.4912\n",
      "Epoch 328/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8002 - acc: 0.3289 - val_loss: 1.3630 - val_acc: 0.4795\n",
      "Epoch 329/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7894 - acc: 0.3480 - val_loss: 1.3656 - val_acc: 0.4825 loss: 1.763\n",
      "Epoch 330/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7662 - acc: 0.3684 - val_loss: 1.3678 - val_acc: 0.5000\n",
      "Epoch 331/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7846 - acc: 0.3333 - val_loss: 1.3631 - val_acc: 0.4942\n",
      "Epoch 332/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8094 - acc: 0.3684 - val_loss: 1.3615 - val_acc: 0.4942\n",
      "Epoch 333/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7800 - acc: 0.3699 - val_loss: 1.3679 - val_acc: 0.5000\n",
      "Epoch 334/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7989 - acc: 0.3348 - val_loss: 1.3826 - val_acc: 0.4795\n",
      "Epoch 335/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7956 - acc: 0.3392 - val_loss: 1.3749 - val_acc: 0.4825\n",
      "Epoch 336/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7904 - acc: 0.3450 - val_loss: 1.3892 - val_acc: 0.4883\n",
      "Epoch 337/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7979 - acc: 0.3509 - val_loss: 1.3911 - val_acc: 0.4854\n",
      "Epoch 338/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7125 - acc: 0.3743 - val_loss: 1.3687 - val_acc: 0.4971\n",
      "Epoch 339/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8125 - acc: 0.3889 - val_loss: 1.3834 - val_acc: 0.4854\n",
      "Epoch 340/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7501 - acc: 0.3655 - val_loss: 1.3976 - val_acc: 0.4854\n",
      "Epoch 341/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7943 - acc: 0.3699 - val_loss: 1.3984 - val_acc: 0.4795\n",
      "Epoch 342/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7986 - acc: 0.3640 - val_loss: 1.3824 - val_acc: 0.4795\n",
      "Epoch 343/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8002 - acc: 0.3611 - val_loss: 1.3822 - val_acc: 0.4795\n",
      "Epoch 344/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7488 - acc: 0.3904 - val_loss: 1.3914 - val_acc: 0.4854\n",
      "Epoch 345/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7243 - acc: 0.3538 - val_loss: 1.3795 - val_acc: 0.5058\n",
      "Epoch 346/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7900 - acc: 0.3509 - val_loss: 1.4007 - val_acc: 0.4825\n",
      "Epoch 347/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7697 - acc: 0.3830 - val_loss: 1.3845 - val_acc: 0.4971\n",
      "Epoch 348/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7531 - acc: 0.3699 - val_loss: 1.3717 - val_acc: 0.4854\n",
      "Epoch 349/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7787 - acc: 0.3596 - val_loss: 1.3711 - val_acc: 0.4883\n",
      "Epoch 350/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7605 - acc: 0.3787 - val_loss: 1.4140 - val_acc: 0.4708\n",
      "Epoch 351/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7223 - acc: 0.3860 - val_loss: 1.4040 - val_acc: 0.4825\n",
      "Epoch 352/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7717 - acc: 0.3509 - val_loss: 1.4057 - val_acc: 0.4854\n",
      "Epoch 353/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7187 - acc: 0.3801 - val_loss: 1.3916 - val_acc: 0.4766\n",
      "Epoch 354/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7434 - acc: 0.3918 - val_loss: 1.3832 - val_acc: 0.4795\n",
      "Epoch 355/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7448 - acc: 0.3728 - val_loss: 1.3826 - val_acc: 0.4912\n",
      "Epoch 356/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7097 - acc: 0.3596 - val_loss: 1.3790 - val_acc: 0.4649\n",
      "Epoch 357/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 1.7930 - acc: 0.3436 - val_loss: 1.3823 - val_acc: 0.4883\n",
      "Epoch 358/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7496 - acc: 0.3626 - val_loss: 1.3903 - val_acc: 0.4942\n",
      "Epoch 359/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7654 - acc: 0.3670 - val_loss: 1.3791 - val_acc: 0.4766\n",
      "Epoch 360/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7539 - acc: 0.3713 - val_loss: 1.3818 - val_acc: 0.4942\n",
      "Epoch 361/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8213 - acc: 0.3787 - val_loss: 1.4214 - val_acc: 0.4678\n",
      "Epoch 362/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7903 - acc: 0.3611 - val_loss: 1.4035 - val_acc: 0.4708\n",
      "Epoch 363/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7021 - acc: 0.4020 - val_loss: 1.3946 - val_acc: 0.4825\n",
      "Epoch 364/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7418 - acc: 0.3713 - val_loss: 1.3779 - val_acc: 0.4678\n",
      "Epoch 365/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7092 - acc: 0.3670 - val_loss: 1.3639 - val_acc: 0.4737\n",
      "Epoch 366/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7621 - acc: 0.3626 - val_loss: 1.3487 - val_acc: 0.4795\n",
      "Epoch 367/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7190 - acc: 0.4108 - val_loss: 1.3626 - val_acc: 0.4737\n",
      "Epoch 368/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7105 - acc: 0.3626 - val_loss: 1.3487 - val_acc: 0.4854\n",
      "Epoch 369/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7524 - acc: 0.3757 - val_loss: 1.3576 - val_acc: 0.4825\n",
      "Epoch 370/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7203 - acc: 0.3816 - val_loss: 1.3656 - val_acc: 0.4854\n",
      "Epoch 371/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7529 - acc: 0.3670 - val_loss: 1.3608 - val_acc: 0.4942\n",
      "Epoch 372/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7791 - acc: 0.3611 - val_loss: 1.3759 - val_acc: 0.4883\n",
      "Epoch 373/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7329 - acc: 0.3553 - val_loss: 1.3638 - val_acc: 0.4883\n",
      "Epoch 374/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7798 - acc: 0.3699 - val_loss: 1.3736 - val_acc: 0.4854\n",
      "Epoch 375/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7864 - acc: 0.3699 - val_loss: 1.3809 - val_acc: 0.4766\n",
      "Epoch 376/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7128 - acc: 0.3743 - val_loss: 1.3849 - val_acc: 0.4942\n",
      "Epoch 377/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7683 - acc: 0.3801 - val_loss: 1.3967 - val_acc: 0.4971\n",
      "Epoch 378/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7711 - acc: 0.3596 - val_loss: 1.3953 - val_acc: 0.4883\n",
      "Epoch 379/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8161 - acc: 0.3494 - val_loss: 1.3968 - val_acc: 0.4766\n",
      "Epoch 380/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7492 - acc: 0.3757 - val_loss: 1.3811 - val_acc: 0.4912\n",
      "Epoch 381/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7594 - acc: 0.3918 - val_loss: 1.3802 - val_acc: 0.5088\n",
      "Epoch 382/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7481 - acc: 0.3816 - val_loss: 1.3832 - val_acc: 0.4942\n",
      "Epoch 383/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7251 - acc: 0.3465 - val_loss: 1.3733 - val_acc: 0.4942\n",
      "Epoch 384/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6863 - acc: 0.3962 - val_loss: 1.3775 - val_acc: 0.4883\n",
      "Epoch 385/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7084 - acc: 0.3655 - val_loss: 1.3850 - val_acc: 0.4883\n",
      "Epoch 386/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7219 - acc: 0.3947 - val_loss: 1.3730 - val_acc: 0.4912\n",
      "Epoch 387/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7057 - acc: 0.4020 - val_loss: 1.3605 - val_acc: 0.5000\n",
      "Epoch 388/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7588 - acc: 0.3713 - val_loss: 1.3809 - val_acc: 0.5000\n",
      "Epoch 389/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7596 - acc: 0.3757 - val_loss: 1.3928 - val_acc: 0.5029\n",
      "Epoch 390/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7346 - acc: 0.3816 - val_loss: 1.3606 - val_acc: 0.5058\n",
      "Epoch 391/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7067 - acc: 0.3772 - val_loss: 1.3665 - val_acc: 0.5205\n",
      "Epoch 392/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6783 - acc: 0.3962 - val_loss: 1.3517 - val_acc: 0.5117\n",
      "Epoch 393/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6958 - acc: 0.3845 - val_loss: 1.3451 - val_acc: 0.5146\n",
      "Epoch 394/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7280 - acc: 0.3728 - val_loss: 1.3588 - val_acc: 0.4971\n",
      "Epoch 395/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7469 - acc: 0.3743 - val_loss: 1.3540 - val_acc: 0.5146\n",
      "Epoch 396/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6943 - acc: 0.3904 - val_loss: 1.3513 - val_acc: 0.5175\n",
      "Epoch 397/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7261 - acc: 0.3801 - val_loss: 1.3496 - val_acc: 0.5058\n",
      "Epoch 398/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6968 - acc: 0.3904 - val_loss: 1.3682 - val_acc: 0.4971\n",
      "Epoch 399/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7403 - acc: 0.3801 - val_loss: 1.3512 - val_acc: 0.5058\n",
      "Epoch 400/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7395 - acc: 0.3874 - val_loss: 1.3702 - val_acc: 0.5000\n",
      "Epoch 401/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8166 - acc: 0.3626 - val_loss: 1.3839 - val_acc: 0.4971\n",
      "Epoch 402/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7179 - acc: 0.3947 - val_loss: 1.3717 - val_acc: 0.4883\n",
      "Epoch 403/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7499 - acc: 0.3947 - val_loss: 1.3853 - val_acc: 0.4825\n",
      "Epoch 404/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7709 - acc: 0.3567 - val_loss: 1.3784 - val_acc: 0.4854\n",
      "Epoch 405/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7330 - acc: 0.3787 - val_loss: 1.3744 - val_acc: 0.4766\n",
      "Epoch 406/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7680 - acc: 0.3713 - val_loss: 1.3878 - val_acc: 0.4708\n",
      "Epoch 407/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7383 - acc: 0.3787 - val_loss: 1.3779 - val_acc: 0.4854\n",
      "Epoch 408/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7535 - acc: 0.3772 - val_loss: 1.3742 - val_acc: 0.4942\n",
      "Epoch 409/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7523 - acc: 0.3816 - val_loss: 1.3841 - val_acc: 0.4942\n",
      "Epoch 410/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7267 - acc: 0.3699 - val_loss: 1.3606 - val_acc: 0.5029\n",
      "Epoch 411/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7646 - acc: 0.3962 - val_loss: 1.3500 - val_acc: 0.4912\n",
      "Epoch 412/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7211 - acc: 0.3918 - val_loss: 1.3538 - val_acc: 0.4854\n",
      "Epoch 413/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7650 - acc: 0.3874 - val_loss: 1.3779 - val_acc: 0.4766\n",
      "Epoch 414/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7154 - acc: 0.3772 - val_loss: 1.3665 - val_acc: 0.4737\n",
      "Epoch 415/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7289 - acc: 0.3801 - val_loss: 1.3643 - val_acc: 0.4737\n",
      "Epoch 416/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6616 - acc: 0.3772 - val_loss: 1.3534 - val_acc: 0.4825\n",
      "Epoch 417/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6766 - acc: 0.4020 - val_loss: 1.3592 - val_acc: 0.4766\n",
      "Epoch 418/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7361 - acc: 0.3991 - val_loss: 1.3675 - val_acc: 0.4883\n",
      "Epoch 419/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7460 - acc: 0.3918 - val_loss: 1.3753 - val_acc: 0.4883\n",
      "Epoch 420/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7124 - acc: 0.4050 - val_loss: 1.3600 - val_acc: 0.5088\n",
      "Epoch 421/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7622 - acc: 0.3713 - val_loss: 1.3698 - val_acc: 0.5205\n",
      "Epoch 422/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7355 - acc: 0.3947 - val_loss: 1.3585 - val_acc: 0.5175\n",
      "Epoch 423/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7193 - acc: 0.3728 - val_loss: 1.3607 - val_acc: 0.5088\n",
      "Epoch 424/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7551 - acc: 0.3684 - val_loss: 1.3754 - val_acc: 0.5322\n",
      "Epoch 425/1000\n",
      "684/684 [==============================] - ETA: 0s - loss: 1.7294 - acc: 0.373 - 2s 3ms/step - loss: 1.7309 - acc: 0.3728 - val_loss: 1.3437 - val_acc: 0.5175\n",
      "Epoch 426/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6973 - acc: 0.3918 - val_loss: 1.3601 - val_acc: 0.5205\n",
      "Epoch 427/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7378 - acc: 0.3626 - val_loss: 1.3375 - val_acc: 0.5029\n",
      "Epoch 428/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6541 - acc: 0.3991 - val_loss: 1.3469 - val_acc: 0.5146\n",
      "Epoch 429/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7231 - acc: 0.3918 - val_loss: 1.3530 - val_acc: 0.5175\n",
      "Epoch 430/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6720 - acc: 0.3860 - val_loss: 1.3622 - val_acc: 0.5058\n",
      "Epoch 431/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7369 - acc: 0.3787 - val_loss: 1.3384 - val_acc: 0.5058\n",
      "Epoch 432/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6789 - acc: 0.4137 - val_loss: 1.3357 - val_acc: 0.5088\n",
      "Epoch 433/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7421 - acc: 0.3933 - val_loss: 1.3494 - val_acc: 0.4971\n",
      "Epoch 434/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7588 - acc: 0.3596 - val_loss: 1.3604 - val_acc: 0.4825\n",
      "Epoch 435/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7115 - acc: 0.3947 - val_loss: 1.3497 - val_acc: 0.4912\n",
      "Epoch 436/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7205 - acc: 0.3860 - val_loss: 1.3450 - val_acc: 0.5058\n",
      "Epoch 437/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7224 - acc: 0.3757 - val_loss: 1.3494 - val_acc: 0.4971\n",
      "Epoch 438/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7276 - acc: 0.3904 - val_loss: 1.3607 - val_acc: 0.5117\n",
      "Epoch 439/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6871 - acc: 0.3991 - val_loss: 1.3555 - val_acc: 0.5029\n",
      "Epoch 440/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6563 - acc: 0.3801 - val_loss: 1.3409 - val_acc: 0.5263\n",
      "Epoch 441/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7850 - acc: 0.3713 - val_loss: 1.3454 - val_acc: 0.5175\n",
      "Epoch 442/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6983 - acc: 0.4020 - val_loss: 1.3406 - val_acc: 0.5088\n",
      "Epoch 443/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7294 - acc: 0.4035 - val_loss: 1.3648 - val_acc: 0.4825\n",
      "Epoch 444/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7253 - acc: 0.3670 - val_loss: 1.3609 - val_acc: 0.4942\n",
      "Epoch 445/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7296 - acc: 0.3772 - val_loss: 1.3576 - val_acc: 0.5322\n",
      "Epoch 446/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6864 - acc: 0.4108 - val_loss: 1.3448 - val_acc: 0.5205\n",
      "Epoch 447/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.8064 - acc: 0.3553 - val_loss: 1.3802 - val_acc: 0.4971\n",
      "Epoch 448/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 1.6921 - acc: 0.3757 - val_loss: 1.3457 - val_acc: 0.5058\n",
      "Epoch 449/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 1.7442 - acc: 0.3728 - val_loss: 1.3590 - val_acc: 0.5058\n",
      "Epoch 450/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6369 - acc: 0.4020 - val_loss: 1.3278 - val_acc: 0.5234\n",
      "Epoch 451/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6489 - acc: 0.4050 - val_loss: 1.3221 - val_acc: 0.5117\n",
      "Epoch 452/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7497 - acc: 0.3582 - val_loss: 1.3397 - val_acc: 0.5117\n",
      "Epoch 453/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7410 - acc: 0.3889 - val_loss: 1.3235 - val_acc: 0.5000\n",
      "Epoch 454/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6878 - acc: 0.4167 - val_loss: 1.3243 - val_acc: 0.5205\n",
      "Epoch 455/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6711 - acc: 0.3684 - val_loss: 1.3178 - val_acc: 0.5292\n",
      "Epoch 456/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7105 - acc: 0.3816 - val_loss: 1.3368 - val_acc: 0.5205\n",
      "Epoch 457/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6766 - acc: 0.4050 - val_loss: 1.3568 - val_acc: 0.5117\n",
      "Epoch 458/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6821 - acc: 0.3991 - val_loss: 1.3482 - val_acc: 0.5146\n",
      "Epoch 459/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7106 - acc: 0.3713 - val_loss: 1.3626 - val_acc: 0.5175\n",
      "Epoch 460/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7357 - acc: 0.3845 - val_loss: 1.3387 - val_acc: 0.5175\n",
      "Epoch 461/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7103 - acc: 0.3772 - val_loss: 1.3366 - val_acc: 0.5322\n",
      "Epoch 462/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7205 - acc: 0.3699 - val_loss: 1.3430 - val_acc: 0.5322\n",
      "Epoch 463/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7039 - acc: 0.3743 - val_loss: 1.3541 - val_acc: 0.5234\n",
      "Epoch 464/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7079 - acc: 0.3801 - val_loss: 1.3348 - val_acc: 0.5468\n",
      "Epoch 465/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7125 - acc: 0.4123 - val_loss: 1.3437 - val_acc: 0.5439\n",
      "Epoch 466/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6978 - acc: 0.3991 - val_loss: 1.3400 - val_acc: 0.5409\n",
      "Epoch 467/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7267 - acc: 0.3670 - val_loss: 1.3290 - val_acc: 0.5234\n",
      "Epoch 468/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6898 - acc: 0.4123 - val_loss: 1.3309 - val_acc: 0.5322\n",
      "Epoch 469/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6580 - acc: 0.3684 - val_loss: 1.3207 - val_acc: 0.5263\n",
      "Epoch 470/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7358 - acc: 0.3699 - val_loss: 1.3262 - val_acc: 0.5234\n",
      "Epoch 471/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6902 - acc: 0.4035 - val_loss: 1.3377 - val_acc: 0.5292\n",
      "Epoch 472/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7395 - acc: 0.3713 - val_loss: 1.3389 - val_acc: 0.5088\n",
      "Epoch 473/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6974 - acc: 0.4006 - val_loss: 1.3270 - val_acc: 0.5175\n",
      "Epoch 474/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7129 - acc: 0.3816 - val_loss: 1.3278 - val_acc: 0.5175\n",
      "Epoch 475/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7274 - acc: 0.3845 - val_loss: 1.3278 - val_acc: 0.5263\n",
      "Epoch 476/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7158 - acc: 0.3962 - val_loss: 1.3316 - val_acc: 0.5292\n",
      "Epoch 477/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7196 - acc: 0.3977 - val_loss: 1.3229 - val_acc: 0.5292\n",
      "Epoch 478/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7760 - acc: 0.3845 - val_loss: 1.3045 - val_acc: 0.5322\n",
      "Epoch 479/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6949 - acc: 0.3757 - val_loss: 1.3169 - val_acc: 0.5468\n",
      "Epoch 480/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6418 - acc: 0.4006 - val_loss: 1.3103 - val_acc: 0.5556\n",
      "Epoch 481/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7275 - acc: 0.3918 - val_loss: 1.3158 - val_acc: 0.5468\n",
      "Epoch 482/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6991 - acc: 0.3933 - val_loss: 1.2990 - val_acc: 0.5497\n",
      "Epoch 483/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6729 - acc: 0.4079 - val_loss: 1.3086 - val_acc: 0.5409\n",
      "Epoch 484/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7117 - acc: 0.3933 - val_loss: 1.3284 - val_acc: 0.5468\n",
      "Epoch 485/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6913 - acc: 0.3845 - val_loss: 1.3276 - val_acc: 0.5439\n",
      "Epoch 486/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6739 - acc: 0.3889 - val_loss: 1.3533 - val_acc: 0.5351\n",
      "Epoch 487/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6956 - acc: 0.3962 - val_loss: 1.3223 - val_acc: 0.5292\n",
      "Epoch 488/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7359 - acc: 0.3874 - val_loss: 1.3203 - val_acc: 0.5263\n",
      "Epoch 489/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7062 - acc: 0.3787 - val_loss: 1.3113 - val_acc: 0.5409\n",
      "Epoch 490/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6598 - acc: 0.3904 - val_loss: 1.3115 - val_acc: 0.5292\n",
      "Epoch 491/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6485 - acc: 0.4020 - val_loss: 1.3026 - val_acc: 0.5175\n",
      "Epoch 492/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7164 - acc: 0.3874 - val_loss: 1.3120 - val_acc: 0.5351\n",
      "Epoch 493/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6361 - acc: 0.4211 - val_loss: 1.3223 - val_acc: 0.5322\n",
      "Epoch 494/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 1.6209 - acc: 0.3728 - val_loss: 1.3086 - val_acc: 0.5234\n",
      "Epoch 495/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6592 - acc: 0.4181 - val_loss: 1.3189 - val_acc: 0.5468\n",
      "Epoch 496/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6497 - acc: 0.3830 - val_loss: 1.3024 - val_acc: 0.5409\n",
      "Epoch 497/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6610 - acc: 0.4371 - val_loss: 1.2898 - val_acc: 0.5351\n",
      "Epoch 498/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7086 - acc: 0.3947 - val_loss: 1.2936 - val_acc: 0.5292\n",
      "Epoch 499/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6876 - acc: 0.3962 - val_loss: 1.3199 - val_acc: 0.5468\n",
      "Epoch 500/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7265 - acc: 0.4050 - val_loss: 1.3207 - val_acc: 0.5439\n",
      "Epoch 501/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7379 - acc: 0.3860 - val_loss: 1.3143 - val_acc: 0.5351\n",
      "Epoch 502/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7514 - acc: 0.3860 - val_loss: 1.3155 - val_acc: 0.5409\n",
      "Epoch 503/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7002 - acc: 0.3845 - val_loss: 1.2919 - val_acc: 0.5380\n",
      "Epoch 504/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6958 - acc: 0.3933 - val_loss: 1.2990 - val_acc: 0.5234\n",
      "Epoch 505/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6992 - acc: 0.3713 - val_loss: 1.3190 - val_acc: 0.5380\n",
      "Epoch 506/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6501 - acc: 0.3830 - val_loss: 1.3105 - val_acc: 0.5263\n",
      "Epoch 507/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6631 - acc: 0.3699 - val_loss: 1.3076 - val_acc: 0.5234\n",
      "Epoch 508/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6534 - acc: 0.4064 - val_loss: 1.2699 - val_acc: 0.5380\n",
      "Epoch 509/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6526 - acc: 0.3830 - val_loss: 1.2859 - val_acc: 0.5322\n",
      "Epoch 510/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7749 - acc: 0.3816 - val_loss: 1.2852 - val_acc: 0.5409\n",
      "Epoch 511/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6858 - acc: 0.3947 - val_loss: 1.2954 - val_acc: 0.5117\n",
      "Epoch 512/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6942 - acc: 0.3816 - val_loss: 1.2915 - val_acc: 0.5351\n",
      "Epoch 513/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6759 - acc: 0.4196 - val_loss: 1.2890 - val_acc: 0.5380\n",
      "Epoch 514/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7412 - acc: 0.3772 - val_loss: 1.3006 - val_acc: 0.5292\n",
      "Epoch 515/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7284 - acc: 0.3904 - val_loss: 1.3113 - val_acc: 0.5322\n",
      "Epoch 516/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7151 - acc: 0.3904 - val_loss: 1.2939 - val_acc: 0.5380\n",
      "Epoch 517/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7326 - acc: 0.4020 - val_loss: 1.3015 - val_acc: 0.5205\n",
      "Epoch 518/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6515 - acc: 0.4211 - val_loss: 1.3014 - val_acc: 0.5263\n",
      "Epoch 519/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6722 - acc: 0.3918 - val_loss: 1.3036 - val_acc: 0.5292\n",
      "Epoch 520/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7123 - acc: 0.3889 - val_loss: 1.3108 - val_acc: 0.5322\n",
      "Epoch 521/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6821 - acc: 0.3947 - val_loss: 1.2965 - val_acc: 0.5380\n",
      "Epoch 522/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6243 - acc: 0.3962 - val_loss: 1.2895 - val_acc: 0.5497\n",
      "Epoch 523/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6601 - acc: 0.3743 - val_loss: 1.2949 - val_acc: 0.5673\n",
      "Epoch 524/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6959 - acc: 0.4064 - val_loss: 1.2933 - val_acc: 0.5585\n",
      "Epoch 525/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6987 - acc: 0.3977 - val_loss: 1.3204 - val_acc: 0.5380\n",
      "Epoch 526/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6905 - acc: 0.3713 - val_loss: 1.3131 - val_acc: 0.5497\n",
      "Epoch 527/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7081 - acc: 0.3772 - val_loss: 1.3023 - val_acc: 0.5409\n",
      "Epoch 528/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6771 - acc: 0.4225 - val_loss: 1.3123 - val_acc: 0.5614\n",
      "Epoch 529/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7195 - acc: 0.3728 - val_loss: 1.3296 - val_acc: 0.5322\n",
      "Epoch 530/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6933 - acc: 0.3962 - val_loss: 1.3182 - val_acc: 0.5263\n",
      "Epoch 531/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6876 - acc: 0.3889 - val_loss: 1.3125 - val_acc: 0.5175\n",
      "Epoch 532/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7330 - acc: 0.3494 - val_loss: 1.3189 - val_acc: 0.5292\n",
      "Epoch 533/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6553 - acc: 0.3801 - val_loss: 1.3042 - val_acc: 0.5263\n",
      "Epoch 534/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7255 - acc: 0.3728 - val_loss: 1.3156 - val_acc: 0.5351\n",
      "Epoch 535/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7806 - acc: 0.3787 - val_loss: 1.3391 - val_acc: 0.5263\n",
      "Epoch 536/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7533 - acc: 0.3670 - val_loss: 1.3452 - val_acc: 0.5205\n",
      "Epoch 537/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6991 - acc: 0.4079 - val_loss: 1.3254 - val_acc: 0.5234\n",
      "Epoch 538/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6561 - acc: 0.3977 - val_loss: 1.3090 - val_acc: 0.5409\n",
      "Epoch 539/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6708 - acc: 0.4079 - val_loss: 1.2947 - val_acc: 0.5468\n",
      "Epoch 540/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7522 - acc: 0.4050 - val_loss: 1.3065 - val_acc: 0.5468\n",
      "Epoch 541/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6979 - acc: 0.3962 - val_loss: 1.3172 - val_acc: 0.5322\n",
      "Epoch 542/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6504 - acc: 0.4035 - val_loss: 1.3104 - val_acc: 0.5322\n",
      "Epoch 543/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7450 - acc: 0.3757 - val_loss: 1.3235 - val_acc: 0.5263\n",
      "Epoch 544/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6841 - acc: 0.3684 - val_loss: 1.3101 - val_acc: 0.5439\n",
      "Epoch 545/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6740 - acc: 0.4108 - val_loss: 1.2970 - val_acc: 0.5380\n",
      "Epoch 546/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6889 - acc: 0.3918 - val_loss: 1.2967 - val_acc: 0.5439\n",
      "Epoch 547/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6596 - acc: 0.4006 - val_loss: 1.3145 - val_acc: 0.5351\n",
      "Epoch 548/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7031 - acc: 0.3845 - val_loss: 1.3083 - val_acc: 0.5556\n",
      "Epoch 549/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6168 - acc: 0.3962 - val_loss: 1.2971 - val_acc: 0.5322\n",
      "Epoch 550/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6927 - acc: 0.3933 - val_loss: 1.3002 - val_acc: 0.5439\n",
      "Epoch 551/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6580 - acc: 0.4211 - val_loss: 1.3023 - val_acc: 0.5468\n",
      "Epoch 552/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6491 - acc: 0.3889 - val_loss: 1.2996 - val_acc: 0.5409\n",
      "Epoch 553/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7188 - acc: 0.3977 - val_loss: 1.3149 - val_acc: 0.5380\n",
      "Epoch 554/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6656 - acc: 0.4094 - val_loss: 1.2925 - val_acc: 0.5263\n",
      "Epoch 555/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6916 - acc: 0.3904 - val_loss: 1.2849 - val_acc: 0.5439\n",
      "Epoch 556/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6460 - acc: 0.4020 - val_loss: 1.2549 - val_acc: 0.5351\n",
      "Epoch 557/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6763 - acc: 0.3713 - val_loss: 1.2787 - val_acc: 0.5292\n",
      "Epoch 558/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6975 - acc: 0.3772 - val_loss: 1.3085 - val_acc: 0.5175\n",
      "Epoch 559/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6712 - acc: 0.4123 - val_loss: 1.2865 - val_acc: 0.5175\n",
      "Epoch 560/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6202 - acc: 0.4240 - val_loss: 1.2848 - val_acc: 0.5263\n",
      "Epoch 561/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6649 - acc: 0.3830 - val_loss: 1.2809 - val_acc: 0.5351\n",
      "Epoch 562/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6406 - acc: 0.3684 - val_loss: 1.2836 - val_acc: 0.5175\n",
      "Epoch 563/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6290 - acc: 0.4108 - val_loss: 1.2838 - val_acc: 0.5234\n",
      "Epoch 564/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7432 - acc: 0.3962 - val_loss: 1.3049 - val_acc: 0.5175\n",
      "Epoch 565/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6749 - acc: 0.3830 - val_loss: 1.3088 - val_acc: 0.5058\n",
      "Epoch 566/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7338 - acc: 0.3845 - val_loss: 1.3130 - val_acc: 0.5351\n",
      "Epoch 567/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7536 - acc: 0.4064 - val_loss: 1.2928 - val_acc: 0.5439\n",
      "Epoch 568/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6964 - acc: 0.4269 - val_loss: 1.3090 - val_acc: 0.5351\n",
      "Epoch 569/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6607 - acc: 0.4342 - val_loss: 1.3125 - val_acc: 0.5146\n",
      "Epoch 570/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7371 - acc: 0.3933 - val_loss: 1.3239 - val_acc: 0.5292\n",
      "Epoch 571/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7073 - acc: 0.4006 - val_loss: 1.2899 - val_acc: 0.5380\n",
      "Epoch 572/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6138 - acc: 0.4006 - val_loss: 1.2888 - val_acc: 0.5322\n",
      "Epoch 573/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6970 - acc: 0.4006 - val_loss: 1.2933 - val_acc: 0.5205\n",
      "Epoch 574/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6477 - acc: 0.4225 - val_loss: 1.2980 - val_acc: 0.5351\n",
      "Epoch 575/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6486 - acc: 0.3933 - val_loss: 1.2961 - val_acc: 0.5351\n",
      "Epoch 576/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6679 - acc: 0.3801 - val_loss: 1.2922 - val_acc: 0.5322\n",
      "Epoch 577/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7340 - acc: 0.3743 - val_loss: 1.2920 - val_acc: 0.5439\n",
      "Epoch 578/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7337 - acc: 0.3713 - val_loss: 1.3301 - val_acc: 0.5468\n",
      "Epoch 579/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 1.7041 - acc: 0.3918 - val_loss: 1.3222 - val_acc: 0.5380\n",
      "Epoch 580/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6574 - acc: 0.3933 - val_loss: 1.3031 - val_acc: 0.5439\n",
      "Epoch 581/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7244 - acc: 0.4020 - val_loss: 1.2952 - val_acc: 0.5497\n",
      "Epoch 582/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7527 - acc: 0.3743 - val_loss: 1.3019 - val_acc: 0.5497\n",
      "Epoch 583/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7420 - acc: 0.4050 - val_loss: 1.3173 - val_acc: 0.5322\n",
      "Epoch 584/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6899 - acc: 0.4123 - val_loss: 1.3246 - val_acc: 0.5292\n",
      "Epoch 585/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6894 - acc: 0.3933 - val_loss: 1.3194 - val_acc: 0.5409\n",
      "Epoch 586/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 1.6902 - acc: 0.3640 - val_loss: 1.3166 - val_acc: 0.5263\n",
      "Epoch 587/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7032 - acc: 0.3684 - val_loss: 1.3097 - val_acc: 0.5292\n",
      "Epoch 588/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6827 - acc: 0.3904 - val_loss: 1.2958 - val_acc: 0.5292\n",
      "Epoch 589/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6417 - acc: 0.4211 - val_loss: 1.2875 - val_acc: 0.5234\n",
      "Epoch 590/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 1.6627 - acc: 0.4152 - val_loss: 1.2989 - val_acc: 0.5380\n",
      "Epoch 591/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6609 - acc: 0.4064 - val_loss: 1.3089 - val_acc: 0.5263\n",
      "Epoch 592/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6691 - acc: 0.3889 - val_loss: 1.3121 - val_acc: 0.5175\n",
      "Epoch 593/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7045 - acc: 0.3728 - val_loss: 1.3034 - val_acc: 0.5292\n",
      "Epoch 594/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7423 - acc: 0.3991 - val_loss: 1.3115 - val_acc: 0.5380\n",
      "Epoch 595/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6873 - acc: 0.4064 - val_loss: 1.3098 - val_acc: 0.5468\n",
      "Epoch 596/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6350 - acc: 0.4181 - val_loss: 1.3198 - val_acc: 0.5468\n",
      "Epoch 597/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7122 - acc: 0.3772 - val_loss: 1.3401 - val_acc: 0.5117\n",
      "Epoch 598/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6705 - acc: 0.3772 - val_loss: 1.3253 - val_acc: 0.5175\n",
      "Epoch 599/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7147 - acc: 0.3713 - val_loss: 1.3321 - val_acc: 0.5117\n",
      "Epoch 600/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 1.6863 - acc: 0.4020 - val_loss: 1.3143 - val_acc: 0.5205\n",
      "Epoch 601/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6607 - acc: 0.4313 - val_loss: 1.3051 - val_acc: 0.5351\n",
      "Epoch 602/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6771 - acc: 0.4035 - val_loss: 1.3263 - val_acc: 0.5322\n",
      "Epoch 603/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7119 - acc: 0.3699 - val_loss: 1.3203 - val_acc: 0.5205\n",
      "Epoch 604/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7217 - acc: 0.3787 - val_loss: 1.3101 - val_acc: 0.5292\n",
      "Epoch 605/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6829 - acc: 0.3991 - val_loss: 1.3066 - val_acc: 0.5380\n",
      "Epoch 606/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6742 - acc: 0.3640 - val_loss: 1.3167 - val_acc: 0.5292\n",
      "Epoch 607/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7130 - acc: 0.4123 - val_loss: 1.3287 - val_acc: 0.5380\n",
      "Epoch 608/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6900 - acc: 0.3918 - val_loss: 1.3077 - val_acc: 0.5322\n",
      "Epoch 609/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7543 - acc: 0.3801 - val_loss: 1.3157 - val_acc: 0.5292\n",
      "Epoch 610/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7114 - acc: 0.3933 - val_loss: 1.3258 - val_acc: 0.5409\n",
      "Epoch 611/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6822 - acc: 0.3655 - val_loss: 1.3097 - val_acc: 0.5322\n",
      "Epoch 612/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7007 - acc: 0.4020 - val_loss: 1.3081 - val_acc: 0.5263\n",
      "Epoch 613/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7013 - acc: 0.4006 - val_loss: 1.3130 - val_acc: 0.5263\n",
      "Epoch 614/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7294 - acc: 0.3787 - val_loss: 1.3129 - val_acc: 0.5205\n",
      "Epoch 615/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7757 - acc: 0.3567 - val_loss: 1.3229 - val_acc: 0.5117\n",
      "Epoch 616/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 1.7176 - acc: 0.4006 - val_loss: 1.3203 - val_acc: 0.5205\n",
      "Epoch 617/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6652 - acc: 0.4152 - val_loss: 1.3129 - val_acc: 0.5117\n",
      "Epoch 618/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6887 - acc: 0.4006 - val_loss: 1.3275 - val_acc: 0.5205\n",
      "Epoch 619/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7315 - acc: 0.4137 - val_loss: 1.3235 - val_acc: 0.5292\n",
      "Epoch 620/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 1.6437 - acc: 0.3933 - val_loss: 1.3071 - val_acc: 0.5409\n",
      "Epoch 621/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 1.6599 - acc: 0.3874 - val_loss: 1.3222 - val_acc: 0.5322\n",
      "Epoch 622/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 1.7176 - acc: 0.3904 - val_loss: 1.3049 - val_acc: 0.5292\n",
      "Epoch 623/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 1.6636 - acc: 0.3962 - val_loss: 1.3053 - val_acc: 0.5175\n",
      "Epoch 624/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 1.6961 - acc: 0.3801 - val_loss: 1.3084 - val_acc: 0.5175\n",
      "Epoch 625/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6723 - acc: 0.3860 - val_loss: 1.3149 - val_acc: 0.5146\n",
      "Epoch 626/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7007 - acc: 0.3947 - val_loss: 1.3070 - val_acc: 0.5175\n",
      "Epoch 627/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 1.6442 - acc: 0.3670 - val_loss: 1.2874 - val_acc: 0.5175\n",
      "Epoch 628/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7352 - acc: 0.3933 - val_loss: 1.2923 - val_acc: 0.5146\n",
      "Epoch 629/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6795 - acc: 0.3772 - val_loss: 1.2980 - val_acc: 0.5234\n",
      "Epoch 630/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7033 - acc: 0.3845 - val_loss: 1.3185 - val_acc: 0.5292\n",
      "Epoch 631/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7320 - acc: 0.3787 - val_loss: 1.2953 - val_acc: 0.5409\n",
      "Epoch 632/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6606 - acc: 0.4240 - val_loss: 1.2950 - val_acc: 0.5234\n",
      "Epoch 633/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7186 - acc: 0.4152 - val_loss: 1.3276 - val_acc: 0.5322\n",
      "Epoch 634/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6747 - acc: 0.3830 - val_loss: 1.3161 - val_acc: 0.5263\n",
      "Epoch 635/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7246 - acc: 0.3904 - val_loss: 1.3166 - val_acc: 0.5234\n",
      "Epoch 636/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6856 - acc: 0.3845 - val_loss: 1.3273 - val_acc: 0.5146\n",
      "Epoch 637/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6540 - acc: 0.3830 - val_loss: 1.3051 - val_acc: 0.5322\n",
      "Epoch 638/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6834 - acc: 0.4137 - val_loss: 1.3034 - val_acc: 0.5263\n",
      "Epoch 639/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6279 - acc: 0.4357 - val_loss: 1.2892 - val_acc: 0.5380\n",
      "Epoch 640/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7195 - acc: 0.3728 - val_loss: 1.2888 - val_acc: 0.5351\n",
      "Epoch 641/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7129 - acc: 0.4006 - val_loss: 1.3127 - val_acc: 0.5146\n",
      "Epoch 642/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6884 - acc: 0.3830 - val_loss: 1.3134 - val_acc: 0.5205\n",
      "Epoch 643/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7048 - acc: 0.4064 - val_loss: 1.3154 - val_acc: 0.5234\n",
      "Epoch 644/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6920 - acc: 0.4020 - val_loss: 1.3148 - val_acc: 0.5234\n",
      "Epoch 645/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7304 - acc: 0.3947 - val_loss: 1.3212 - val_acc: 0.5322\n",
      "Epoch 646/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 1.6921 - acc: 0.3962 - val_loss: 1.3143 - val_acc: 0.5322\n",
      "Epoch 647/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 1.6477 - acc: 0.4254 - val_loss: 1.3137 - val_acc: 0.5263\n",
      "Epoch 648/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7766 - acc: 0.3991 - val_loss: 1.3342 - val_acc: 0.5234\n",
      "Epoch 649/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 1.6806 - acc: 0.3787 - val_loss: 1.3274 - val_acc: 0.5351\n",
      "Epoch 650/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 1.6511 - acc: 0.3947 - val_loss: 1.3183 - val_acc: 0.5292\n",
      "Epoch 651/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6828 - acc: 0.3962 - val_loss: 1.3035 - val_acc: 0.5234\n",
      "Epoch 652/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7173 - acc: 0.3845 - val_loss: 1.3118 - val_acc: 0.5146\n",
      "Epoch 653/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6652 - acc: 0.4284 - val_loss: 1.3099 - val_acc: 0.5263\n",
      "Epoch 654/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6280 - acc: 0.3962 - val_loss: 1.2943 - val_acc: 0.5351\n",
      "Epoch 655/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6908 - acc: 0.3845 - val_loss: 1.2913 - val_acc: 0.5234\n",
      "Epoch 656/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6907 - acc: 0.3830 - val_loss: 1.2908 - val_acc: 0.5263\n",
      "Epoch 657/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7238 - acc: 0.3904 - val_loss: 1.3053 - val_acc: 0.5292\n",
      "Epoch 658/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6983 - acc: 0.3860 - val_loss: 1.3073 - val_acc: 0.5175\n",
      "Epoch 659/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 1.6700 - acc: 0.3991 - val_loss: 1.3051 - val_acc: 0.5409\n",
      "Epoch 660/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 1.6399 - acc: 0.4123 - val_loss: 1.2874 - val_acc: 0.5351\n",
      "Epoch 661/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7219 - acc: 0.3889 - val_loss: 1.3031 - val_acc: 0.5146\n",
      "Epoch 662/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6960 - acc: 0.3860 - val_loss: 1.3079 - val_acc: 0.5292\n",
      "Epoch 663/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6373 - acc: 0.4035 - val_loss: 1.2930 - val_acc: 0.5292\n",
      "Epoch 664/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6181 - acc: 0.4094 - val_loss: 1.2975 - val_acc: 0.5205\n",
      "Epoch 665/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6735 - acc: 0.3860 - val_loss: 1.2793 - val_acc: 0.5234\n",
      "Epoch 666/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6954 - acc: 0.3933 - val_loss: 1.2839 - val_acc: 0.5380\n",
      "Epoch 667/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 1.6896 - acc: 0.4123 - val_loss: 1.2883 - val_acc: 0.5351\n",
      "Epoch 668/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6457 - acc: 0.4313 - val_loss: 1.2695 - val_acc: 0.5380\n",
      "Epoch 669/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7151 - acc: 0.3947 - val_loss: 1.3000 - val_acc: 0.5351\n",
      "Epoch 670/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6676 - acc: 0.4211 - val_loss: 1.2939 - val_acc: 0.5322\n",
      "Epoch 671/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6827 - acc: 0.4211 - val_loss: 1.3075 - val_acc: 0.5234\n",
      "Epoch 672/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6183 - acc: 0.4035 - val_loss: 1.2990 - val_acc: 0.5322\n",
      "Epoch 673/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6998 - acc: 0.3626 - val_loss: 1.3062 - val_acc: 0.5322\n",
      "Epoch 674/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7010 - acc: 0.3977 - val_loss: 1.3096 - val_acc: 0.5175\n",
      "Epoch 675/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7239 - acc: 0.3933 - val_loss: 1.3160 - val_acc: 0.5409\n",
      "Epoch 676/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6612 - acc: 0.4240 - val_loss: 1.3040 - val_acc: 0.5351\n",
      "Epoch 677/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6372 - acc: 0.3845 - val_loss: 1.2910 - val_acc: 0.5175\n",
      "Epoch 678/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7453 - acc: 0.3918 - val_loss: 1.3109 - val_acc: 0.5322\n",
      "Epoch 679/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7230 - acc: 0.3830 - val_loss: 1.3213 - val_acc: 0.5234\n",
      "Epoch 680/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6316 - acc: 0.4240 - val_loss: 1.3131 - val_acc: 0.5175\n",
      "Epoch 681/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6584 - acc: 0.3845 - val_loss: 1.3079 - val_acc: 0.5117\n",
      "Epoch 682/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7146 - acc: 0.4094 - val_loss: 1.3069 - val_acc: 0.5175\n",
      "Epoch 683/1000\n",
      "684/684 [==============================] - ETA: 0s - loss: 1.6810 - acc: 0.410 - 2s 3ms/step - loss: 1.6853 - acc: 0.4094 - val_loss: 1.3001 - val_acc: 0.5234\n",
      "Epoch 684/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6911 - acc: 0.3816 - val_loss: 1.3041 - val_acc: 0.5292\n",
      "Epoch 685/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6477 - acc: 0.4181 - val_loss: 1.2896 - val_acc: 0.5526\n",
      "Epoch 686/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6229 - acc: 0.3977 - val_loss: 1.2899 - val_acc: 0.5205\n",
      "Epoch 687/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6492 - acc: 0.4123 - val_loss: 1.2919 - val_acc: 0.5497\n",
      "Epoch 688/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6584 - acc: 0.3977 - val_loss: 1.2800 - val_acc: 0.5263\n",
      "Epoch 689/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7320 - acc: 0.4006 - val_loss: 1.2936 - val_acc: 0.5351\n",
      "Epoch 690/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7063 - acc: 0.3772 - val_loss: 1.3114 - val_acc: 0.5205\n",
      "Epoch 691/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6833 - acc: 0.4123 - val_loss: 1.3115 - val_acc: 0.5175\n",
      "Epoch 692/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6220 - acc: 0.4050 - val_loss: 1.2930 - val_acc: 0.5205\n",
      "Epoch 693/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6971 - acc: 0.4006 - val_loss: 1.2987 - val_acc: 0.5175\n",
      "Epoch 694/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6860 - acc: 0.3757 - val_loss: 1.2982 - val_acc: 0.5205\n",
      "Epoch 695/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6771 - acc: 0.4006 - val_loss: 1.3058 - val_acc: 0.5146\n",
      "Epoch 696/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6652 - acc: 0.4006 - val_loss: 1.3047 - val_acc: 0.5234\n",
      "Epoch 697/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6873 - acc: 0.3933 - val_loss: 1.2905 - val_acc: 0.5351\n",
      "Epoch 698/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6114 - acc: 0.4108 - val_loss: 1.2875 - val_acc: 0.5263\n",
      "Epoch 699/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7309 - acc: 0.4050 - val_loss: 1.3009 - val_acc: 0.5322\n",
      "Epoch 700/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6773 - acc: 0.4050 - val_loss: 1.3060 - val_acc: 0.5468\n",
      "Epoch 701/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 1.6591 - acc: 0.4094 - val_loss: 1.2877 - val_acc: 0.5409\n",
      "Epoch 702/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6914 - acc: 0.4211 - val_loss: 1.3046 - val_acc: 0.5205\n",
      "Epoch 703/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6963 - acc: 0.3904 - val_loss: 1.3058 - val_acc: 0.5292\n",
      "Epoch 704/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6977 - acc: 0.4137 - val_loss: 1.3065 - val_acc: 0.5322\n",
      "Epoch 705/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6604 - acc: 0.4181 - val_loss: 1.2965 - val_acc: 0.5205\n",
      "Epoch 706/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6814 - acc: 0.4094 - val_loss: 1.3023 - val_acc: 0.5234\n",
      "Epoch 707/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7217 - acc: 0.3889 - val_loss: 1.3041 - val_acc: 0.5409\n",
      "Epoch 708/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6784 - acc: 0.4108 - val_loss: 1.2892 - val_acc: 0.5439\n",
      "Epoch 709/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6204 - acc: 0.3991 - val_loss: 1.2932 - val_acc: 0.5380\n",
      "Epoch 710/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 1.6787 - acc: 0.4108 - val_loss: 1.2956 - val_acc: 0.5322\n",
      "Epoch 711/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 1.6448 - acc: 0.4094 - val_loss: 1.2965 - val_acc: 0.5292\n",
      "Epoch 712/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 1.6722 - acc: 0.3860 - val_loss: 1.2929 - val_acc: 0.5439\n",
      "Epoch 713/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6271 - acc: 0.4094 - val_loss: 1.2935 - val_acc: 0.5380\n",
      "Epoch 714/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7079 - acc: 0.3582 - val_loss: 1.3013 - val_acc: 0.5351\n",
      "Epoch 715/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6859 - acc: 0.3918 - val_loss: 1.3086 - val_acc: 0.5234\n",
      "Epoch 716/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6724 - acc: 0.3874 - val_loss: 1.3015 - val_acc: 0.5205\n",
      "Epoch 717/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.5962 - acc: 0.4313 - val_loss: 1.3009 - val_acc: 0.5234\n",
      "Epoch 718/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6624 - acc: 0.4167 - val_loss: 1.2845 - val_acc: 0.5468\n",
      "Epoch 719/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6987 - acc: 0.4020 - val_loss: 1.3002 - val_acc: 0.5292\n",
      "Epoch 720/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6999 - acc: 0.3845 - val_loss: 1.3055 - val_acc: 0.5497\n",
      "Epoch 721/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6262 - acc: 0.3977 - val_loss: 1.2884 - val_acc: 0.5409\n",
      "Epoch 722/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.5973 - acc: 0.4137 - val_loss: 1.2921 - val_acc: 0.5526\n",
      "Epoch 723/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7340 - acc: 0.3772 - val_loss: 1.3039 - val_acc: 0.5351\n",
      "Epoch 724/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6940 - acc: 0.3816 - val_loss: 1.3088 - val_acc: 0.5292\n",
      "Epoch 725/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6834 - acc: 0.3699 - val_loss: 1.2937 - val_acc: 0.5292\n",
      "Epoch 726/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6265 - acc: 0.4020 - val_loss: 1.2828 - val_acc: 0.5409\n",
      "Epoch 727/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6147 - acc: 0.3918 - val_loss: 1.2791 - val_acc: 0.5263\n",
      "Epoch 728/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6910 - acc: 0.3977 - val_loss: 1.2913 - val_acc: 0.5351\n",
      "Epoch 729/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7227 - acc: 0.3962 - val_loss: 1.3040 - val_acc: 0.5351\n",
      "Epoch 730/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6730 - acc: 0.3918 - val_loss: 1.2866 - val_acc: 0.5380\n",
      "Epoch 731/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7188 - acc: 0.4006 - val_loss: 1.2965 - val_acc: 0.5322\n",
      "Epoch 732/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 1.7106 - acc: 0.3772 - val_loss: 1.2921 - val_acc: 0.5351\n",
      "Epoch 733/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 1.6225 - acc: 0.4020 - val_loss: 1.2780 - val_acc: 0.5409\n",
      "Epoch 734/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 1.7287 - acc: 0.3567 - val_loss: 1.2877 - val_acc: 0.5380\n",
      "Epoch 735/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 1.6640 - acc: 0.3889 - val_loss: 1.2826 - val_acc: 0.5380\n",
      "Epoch 736/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 1.6101 - acc: 0.3991 - val_loss: 1.2818 - val_acc: 0.5322\n",
      "Epoch 737/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6733 - acc: 0.3947 - val_loss: 1.2870 - val_acc: 0.5322\n",
      "Epoch 738/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6719 - acc: 0.3904 - val_loss: 1.2956 - val_acc: 0.5380\n",
      "Epoch 739/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 1.7050 - acc: 0.3801 - val_loss: 1.2988 - val_acc: 0.5351\n",
      "Epoch 740/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6726 - acc: 0.3933 - val_loss: 1.3071 - val_acc: 0.5409\n",
      "Epoch 741/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6923 - acc: 0.3816 - val_loss: 1.3022 - val_acc: 0.5351\n",
      "Epoch 742/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6223 - acc: 0.4079 - val_loss: 1.2958 - val_acc: 0.5409\n",
      "Epoch 743/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6752 - acc: 0.3918 - val_loss: 1.2966 - val_acc: 0.5351\n",
      "Epoch 744/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6745 - acc: 0.3977 - val_loss: 1.3022 - val_acc: 0.5409\n",
      "Epoch 745/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 1.6886 - acc: 0.3933 - val_loss: 1.2966 - val_acc: 0.5439\n",
      "Epoch 746/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6913 - acc: 0.4211 - val_loss: 1.2883 - val_acc: 0.5468\n",
      "Epoch 747/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6876 - acc: 0.3947 - val_loss: 1.2878 - val_acc: 0.5380\n",
      "Epoch 748/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6784 - acc: 0.4137 - val_loss: 1.2810 - val_acc: 0.5439\n",
      "Epoch 749/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6746 - acc: 0.3830 - val_loss: 1.2946 - val_acc: 0.5322\n",
      "Epoch 750/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6602 - acc: 0.4094 - val_loss: 1.2980 - val_acc: 0.5585\n",
      "Epoch 751/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6991 - acc: 0.3772 - val_loss: 1.2991 - val_acc: 0.5468\n",
      "Epoch 752/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6866 - acc: 0.3918 - val_loss: 1.2906 - val_acc: 0.5468\n",
      "Epoch 753/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7343 - acc: 0.4064 - val_loss: 1.2732 - val_acc: 0.5468\n",
      "Epoch 754/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6758 - acc: 0.4020 - val_loss: 1.2830 - val_acc: 0.5526\n",
      "Epoch 755/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6532 - acc: 0.4211 - val_loss: 1.2917 - val_acc: 0.5439\n",
      "Epoch 756/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.6588 - acc: 0.3801 - val_loss: 1.2824 - val_acc: 0.5497\n",
      "Epoch 757/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.6884 - acc: 0.4137 - val_loss: 1.2799 - val_acc: 0.5439\n",
      "Epoch 758/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.6963 - acc: 0.4108 - val_loss: 1.2818 - val_acc: 0.5439\n",
      "Epoch 759/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.7106 - acc: 0.3904 - val_loss: 1.2988 - val_acc: 0.5468\n",
      "Epoch 760/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.6670 - acc: 0.3860 - val_loss: 1.2968 - val_acc: 0.5409\n",
      "Epoch 761/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.6769 - acc: 0.3845 - val_loss: 1.2820 - val_acc: 0.5497\n",
      "Epoch 762/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.7576 - acc: 0.3933 - val_loss: 1.2966 - val_acc: 0.5497\n",
      "Epoch 763/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.6681 - acc: 0.4181 - val_loss: 1.2888 - val_acc: 0.5526\n",
      "Epoch 764/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.6602 - acc: 0.3904 - val_loss: 1.2912 - val_acc: 0.5556\n",
      "Epoch 765/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.6155 - acc: 0.4225 - val_loss: 1.2896 - val_acc: 0.5351\n",
      "Epoch 766/1000\n",
      "684/684 [==============================] - 4s 5ms/step - loss: 1.7090 - acc: 0.3977 - val_loss: 1.2998 - val_acc: 0.5497\n",
      "Epoch 767/1000\n",
      "684/684 [==============================] - 4s 6ms/step - loss: 1.6692 - acc: 0.3933 - val_loss: 1.2995 - val_acc: 0.5526\n",
      "Epoch 768/1000\n",
      "684/684 [==============================] - 4s 5ms/step - loss: 1.5954 - acc: 0.4064 - val_loss: 1.2949 - val_acc: 0.5439\n",
      "Epoch 769/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.7116 - acc: 0.3991 - val_loss: 1.2978 - val_acc: 0.5526\n",
      "Epoch 770/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.6773 - acc: 0.4079 - val_loss: 1.2883 - val_acc: 0.5468\n",
      "Epoch 771/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.6692 - acc: 0.4079 - val_loss: 1.2978 - val_acc: 0.5468\n",
      "Epoch 772/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.6794 - acc: 0.4050 - val_loss: 1.2782 - val_acc: 0.5439\n",
      "Epoch 773/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.6387 - acc: 0.4050 - val_loss: 1.2843 - val_acc: 0.5468\n",
      "Epoch 774/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.6840 - acc: 0.4064 - val_loss: 1.2887 - val_acc: 0.5439\n",
      "Epoch 775/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.6524 - acc: 0.3904 - val_loss: 1.2812 - val_acc: 0.5439\n",
      "Epoch 776/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.6495 - acc: 0.4050 - val_loss: 1.2705 - val_acc: 0.5322\n",
      "Epoch 777/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.6610 - acc: 0.3860 - val_loss: 1.2742 - val_acc: 0.5409\n",
      "Epoch 778/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.7067 - acc: 0.4094 - val_loss: 1.2908 - val_acc: 0.5263\n",
      "Epoch 779/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.7315 - acc: 0.3918 - val_loss: 1.2911 - val_acc: 0.5234\n",
      "Epoch 780/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.6725 - acc: 0.4123 - val_loss: 1.2766 - val_acc: 0.5322\n",
      "Epoch 781/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 3s 5ms/step - loss: 1.6832 - acc: 0.3947 - val_loss: 1.2855 - val_acc: 0.5351\n",
      "Epoch 782/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.6500 - acc: 0.3889 - val_loss: 1.2806 - val_acc: 0.5439\n",
      "Epoch 783/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.7172 - acc: 0.3962 - val_loss: 1.2714 - val_acc: 0.5468 1.7196 - acc: 0.39 - ETA: 0s - loss: 1.6945 - acc: 0.40\n",
      "Epoch 784/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.7113 - acc: 0.3728 - val_loss: 1.2763 - val_acc: 0.5380\n",
      "Epoch 785/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.6410 - acc: 0.4094 - val_loss: 1.2710 - val_acc: 0.5468\n",
      "Epoch 786/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.6503 - acc: 0.4020 - val_loss: 1.2703 - val_acc: 0.5439\n",
      "Epoch 787/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.6936 - acc: 0.3874 - val_loss: 1.2844 - val_acc: 0.5292\n",
      "Epoch 788/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.7136 - acc: 0.3845 - val_loss: 1.2813 - val_acc: 0.5380\n",
      "Epoch 789/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.6736 - acc: 0.3977 - val_loss: 1.2814 - val_acc: 0.5380\n",
      "Epoch 790/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.6726 - acc: 0.4006 - val_loss: 1.2702 - val_acc: 0.5409\n",
      "Epoch 791/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.7280 - acc: 0.4108 - val_loss: 1.2789 - val_acc: 0.5292\n",
      "Epoch 792/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.6358 - acc: 0.3787 - val_loss: 1.2625 - val_acc: 0.5526ss: 1.\n",
      "Epoch 793/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6534 - acc: 0.4254 - val_loss: 1.2650 - val_acc: 0.5351\n",
      "Epoch 794/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.6740 - acc: 0.4196 - val_loss: 1.2666 - val_acc: 0.5439\n",
      "Epoch 795/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.6680 - acc: 0.4094 - val_loss: 1.2726 - val_acc: 0.5322\n",
      "Epoch 796/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.6556 - acc: 0.4050 - val_loss: 1.2680 - val_acc: 0.5263\n",
      "Epoch 797/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.6478 - acc: 0.4123 - val_loss: 1.2762 - val_acc: 0.5263\n",
      "Epoch 798/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.7384 - acc: 0.3772 - val_loss: 1.2739 - val_acc: 0.5439\n",
      "Epoch 799/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.6966 - acc: 0.3801 - val_loss: 1.2917 - val_acc: 0.5322\n",
      "Epoch 800/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.7009 - acc: 0.3933 - val_loss: 1.2814 - val_acc: 0.5409\n",
      "Epoch 801/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.6300 - acc: 0.4064 - val_loss: 1.2866 - val_acc: 0.5351\n",
      "Epoch 802/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.6590 - acc: 0.4094 - val_loss: 1.2892 - val_acc: 0.5497\n",
      "Epoch 803/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6389 - acc: 0.3889 - val_loss: 1.2951 - val_acc: 0.5292\n",
      "Epoch 804/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6542 - acc: 0.4371 - val_loss: 1.3013 - val_acc: 0.5351\n",
      "Epoch 805/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6299 - acc: 0.4050 - val_loss: 1.2947 - val_acc: 0.5380\n",
      "Epoch 806/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6595 - acc: 0.3962 - val_loss: 1.2855 - val_acc: 0.5380\n",
      "Epoch 807/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6661 - acc: 0.4050 - val_loss: 1.2927 - val_acc: 0.5175\n",
      "Epoch 808/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6522 - acc: 0.4181 - val_loss: 1.2920 - val_acc: 0.5380\n",
      "Epoch 809/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6814 - acc: 0.4006 - val_loss: 1.2961 - val_acc: 0.5205\n",
      "Epoch 810/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6455 - acc: 0.4152 - val_loss: 1.2941 - val_acc: 0.5146\n",
      "Epoch 811/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6766 - acc: 0.3860 - val_loss: 1.2915 - val_acc: 0.5205\n",
      "Epoch 812/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6851 - acc: 0.3801 - val_loss: 1.2839 - val_acc: 0.5380\n",
      "Epoch 813/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6726 - acc: 0.4006 - val_loss: 1.2794 - val_acc: 0.5292\n",
      "Epoch 814/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6970 - acc: 0.3962 - val_loss: 1.2835 - val_acc: 0.5439\n",
      "Epoch 815/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6881 - acc: 0.4079 - val_loss: 1.2855 - val_acc: 0.5380\n",
      "Epoch 816/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7112 - acc: 0.4094 - val_loss: 1.2795 - val_acc: 0.5468\n",
      "Epoch 817/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6428 - acc: 0.4196 - val_loss: 1.2863 - val_acc: 0.5468\n",
      "Epoch 818/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6469 - acc: 0.3962 - val_loss: 1.2893 - val_acc: 0.5556\n",
      "Epoch 819/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7046 - acc: 0.3787 - val_loss: 1.2922 - val_acc: 0.5497\n",
      "Epoch 820/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6867 - acc: 0.3918 - val_loss: 1.2881 - val_acc: 0.5497\n",
      "Epoch 821/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7260 - acc: 0.3918 - val_loss: 1.2920 - val_acc: 0.5351\n",
      "Epoch 822/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7401 - acc: 0.3640 - val_loss: 1.2868 - val_acc: 0.5497\n",
      "Epoch 823/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7050 - acc: 0.4181 - val_loss: 1.2911 - val_acc: 0.5292\n",
      "Epoch 824/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6639 - acc: 0.4006 - val_loss: 1.2952 - val_acc: 0.5439\n",
      "Epoch 825/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6448 - acc: 0.4152 - val_loss: 1.2898 - val_acc: 0.5351\n",
      "Epoch 826/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6778 - acc: 0.3801 - val_loss: 1.3029 - val_acc: 0.5380\n",
      "Epoch 827/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.6395 - acc: 0.4035 - val_loss: 1.2924 - val_acc: 0.5439\n",
      "Epoch 828/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7323 - acc: 0.3889 - val_loss: 1.2911 - val_acc: 0.5292\n",
      "Epoch 829/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6829 - acc: 0.3626 - val_loss: 1.3106 - val_acc: 0.5351\n",
      "Epoch 830/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7556 - acc: 0.3860 - val_loss: 1.3177 - val_acc: 0.5117\n",
      "Epoch 831/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6917 - acc: 0.3801 - val_loss: 1.3042 - val_acc: 0.5292\n",
      "Epoch 832/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7793 - acc: 0.3626 - val_loss: 1.3100 - val_acc: 0.5205\n",
      "Epoch 833/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7035 - acc: 0.3904 - val_loss: 1.3152 - val_acc: 0.5146\n",
      "Epoch 834/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7495 - acc: 0.3582 - val_loss: 1.3104 - val_acc: 0.5409\n",
      "Epoch 835/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7301 - acc: 0.4108 - val_loss: 1.2952 - val_acc: 0.5292\n",
      "Epoch 836/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7161 - acc: 0.3904 - val_loss: 1.3114 - val_acc: 0.5380\n",
      "Epoch 837/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7044 - acc: 0.3743 - val_loss: 1.3005 - val_acc: 0.5292\n",
      "Epoch 838/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7201 - acc: 0.3845 - val_loss: 1.3015 - val_acc: 0.5234\n",
      "Epoch 839/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7232 - acc: 0.3991 - val_loss: 1.3080 - val_acc: 0.5380\n",
      "Epoch 840/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6808 - acc: 0.4094 - val_loss: 1.3137 - val_acc: 0.5380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 841/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6719 - acc: 0.3860 - val_loss: 1.3071 - val_acc: 0.5292\n",
      "Epoch 842/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6735 - acc: 0.3816 - val_loss: 1.3034 - val_acc: 0.5175\n",
      "Epoch 843/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7298 - acc: 0.4342 - val_loss: 1.3090 - val_acc: 0.5263\n",
      "Epoch 844/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7218 - acc: 0.3626 - val_loss: 1.3031 - val_acc: 0.5292\n",
      "Epoch 845/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7147 - acc: 0.4152 - val_loss: 1.3006 - val_acc: 0.5292\n",
      "Epoch 846/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7395 - acc: 0.3874 - val_loss: 1.2954 - val_acc: 0.5380\n",
      "Epoch 847/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7008 - acc: 0.4313 - val_loss: 1.2982 - val_acc: 0.5351\n",
      "Epoch 848/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6940 - acc: 0.4006 - val_loss: 1.2945 - val_acc: 0.5468\n",
      "Epoch 849/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6764 - acc: 0.3787 - val_loss: 1.3007 - val_acc: 0.5526\n",
      "Epoch 850/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7086 - acc: 0.3889 - val_loss: 1.3122 - val_acc: 0.5526\n",
      "Epoch 851/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7098 - acc: 0.3991 - val_loss: 1.3039 - val_acc: 0.5526\n",
      "Epoch 852/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6884 - acc: 0.3991 - val_loss: 1.2981 - val_acc: 0.5556\n",
      "Epoch 853/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6975 - acc: 0.3874 - val_loss: 1.3029 - val_acc: 0.5380\n",
      "Epoch 854/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7418 - acc: 0.3757 - val_loss: 1.3132 - val_acc: 0.5263\n",
      "Epoch 855/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6971 - acc: 0.4050 - val_loss: 1.2969 - val_acc: 0.5380\n",
      "Epoch 856/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7290 - acc: 0.3904 - val_loss: 1.2947 - val_acc: 0.5614\n",
      "Epoch 857/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.8018 - acc: 0.3655 - val_loss: 1.3033 - val_acc: 0.5526\n",
      "Epoch 858/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7079 - acc: 0.3947 - val_loss: 1.3109 - val_acc: 0.5556\n",
      "Epoch 859/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7263 - acc: 0.3787 - val_loss: 1.3091 - val_acc: 0.5585\n",
      "Epoch 860/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7662 - acc: 0.4020 - val_loss: 1.3202 - val_acc: 0.5380\n",
      "Epoch 861/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7201 - acc: 0.4035 - val_loss: 1.3210 - val_acc: 0.5380\n",
      "Epoch 862/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7220 - acc: 0.3787 - val_loss: 1.3191 - val_acc: 0.5292\n",
      "Epoch 863/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7678 - acc: 0.3553 - val_loss: 1.3273 - val_acc: 0.5263\n",
      "Epoch 864/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7090 - acc: 0.4225 - val_loss: 1.3463 - val_acc: 0.5088\n",
      "Epoch 865/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6630 - acc: 0.3904 - val_loss: 1.3337 - val_acc: 0.5205\n",
      "Epoch 866/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7211 - acc: 0.4079 - val_loss: 1.3303 - val_acc: 0.5205\n",
      "Epoch 867/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7157 - acc: 0.4035 - val_loss: 1.3216 - val_acc: 0.5205\n",
      "Epoch 868/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7217 - acc: 0.3699 - val_loss: 1.3248 - val_acc: 0.5000\n",
      "Epoch 869/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6996 - acc: 0.3713 - val_loss: 1.3275 - val_acc: 0.5117\n",
      "Epoch 870/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7317 - acc: 0.3845 - val_loss: 1.3187 - val_acc: 0.5292\n",
      "Epoch 871/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6655 - acc: 0.4064 - val_loss: 1.3072 - val_acc: 0.5322\n",
      "Epoch 872/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6624 - acc: 0.3991 - val_loss: 1.3114 - val_acc: 0.5175\n",
      "Epoch 873/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6952 - acc: 0.3772 - val_loss: 1.3077 - val_acc: 0.5292\n",
      "Epoch 874/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.6879 - acc: 0.3933 - val_loss: 1.3207 - val_acc: 0.5263\n",
      "Epoch 875/1000\n",
      "684/684 [==============================] - 4s 5ms/step - loss: 1.7178 - acc: 0.3728 - val_loss: 1.3025 - val_acc: 0.5292\n",
      "Epoch 876/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7252 - acc: 0.3757 - val_loss: 1.3000 - val_acc: 0.5263\n",
      "Epoch 877/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6300 - acc: 0.4254 - val_loss: 1.2914 - val_acc: 0.5205\n",
      "Epoch 878/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6300 - acc: 0.4181 - val_loss: 1.2907 - val_acc: 0.5263\n",
      "Epoch 879/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7535 - acc: 0.3977 - val_loss: 1.2948 - val_acc: 0.5322\n",
      "Epoch 880/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.7582 - acc: 0.3743 - val_loss: 1.3073 - val_acc: 0.5175\n",
      "Epoch 881/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.6669 - acc: 0.3962 - val_loss: 1.2938 - val_acc: 0.5234\n",
      "Epoch 882/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.7144 - acc: 0.3991 - val_loss: 1.2970 - val_acc: 0.5351\n",
      "Epoch 883/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.7267 - acc: 0.3757 - val_loss: 1.2980 - val_acc: 0.5263\n",
      "Epoch 884/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.7090 - acc: 0.3816 - val_loss: 1.3120 - val_acc: 0.5380\n",
      "Epoch 885/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.6905 - acc: 0.4108 - val_loss: 1.3082 - val_acc: 0.5380\n",
      "Epoch 886/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.7130 - acc: 0.3684 - val_loss: 1.3061 - val_acc: 0.5380\n",
      "Epoch 887/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.7291 - acc: 0.3757 - val_loss: 1.3128 - val_acc: 0.5468\n",
      "Epoch 888/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.7242 - acc: 0.3860 - val_loss: 1.3144 - val_acc: 0.5292\n",
      "Epoch 889/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.7409 - acc: 0.3947 - val_loss: 1.3206 - val_acc: 0.5175\n",
      "Epoch 890/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.6977 - acc: 0.4240 - val_loss: 1.3204 - val_acc: 0.5058\n",
      "Epoch 891/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.7189 - acc: 0.3801 - val_loss: 1.3269 - val_acc: 0.5029\n",
      "Epoch 892/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.7220 - acc: 0.4137 - val_loss: 1.3214 - val_acc: 0.5088\n",
      "Epoch 893/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.6635 - acc: 0.4137 - val_loss: 1.3103 - val_acc: 0.5029\n",
      "Epoch 894/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.7424 - acc: 0.3889 - val_loss: 1.3059 - val_acc: 0.5117\n",
      "Epoch 895/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.7089 - acc: 0.3801 - val_loss: 1.3036 - val_acc: 0.5029\n",
      "Epoch 896/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.7196 - acc: 0.3670 - val_loss: 1.3173 - val_acc: 0.5175\n",
      "Epoch 897/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.6615 - acc: 0.4123 - val_loss: 1.3046 - val_acc: 0.5351\n",
      "Epoch 898/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.6884 - acc: 0.3845 - val_loss: 1.3025 - val_acc: 0.5322\n",
      "Epoch 899/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.6575 - acc: 0.3874 - val_loss: 1.3102 - val_acc: 0.5292\n",
      "Epoch 900/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.6989 - acc: 0.3962 - val_loss: 1.3183 - val_acc: 0.5234\n",
      "Epoch 901/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 3s 5ms/step - loss: 1.7120 - acc: 0.4035 - val_loss: 1.3084 - val_acc: 0.5292\n",
      "Epoch 902/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.6833 - acc: 0.4123 - val_loss: 1.3112 - val_acc: 0.5175\n",
      "Epoch 903/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7179 - acc: 0.3860 - val_loss: 1.3052 - val_acc: 0.5205\n",
      "Epoch 904/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.6529 - acc: 0.4020 - val_loss: 1.3041 - val_acc: 0.5439\n",
      "Epoch 905/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6421 - acc: 0.4079 - val_loss: 1.3049 - val_acc: 0.5292\n",
      "Epoch 906/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7026 - acc: 0.4064 - val_loss: 1.3070 - val_acc: 0.5322\n",
      "Epoch 907/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.7428 - acc: 0.3845 - val_loss: 1.3110 - val_acc: 0.5205\n",
      "Epoch 908/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.6803 - acc: 0.4035 - val_loss: 1.3194 - val_acc: 0.5146\n",
      "Epoch 909/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.6773 - acc: 0.3845 - val_loss: 1.3200 - val_acc: 0.5234\n",
      "Epoch 910/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.6561 - acc: 0.3933 - val_loss: 1.2988 - val_acc: 0.5351\n",
      "Epoch 911/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.7422 - acc: 0.3845 - val_loss: 1.2860 - val_acc: 0.5409\n",
      "Epoch 912/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.7111 - acc: 0.3991 - val_loss: 1.2962 - val_acc: 0.5234\n",
      "Epoch 913/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.6689 - acc: 0.3787 - val_loss: 1.3075 - val_acc: 0.5088\n",
      "Epoch 914/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.7594 - acc: 0.3757 - val_loss: 1.3240 - val_acc: 0.5117\n",
      "Epoch 915/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.7066 - acc: 0.3977 - val_loss: 1.3220 - val_acc: 0.5058\n",
      "Epoch 916/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.7310 - acc: 0.3757 - val_loss: 1.3284 - val_acc: 0.5263\n",
      "Epoch 917/1000\n",
      "684/684 [==============================] - 4s 6ms/step - loss: 1.7304 - acc: 0.3699 - val_loss: 1.3177 - val_acc: 0.5205\n",
      "Epoch 918/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.6981 - acc: 0.4123 - val_loss: 1.3209 - val_acc: 0.5263\n",
      "Epoch 919/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6632 - acc: 0.4094 - val_loss: 1.3109 - val_acc: 0.5205\n",
      "Epoch 920/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7556 - acc: 0.3699 - val_loss: 1.3168 - val_acc: 0.5263\n",
      "Epoch 921/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6856 - acc: 0.3743 - val_loss: 1.3110 - val_acc: 0.5263\n",
      "Epoch 922/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.8032 - acc: 0.3816 - val_loss: 1.3210 - val_acc: 0.5205\n",
      "Epoch 923/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7026 - acc: 0.3787 - val_loss: 1.3209 - val_acc: 0.5205\n",
      "Epoch 924/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7203 - acc: 0.3684 - val_loss: 1.3124 - val_acc: 0.5322\n",
      "Epoch 925/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7032 - acc: 0.3947 - val_loss: 1.3184 - val_acc: 0.5234\n",
      "Epoch 926/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6734 - acc: 0.4035 - val_loss: 1.3144 - val_acc: 0.5175\n",
      "Epoch 927/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7286 - acc: 0.3962 - val_loss: 1.3151 - val_acc: 0.5175\n",
      "Epoch 928/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6880 - acc: 0.4386 - val_loss: 1.3239 - val_acc: 0.5263\n",
      "Epoch 929/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7778 - acc: 0.3523 - val_loss: 1.3142 - val_acc: 0.5409\n",
      "Epoch 930/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7445 - acc: 0.3918 - val_loss: 1.3306 - val_acc: 0.5322\n",
      "Epoch 931/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7038 - acc: 0.3699 - val_loss: 1.3223 - val_acc: 0.5322\n",
      "Epoch 932/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.7252 - acc: 0.3947 - val_loss: 1.3146 - val_acc: 0.5468\n",
      "Epoch 933/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6798 - acc: 0.4050 - val_loss: 1.3123 - val_acc: 0.5292\n",
      "Epoch 934/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6802 - acc: 0.4254 - val_loss: 1.3119 - val_acc: 0.5292\n",
      "Epoch 935/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7138 - acc: 0.3787 - val_loss: 1.3074 - val_acc: 0.5322\n",
      "Epoch 936/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7317 - acc: 0.3743 - val_loss: 1.3136 - val_acc: 0.5263\n",
      "Epoch 937/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7379 - acc: 0.3596 - val_loss: 1.3113 - val_acc: 0.5439\n",
      "Epoch 938/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6943 - acc: 0.4035 - val_loss: 1.3120 - val_acc: 0.5351\n",
      "Epoch 939/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6470 - acc: 0.4225 - val_loss: 1.3099 - val_acc: 0.5409\n",
      "Epoch 940/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7151 - acc: 0.4152 - val_loss: 1.3069 - val_acc: 0.5439\n",
      "Epoch 941/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6968 - acc: 0.3845 - val_loss: 1.3056 - val_acc: 0.5409\n",
      "Epoch 942/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6494 - acc: 0.3947 - val_loss: 1.3025 - val_acc: 0.5468\n",
      "Epoch 943/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7134 - acc: 0.4020 - val_loss: 1.3031 - val_acc: 0.5322\n",
      "Epoch 944/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6780 - acc: 0.3874 - val_loss: 1.3068 - val_acc: 0.5380\n",
      "Epoch 945/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6811 - acc: 0.4035 - val_loss: 1.3178 - val_acc: 0.5234\n",
      "Epoch 946/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6461 - acc: 0.3947 - val_loss: 1.3106 - val_acc: 0.5380\n",
      "Epoch 947/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6956 - acc: 0.3772 - val_loss: 1.3161 - val_acc: 0.5322\n",
      "Epoch 948/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7806 - acc: 0.3889 - val_loss: 1.3218 - val_acc: 0.5263\n",
      "Epoch 949/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7295 - acc: 0.3743 - val_loss: 1.3249 - val_acc: 0.5292\n",
      "Epoch 950/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7225 - acc: 0.4035 - val_loss: 1.3297 - val_acc: 0.5292\n",
      "Epoch 951/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6579 - acc: 0.4167 - val_loss: 1.3185 - val_acc: 0.5263\n",
      "Epoch 952/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6286 - acc: 0.4137 - val_loss: 1.3054 - val_acc: 0.5263\n",
      "Epoch 953/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7117 - acc: 0.3977 - val_loss: 1.3033 - val_acc: 0.5263\n",
      "Epoch 954/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6731 - acc: 0.4459 - val_loss: 1.3068 - val_acc: 0.5409\n",
      "Epoch 955/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6414 - acc: 0.4050 - val_loss: 1.3064 - val_acc: 0.5292\n",
      "Epoch 956/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6804 - acc: 0.3977 - val_loss: 1.2981 - val_acc: 0.5380\n",
      "Epoch 957/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6606 - acc: 0.4152 - val_loss: 1.3002 - val_acc: 0.5351\n",
      "Epoch 958/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6706 - acc: 0.4006 - val_loss: 1.2941 - val_acc: 0.5292\n",
      "Epoch 959/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6738 - acc: 0.4079 - val_loss: 1.3005 - val_acc: 0.5292\n",
      "Epoch 960/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6947 - acc: 0.3977 - val_loss: 1.3071 - val_acc: 0.5234\n",
      "Epoch 961/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6914 - acc: 0.4137 - val_loss: 1.2997 - val_acc: 0.5263\n",
      "Epoch 962/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7162 - acc: 0.3918 - val_loss: 1.2919 - val_acc: 0.5263\n",
      "Epoch 963/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6733 - acc: 0.3874 - val_loss: 1.2982 - val_acc: 0.5146\n",
      "Epoch 964/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6487 - acc: 0.4269 - val_loss: 1.2885 - val_acc: 0.5205\n",
      "Epoch 965/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6369 - acc: 0.3947 - val_loss: 1.2898 - val_acc: 0.5175\n",
      "Epoch 966/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7502 - acc: 0.3743 - val_loss: 1.2937 - val_acc: 0.5409\n",
      "Epoch 967/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7030 - acc: 0.3830 - val_loss: 1.3087 - val_acc: 0.5439\n",
      "Epoch 968/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7292 - acc: 0.3670 - val_loss: 1.3060 - val_acc: 0.5292\n",
      "Epoch 969/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6390 - acc: 0.4298 - val_loss: 1.2963 - val_acc: 0.5292\n",
      "Epoch 970/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6752 - acc: 0.3816 - val_loss: 1.3098 - val_acc: 0.5439\n",
      "Epoch 971/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6476 - acc: 0.4123 - val_loss: 1.3000 - val_acc: 0.5351\n",
      "Epoch 972/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7360 - acc: 0.3816 - val_loss: 1.3004 - val_acc: 0.5322\n",
      "Epoch 973/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7032 - acc: 0.3772 - val_loss: 1.3012 - val_acc: 0.5380\n",
      "Epoch 974/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7301 - acc: 0.3830 - val_loss: 1.2986 - val_acc: 0.5351\n",
      "Epoch 975/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6695 - acc: 0.3977 - val_loss: 1.2966 - val_acc: 0.5439\n",
      "Epoch 976/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7009 - acc: 0.3977 - val_loss: 1.3015 - val_acc: 0.5175\n",
      "Epoch 977/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6778 - acc: 0.4064 - val_loss: 1.2945 - val_acc: 0.5263\n",
      "Epoch 978/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7510 - acc: 0.3845 - val_loss: 1.3055 - val_acc: 0.5380\n",
      "Epoch 979/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7274 - acc: 0.3816 - val_loss: 1.3217 - val_acc: 0.5351\n",
      "Epoch 980/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7766 - acc: 0.3757 - val_loss: 1.3163 - val_acc: 0.5234\n",
      "Epoch 981/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6566 - acc: 0.3860 - val_loss: 1.3064 - val_acc: 0.5322\n",
      "Epoch 982/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6282 - acc: 0.4064 - val_loss: 1.2984 - val_acc: 0.5234\n",
      "Epoch 983/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7025 - acc: 0.3904 - val_loss: 1.2996 - val_acc: 0.5409\n",
      "Epoch 984/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6682 - acc: 0.4035 - val_loss: 1.2917 - val_acc: 0.5439\n",
      "Epoch 985/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6902 - acc: 0.3860 - val_loss: 1.2857 - val_acc: 0.5380\n",
      "Epoch 986/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6704 - acc: 0.3962 - val_loss: 1.3015 - val_acc: 0.5292\n",
      "Epoch 987/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7102 - acc: 0.3889 - val_loss: 1.3060 - val_acc: 0.5322\n",
      "Epoch 988/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6557 - acc: 0.3933 - val_loss: 1.2901 - val_acc: 0.5380\n",
      "Epoch 989/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6844 - acc: 0.3845 - val_loss: 1.2894 - val_acc: 0.5263\n",
      "Epoch 990/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7358 - acc: 0.3845 - val_loss: 1.2924 - val_acc: 0.5468\n",
      "Epoch 991/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7099 - acc: 0.3816 - val_loss: 1.2931 - val_acc: 0.5468\n",
      "Epoch 992/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6687 - acc: 0.4167 - val_loss: 1.3009 - val_acc: 0.5409\n",
      "Epoch 993/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6541 - acc: 0.4181 - val_loss: 1.2964 - val_acc: 0.5497\n",
      "Epoch 994/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6771 - acc: 0.3918 - val_loss: 1.2830 - val_acc: 0.5439\n",
      "Epoch 995/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7626 - acc: 0.3772 - val_loss: 1.2970 - val_acc: 0.5468\n",
      "Epoch 996/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7016 - acc: 0.4006 - val_loss: 1.3008 - val_acc: 0.5468\n",
      "Epoch 997/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7061 - acc: 0.3904 - val_loss: 1.3119 - val_acc: 0.5439\n",
      "Epoch 998/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7003 - acc: 0.4108 - val_loss: 1.3117 - val_acc: 0.5526\n",
      "Epoch 999/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6585 - acc: 0.4167 - val_loss: 1.3186 - val_acc: 0.5322\n",
      "Epoch 1000/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6112 - acc: 0.4313 - val_loss: 1.3102 - val_acc: 0.5468\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train_shuffle, Y_train_shuffle,validation_data=(x_test, Y_test), epochs=1000, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "342/342 [==============================] - 0s 313us/step\n",
      "Test score: 1.31018838339\n",
      "Test accuracy: 0.546783623988\n"
     ]
    }
   ],
   "source": [
    "score, acc = model.evaluate(x_test, Y_test)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# list all data in history\n",
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nM7Pc/wGERSqbAeaoRgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a92bb35780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a92bc90ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
