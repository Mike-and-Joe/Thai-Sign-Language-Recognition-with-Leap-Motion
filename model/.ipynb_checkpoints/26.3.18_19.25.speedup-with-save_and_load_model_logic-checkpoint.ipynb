{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import GRU, Dense, Dropout, Input, concatenate\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import Adam\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# variable\n",
    "words = [\n",
    "    'come quickly', 'emergency', 'father', 'fever', 'good luck',\n",
    "    'headache', 'hello', 'help', 'hi', 'hungry',\n",
    "    'like', 'mother', 'mother_father', 'mother_mother', 'not ok',\n",
    "    'quickly', 'sorry', 'tomorrow', 'yogurt'\n",
    "]\n",
    "data_per_word = 27\n",
    "data_length = 2 * data_per_word * len(words)\n",
    "timesteps = 50\n",
    "dimensions = 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_feature(frame):\n",
    "    finger_name = ['thumb', 'index', 'middle', 'ring', 'pinky']\n",
    "#     coordinate = ['x', 'y', 'z']\n",
    "    fingertip_pos = np.zeros([2, 5, 3]) # [cooridinates x fingers]\n",
    "    feature = np.zeros([22])\n",
    "    hand_pos = np.zeros([12])\n",
    "#     finger_tip = {}\n",
    "    if 'right' in frame['hands']:\n",
    "        hand_pos[0:6] = np.array([frame['hands']['right']['hand_palm_position'][0],\n",
    "                                  frame['hands']['right']['hand_palm_position'][1],\n",
    "                                  frame['hands']['right']['hand_palm_position'][2],\n",
    "                                  frame['hands']['right']['yaw'], \n",
    "                                  frame['hands']['right']['roll'], \n",
    "                                  frame['hands']['right']['pitch']])\n",
    "        for idx, finger in enumerate(finger_name):\n",
    "#             fingertip_pos[2 + idx, :] = np.array(frame['hands']['right']['fingers'][finger]['bones']['distal']['next_joint'])\n",
    "            fingertip_pos[0, idx, :] = np.array(frame['hands']['right']['fingers'][finger]['bones']['distal']['next_joint'])\n",
    "    if 'left' in frame['hands']:\n",
    "        hand_pos[6:12] = np.array([frame['hands']['left']['hand_palm_position'][0],\n",
    "                                   frame['hands']['left']['hand_palm_position'][1],\n",
    "                                   frame['hands']['left']['hand_palm_position'][2],\n",
    "                                   frame['hands']['left']['yaw'], \n",
    "                                   frame['hands']['left']['roll'], \n",
    "                                   frame['hands']['left']['pitch']])\n",
    "#         fingertip_pos[8, :] = np.array(frame['hands']['left']['hand_palm_position'])\n",
    "        for idx, finger in enumerate(finger_name):\n",
    "#             fingertip_pos[4 + 5 + idx, :] = np.array(frame['hands']['left']['fingers'][finger]['bones']['distal']['next_joint'])\n",
    "            fingertip_pos[1, idx, :] = np.array(frame['hands']['left']['fingers'][finger]['bones']['distal']['next_joint'])\n",
    "    fingertip_pos_shift = np.roll(fingertip_pos, 1, axis=1)\n",
    "    feature[0:10] = np.linalg.norm(fingertip_pos - fingertip_pos_shift, axis=2).reshape(10)\n",
    "    feature[10:22] = hand_pos\n",
    "\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_timestep_from_data(json_data, pick_frame_every_no):\n",
    "    timestep = np.zeros([0, dimensions])\n",
    "    curr_idx = 0\n",
    "    \n",
    "    for frame_no, frame in enumerate(json_data):\n",
    "        if frame_no % pick_frame_every_no != 0 or not frame['hands']: #check if frame[hands] is null\n",
    "            continue\n",
    "        feature = get_feature(frame)\n",
    "#             for idx, fingertip_pos in enumerate(fingertips_pos):\n",
    "        timestep = np.vstack((timestep, feature))\n",
    "        curr_idx += 1\n",
    "        \n",
    "    return timestep\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_timesteps(json_data, pick_frame_every_no): \n",
    "    timesteps = np.zeros([0, dimensions])\n",
    "    for frame_no, frame in enumerate(json_data):\n",
    "        if frame_no % pick_frame_every_no != 0 or not frame['hands']:\n",
    "            continue\n",
    "        feature = get_feature(frame)\n",
    "        timesteps = np.vstack((timesteps, feature))\n",
    "    return timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_fake_speedup_timesteps_1(percent, json_data, pick_frame_every_no):\n",
    "    return get_timesteps(json_data, pick_frame_every_no*(100+percent)//100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_fake_speedup_timesteps_2(percent, old_timesteps, old_pick_frame_every_no):\n",
    "    timesteps = np.zeros([0, dimensions])\n",
    "    pick_frame_every_no = old_pick_frame_every_no*(100+percent)//100\n",
    "    timesteps_length = (old_timesteps.shape[0] * old_pick_frame_every_no) // pick_frame_every_no\n",
    "    \n",
    "    for new_index in range(1, timesteps_length):\n",
    "        start_old_index = (new_index * pick_frame_every_no) // old_pick_frame_every_no\n",
    "        x1 = old_pick_frame_every_no*start_old_index\n",
    "        x2 = old_pick_frame_every_no*(start_old_index + 1)\n",
    "        h1, h2 = old_timesteps[start_old_index : start_old_index + 2]\n",
    "        _x = (new_index * pick_frame_every_no)\n",
    "        \n",
    "        feature = ((_x-x1)/(x2-x1))*(h2-h1) + h1\n",
    "        \n",
    "        timesteps = np.vstack((timesteps, feature))\n",
    "        \n",
    "    return timesteps\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_frame = 0\n",
    "for word_no, word in enumerate(words):\n",
    "    for data_no in range(data_per_word):\n",
    "        try:\n",
    "            with open(\"./record/{}/json_{}.txt\".format(word, data_no)) as json_data:\n",
    "                json_data = json.load(json_data)\n",
    "        except Exception as s:\n",
    "            print ('error log:', s)\n",
    "        \n",
    "        if max_frame < len(json_data):\n",
    "            max_frame = len(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "speedup = 10\n",
    "pick_frame_every_no = int((max_frame * (speedup < 0 and (100-speedup)/100 or 1)) // 50 + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.zeros([0, timesteps, dimensions])\n",
    "y = np.zeros([0])\n",
    "for word_no, word in enumerate(words):\n",
    "    for data_no in range(data_per_word):\n",
    "        try:\n",
    "            with open(\"./record/{}/json_{}.txt\".format(word, data_no)) as json_data:\n",
    "                json_data = json.load(json_data)\n",
    "        except Exception as s:\n",
    "            print ('error log:', s)\n",
    "        \n",
    "        _timesteps = get_timesteps(json_data, pick_frame_every_no)\n",
    "        __timesteps = np.vstack((_timesteps, np.zeros([timesteps - _timesteps.shape[0], dimensions])))\n",
    "        x = np.vstack((x, [__timesteps]))\n",
    "        y = np.append(y, word_no)\n",
    "        \n",
    "        _timesteps = get_fake_speedup_timesteps_2(+10, _timesteps, pick_frame_every_no)\n",
    "        __timesteps = np.vstack((_timesteps, np.zeros([timesteps - _timesteps.shape[0], dimensions])))\n",
    "        x = np.vstack((x, [__timesteps]))\n",
    "        y = np.append(y, word_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_std = x.std(axis=(0,1), keepdims=True)\n",
    "x_mean = x.mean(axis=(0,1), keepdims=True)\n",
    "x_norm = (x-x_mean)/x_std\n",
    "# x_norm = (x-x_min)/(x_max-x_min)\n",
    "# x_norm = 2*(x-(x_max+x_min)/2)/(x_max-x_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = np.zeros([data_length * 2 // 3, timesteps, dimensions])\n",
    "y_train = np.zeros([data_length * 2 // 3])\n",
    "x_test = np.zeros([data_length // 3, timesteps, dimensions])\n",
    "y_test = np.zeros([data_length // 3])\n",
    "for idx in range(data_length):\n",
    "    if idx % 3 == 2:\n",
    "        x_test[idx // 3] = x_norm[idx]\n",
    "        y_test[idx // 3] = y[idx]\n",
    "    else:\n",
    "        x_train[idx - idx // 3] = x_norm[idx]\n",
    "        y_train[idx - idx // 3] = y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shuffle_train = np.arange(len(x_train))\n",
    "np.random.shuffle(shuffle_train)\n",
    "x_train_shuffle = np.zeros([data_length * 2 // 3, timesteps, dimensions])\n",
    "y_train_shuffle = np.zeros([data_length * 2 // 3])\n",
    "for idx, item in enumerate(shuffle_train):\n",
    "    x_train_shuffle[idx] = x_train[item]\n",
    "    y_train_shuffle[idx] = y_train[item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# encoding label\n",
    "Y_train_shuffle = np_utils.to_categorical(y_train_shuffle, len(words))\n",
    "Y_test = np_utils.to_categorical(y_test, len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fingers = Input(shape=(timesteps, dimensions), name='fingers')\n",
    "fingers_layers = GRU(64, activation='tanh', recurrent_activation='hard_sigmoid', dropout=0.2, recurrent_dropout=0.2)(fingers)\n",
    "fingers_layers = Dense(64, activation='relu')(fingers_layers)\n",
    "fingers_layers = Dropout(0.2)(fingers_layers)\n",
    "fingers_layers = Dense(64, activation='relu')(fingers_layers)\n",
    "fingers_layers = Dropout(0.2)(fingers_layers)\n",
    "fingers_layers = Dense(64, activation='relu')(fingers_layers)\n",
    "fingers_layers = Dropout(0.2)(fingers_layers)\n",
    "output_layer = Dense(len(words), activation='softmax')(fingers_layers)\n",
    "model = Model(inputs=fingers, outputs=output_layer)\n",
    "adam = Adam(lr=0.01, decay=0.0005)\n",
    "model.compile(optimizer=adam,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 684 samples, validate on 342 samples\n",
      "Epoch 1/1000\n",
      "684/684 [==============================] - 5s 7ms/step - loss: 2.9764 - acc: 0.0365 - val_loss: 2.9704 - val_acc: 0.0526\n",
      "Epoch 2/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 2.9563 - acc: 0.0512 - val_loss: 2.9011 - val_acc: 0.0731\n",
      "Epoch 3/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 2.9167 - acc: 0.0526 - val_loss: 2.7855 - val_acc: 0.0819\n",
      "Epoch 4/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 2.8525 - acc: 0.0804 - val_loss: 2.6644 - val_acc: 0.0965\n",
      "Epoch 5/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 2.7583 - acc: 0.0950 - val_loss: 2.6578 - val_acc: 0.1053\n",
      "Epoch 6/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 2.6759 - acc: 0.0980 - val_loss: 2.4224 - val_acc: 0.1959\n",
      "Epoch 7/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 2.5424 - acc: 0.1404 - val_loss: 2.3662 - val_acc: 0.2076\n",
      "Epoch 8/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 2.5060 - acc: 0.1433 - val_loss: 2.3301 - val_acc: 0.1901\n",
      "Epoch 9/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 2.5031 - acc: 0.1520 - val_loss: 2.2674 - val_acc: 0.2135\n",
      "Epoch 10/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 2.4759 - acc: 0.1506 - val_loss: 2.2769 - val_acc: 0.2222\n",
      "Epoch 11/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 2.4515 - acc: 0.1623 - val_loss: 2.2208 - val_acc: 0.2193\n",
      "Epoch 12/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 2.4062 - acc: 0.1579 - val_loss: 2.2471 - val_acc: 0.1901\n",
      "Epoch 13/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 2.4419 - acc: 0.1711 - val_loss: 2.2018 - val_acc: 0.1988\n",
      "Epoch 14/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 2.4146 - acc: 0.1769 - val_loss: 2.1955 - val_acc: 0.2222\n",
      "Epoch 15/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 2.3242 - acc: 0.1974 - val_loss: 2.1015 - val_acc: 0.2485\n",
      "Epoch 16/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 2.3668 - acc: 0.1798 - val_loss: 2.1378 - val_acc: 0.2164\n",
      "Epoch 17/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 2.3590 - acc: 0.1769 - val_loss: 2.1773 - val_acc: 0.2749\n",
      "Epoch 18/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 2.3605 - acc: 0.1871 - val_loss: 2.0884 - val_acc: 0.2135\n",
      "Epoch 19/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 2.3465 - acc: 0.1769 - val_loss: 2.1069 - val_acc: 0.2632\n",
      "Epoch 20/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 2.3051 - acc: 0.1930 - val_loss: 2.0504 - val_acc: 0.2076\n",
      "Epoch 21/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 2.2904 - acc: 0.1974 - val_loss: 2.0425 - val_acc: 0.2632\n",
      "Epoch 22/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 2.2211 - acc: 0.1959 - val_loss: 2.0381 - val_acc: 0.2281\n",
      "Epoch 23/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 2.2471 - acc: 0.2018 - val_loss: 2.0059 - val_acc: 0.2895\n",
      "Epoch 24/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 2.1894 - acc: 0.2383 - val_loss: 2.0157 - val_acc: 0.2544\n",
      "Epoch 25/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 2.2347 - acc: 0.2047 - val_loss: 1.9687 - val_acc: 0.2924\n",
      "Epoch 26/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 2.2768 - acc: 0.2061 - val_loss: 1.9689 - val_acc: 0.2602\n",
      "Epoch 27/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 2.2266 - acc: 0.1930 - val_loss: 1.9950 - val_acc: 0.2836\n",
      "Epoch 28/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 2.2029 - acc: 0.1959 - val_loss: 1.9368 - val_acc: 0.2924\n",
      "Epoch 29/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 2.1513 - acc: 0.2061 - val_loss: 1.9532 - val_acc: 0.2953\n",
      "Epoch 30/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 2.1472 - acc: 0.1915 - val_loss: 1.8966 - val_acc: 0.2310\n",
      "Epoch 31/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 2.1496 - acc: 0.2105 - val_loss: 1.8595 - val_acc: 0.2719\n",
      "Epoch 32/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 2.2847 - acc: 0.2135 - val_loss: 1.8999 - val_acc: 0.2924\n",
      "Epoch 33/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 2.0977 - acc: 0.2135 - val_loss: 1.8884 - val_acc: 0.2807\n",
      "Epoch 34/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 2.1306 - acc: 0.2061 - val_loss: 1.8829 - val_acc: 0.2895\n",
      "Epoch 35/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 2.1106 - acc: 0.2295 - val_loss: 1.8672 - val_acc: 0.2749\n",
      "Epoch 36/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 2.1240 - acc: 0.1857 - val_loss: 1.8382 - val_acc: 0.3333\n",
      "Epoch 37/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 2.1706 - acc: 0.2281 - val_loss: 1.9126 - val_acc: 0.2719\n",
      "Epoch 38/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 2.1333 - acc: 0.2091 - val_loss: 1.9978 - val_acc: 0.2164\n",
      "Epoch 39/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 2.1624 - acc: 0.2164 - val_loss: 1.8816 - val_acc: 0.3304\n",
      "Epoch 40/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 2.0322 - acc: 0.2383 - val_loss: 1.8008 - val_acc: 0.2836\n",
      "Epoch 41/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 2.0192 - acc: 0.2690 - val_loss: 1.7679 - val_acc: 0.2807\n",
      "Epoch 42/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 2.0293 - acc: 0.2427 - val_loss: 1.7833 - val_acc: 0.2865\n",
      "Epoch 43/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 2.0215 - acc: 0.2398 - val_loss: 1.7934 - val_acc: 0.3099\n",
      "Epoch 44/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 2.0350 - acc: 0.2368 - val_loss: 1.7587 - val_acc: 0.2778\n",
      "Epoch 45/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 2.0175 - acc: 0.2149 - val_loss: 1.8323 - val_acc: 0.3012\n",
      "Epoch 46/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 2.0199 - acc: 0.2427 - val_loss: 1.7464 - val_acc: 0.2836\n",
      "Epoch 47/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 2.0218 - acc: 0.2295 - val_loss: 1.7528 - val_acc: 0.3275\n",
      "Epoch 48/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 2.0042 - acc: 0.2325 - val_loss: 1.7802 - val_acc: 0.2661\n",
      "Epoch 49/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.9782 - acc: 0.2485 - val_loss: 1.7037 - val_acc: 0.3450\n",
      "Epoch 50/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.9562 - acc: 0.2412 - val_loss: 1.7203 - val_acc: 0.3129\n",
      "Epoch 51/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.9099 - acc: 0.2690 - val_loss: 1.6922 - val_acc: 0.3333\n",
      "Epoch 52/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.9296 - acc: 0.2573 - val_loss: 1.6814 - val_acc: 0.3275\n",
      "Epoch 53/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.9054 - acc: 0.2602 - val_loss: 1.6740 - val_acc: 0.3509\n",
      "Epoch 54/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.8989 - acc: 0.2632 - val_loss: 1.7454 - val_acc: 0.2924\n",
      "Epoch 55/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.9344 - acc: 0.2398 - val_loss: 1.6748 - val_acc: 0.3216\n",
      "Epoch 56/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.9346 - acc: 0.2544 - val_loss: 1.6693 - val_acc: 0.3129\n",
      "Epoch 57/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.9035 - acc: 0.2515 - val_loss: 1.6567 - val_acc: 0.3333\n",
      "Epoch 58/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.9802 - acc: 0.2368 - val_loss: 1.6329 - val_acc: 0.3450\n",
      "Epoch 59/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.9175 - acc: 0.2588 - val_loss: 1.6472 - val_acc: 0.3392\n",
      "Epoch 60/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.9351 - acc: 0.2193 - val_loss: 1.6211 - val_acc: 0.3450\n",
      "Epoch 61/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 3s 4ms/step - loss: 1.8497 - acc: 0.2602 - val_loss: 1.6252 - val_acc: 0.2982\n",
      "Epoch 62/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.9003 - acc: 0.2544 - val_loss: 1.6480 - val_acc: 0.2895\n",
      "Epoch 63/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.8659 - acc: 0.2588 - val_loss: 1.6417 - val_acc: 0.3216\n",
      "Epoch 64/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.8747 - acc: 0.2705 - val_loss: 1.6531 - val_acc: 0.3450\n",
      "Epoch 65/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.9002 - acc: 0.2617 - val_loss: 1.6209 - val_acc: 0.3596\n",
      "Epoch 66/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.8612 - acc: 0.2588 - val_loss: 1.5989 - val_acc: 0.3275\n",
      "Epoch 67/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.9332 - acc: 0.2632 - val_loss: 1.5969 - val_acc: 0.3421\n",
      "Epoch 68/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.9118 - acc: 0.2602 - val_loss: 1.5959 - val_acc: 0.3538\n",
      "Epoch 69/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.8073 - acc: 0.2880 - val_loss: 1.5913 - val_acc: 0.3480\n",
      "Epoch 70/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.8429 - acc: 0.2690 - val_loss: 1.5907 - val_acc: 0.3655\n",
      "Epoch 71/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.8520 - acc: 0.2939 - val_loss: 1.5803 - val_acc: 0.3655\n",
      "Epoch 72/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.8410 - acc: 0.2734 - val_loss: 1.6042 - val_acc: 0.3860\n",
      "Epoch 73/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.8542 - acc: 0.2895 - val_loss: 1.5793 - val_acc: 0.3655\n",
      "Epoch 74/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.8216 - acc: 0.2865 - val_loss: 1.5814 - val_acc: 0.3596\n",
      "Epoch 75/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.8107 - acc: 0.3070 - val_loss: 1.6069 - val_acc: 0.3655\n",
      "Epoch 76/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.8679 - acc: 0.2851 - val_loss: 1.5467 - val_acc: 0.3801\n",
      "Epoch 77/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.8400 - acc: 0.3202 - val_loss: 1.5517 - val_acc: 0.4006\n",
      "Epoch 78/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.8471 - acc: 0.2939 - val_loss: 1.5272 - val_acc: 0.3684\n",
      "Epoch 79/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7747 - acc: 0.2982 - val_loss: 1.5441 - val_acc: 0.4240\n",
      "Epoch 80/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.8704 - acc: 0.3129 - val_loss: 1.5093 - val_acc: 0.4415\n",
      "Epoch 81/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.8605 - acc: 0.3085 - val_loss: 1.5480 - val_acc: 0.4006\n",
      "Epoch 82/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.8294 - acc: 0.2939 - val_loss: 1.5294 - val_acc: 0.3947\n",
      "Epoch 83/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.8069 - acc: 0.2924 - val_loss: 1.5736 - val_acc: 0.3801\n",
      "Epoch 84/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7892 - acc: 0.3114 - val_loss: 1.4667 - val_acc: 0.4181\n",
      "Epoch 85/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7558 - acc: 0.2953 - val_loss: 1.4863 - val_acc: 0.4240\n",
      "Epoch 86/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7559 - acc: 0.3216 - val_loss: 1.4884 - val_acc: 0.4298\n",
      "Epoch 87/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7870 - acc: 0.3173 - val_loss: 1.4381 - val_acc: 0.4152\n",
      "Epoch 88/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7467 - acc: 0.3173 - val_loss: 1.4613 - val_acc: 0.4298\n",
      "Epoch 89/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7545 - acc: 0.3626 - val_loss: 1.4439 - val_acc: 0.4503\n",
      "Epoch 90/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7312 - acc: 0.3158 - val_loss: 1.4261 - val_acc: 0.4561\n",
      "Epoch 91/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7335 - acc: 0.3406 - val_loss: 1.3990 - val_acc: 0.4825\n",
      "Epoch 92/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7326 - acc: 0.3319 - val_loss: 1.4453 - val_acc: 0.4474\n",
      "Epoch 93/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7140 - acc: 0.3216 - val_loss: 1.4351 - val_acc: 0.4474\n",
      "Epoch 94/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7067 - acc: 0.3406 - val_loss: 1.4043 - val_acc: 0.4415\n",
      "Epoch 95/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6647 - acc: 0.3450 - val_loss: 1.3856 - val_acc: 0.4444\n",
      "Epoch 96/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.6757 - acc: 0.3582 - val_loss: 1.3886 - val_acc: 0.4386\n",
      "Epoch 97/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7073 - acc: 0.3289 - val_loss: 1.3907 - val_acc: 0.4620\n",
      "Epoch 98/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7266 - acc: 0.3289 - val_loss: 1.4237 - val_acc: 0.4357\n",
      "Epoch 99/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7054 - acc: 0.3436 - val_loss: 1.4029 - val_acc: 0.4503\n",
      "Epoch 100/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7046 - acc: 0.3158 - val_loss: 1.3889 - val_acc: 0.4678\n",
      "Epoch 101/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6535 - acc: 0.3699 - val_loss: 1.3649 - val_acc: 0.4678\n",
      "Epoch 102/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.6190 - acc: 0.3450 - val_loss: 1.3718 - val_acc: 0.4795\n",
      "Epoch 103/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6848 - acc: 0.3655 - val_loss: 1.3724 - val_acc: 0.4678\n",
      "Epoch 104/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6981 - acc: 0.3567 - val_loss: 1.3754 - val_acc: 0.4795\n",
      "Epoch 105/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7181 - acc: 0.3246 - val_loss: 1.3621 - val_acc: 0.4795\n",
      "Epoch 106/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.5916 - acc: 0.3713 - val_loss: 1.3156 - val_acc: 0.4942\n",
      "Epoch 107/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.6544 - acc: 0.3436 - val_loss: 1.3589 - val_acc: 0.5117\n",
      "Epoch 108/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.5896 - acc: 0.3962 - val_loss: 1.3625 - val_acc: 0.4825\n",
      "Epoch 109/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6616 - acc: 0.3991 - val_loss: 1.3683 - val_acc: 0.4678\n",
      "Epoch 110/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6451 - acc: 0.3406 - val_loss: 1.3691 - val_acc: 0.4737\n",
      "Epoch 111/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.5999 - acc: 0.3538 - val_loss: 1.2996 - val_acc: 0.4883\n",
      "Epoch 112/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.5829 - acc: 0.3845 - val_loss: 1.3337 - val_acc: 0.4912\n",
      "Epoch 113/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.6139 - acc: 0.3523 - val_loss: 1.3067 - val_acc: 0.5029\n",
      "Epoch 114/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6018 - acc: 0.3728 - val_loss: 1.2993 - val_acc: 0.5175\n",
      "Epoch 115/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.5934 - acc: 0.3523 - val_loss: 1.3505 - val_acc: 0.4649\n",
      "Epoch 116/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.5892 - acc: 0.4079 - val_loss: 1.3272 - val_acc: 0.5088\n",
      "Epoch 117/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.6617 - acc: 0.3757 - val_loss: 1.2937 - val_acc: 0.5175\n",
      "Epoch 118/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.6005 - acc: 0.3991 - val_loss: 1.3166 - val_acc: 0.4737\n",
      "Epoch 119/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6221 - acc: 0.3830 - val_loss: 1.3069 - val_acc: 0.4942\n",
      "Epoch 120/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.5788 - acc: 0.3816 - val_loss: 1.2830 - val_acc: 0.5146\n",
      "Epoch 121/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 3s 4ms/step - loss: 1.5695 - acc: 0.4020 - val_loss: 1.3088 - val_acc: 0.4766\n",
      "Epoch 122/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.5974 - acc: 0.4094 - val_loss: 1.2911 - val_acc: 0.4912\n",
      "Epoch 123/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.5935 - acc: 0.4020 - val_loss: 1.2726 - val_acc: 0.4883\n",
      "Epoch 124/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.5488 - acc: 0.3904 - val_loss: 1.2857 - val_acc: 0.4942\n",
      "Epoch 125/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6095 - acc: 0.3743 - val_loss: 1.2558 - val_acc: 0.5205\n",
      "Epoch 126/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.5847 - acc: 0.3977 - val_loss: 1.2641 - val_acc: 0.5205\n",
      "Epoch 127/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.5209 - acc: 0.3904 - val_loss: 1.2687 - val_acc: 0.4883\n",
      "Epoch 128/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.5648 - acc: 0.3947 - val_loss: 1.2732 - val_acc: 0.4649\n",
      "Epoch 129/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.5569 - acc: 0.4006 - val_loss: 1.2535 - val_acc: 0.5058\n",
      "Epoch 130/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.5190 - acc: 0.3962 - val_loss: 1.2555 - val_acc: 0.5058\n",
      "Epoch 131/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.5071 - acc: 0.4196 - val_loss: 1.2699 - val_acc: 0.4825\n",
      "Epoch 132/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.5416 - acc: 0.4050 - val_loss: 1.2510 - val_acc: 0.5263\n",
      "Epoch 133/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.5211 - acc: 0.3787 - val_loss: 1.2297 - val_acc: 0.5175\n",
      "Epoch 134/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.5184 - acc: 0.4254 - val_loss: 1.2143 - val_acc: 0.5585\n",
      "Epoch 135/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.5420 - acc: 0.4094 - val_loss: 1.2297 - val_acc: 0.5234\n",
      "Epoch 136/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.5176 - acc: 0.4079 - val_loss: 1.2256 - val_acc: 0.5263\n",
      "Epoch 137/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6009 - acc: 0.3772 - val_loss: 1.2240 - val_acc: 0.5263\n",
      "Epoch 138/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.5172 - acc: 0.4094 - val_loss: 1.1931 - val_acc: 0.5468\n",
      "Epoch 139/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.5201 - acc: 0.4123 - val_loss: 1.2344 - val_acc: 0.5175\n",
      "Epoch 140/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.4742 - acc: 0.4225 - val_loss: 1.1879 - val_acc: 0.5263\n",
      "Epoch 141/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.4970 - acc: 0.4020 - val_loss: 1.2182 - val_acc: 0.5175\n",
      "Epoch 142/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.4871 - acc: 0.3816 - val_loss: 1.2021 - val_acc: 0.5175\n",
      "Epoch 143/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.5271 - acc: 0.4181 - val_loss: 1.2062 - val_acc: 0.5380\n",
      "Epoch 144/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.4828 - acc: 0.4518 - val_loss: 1.1954 - val_acc: 0.5175\n",
      "Epoch 145/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.4987 - acc: 0.4167 - val_loss: 1.1871 - val_acc: 0.5263\n",
      "Epoch 146/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.4528 - acc: 0.4240 - val_loss: 1.2061 - val_acc: 0.5292\n",
      "Epoch 147/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.4544 - acc: 0.4518 - val_loss: 1.1680 - val_acc: 0.5526\n",
      "Epoch 148/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.4978 - acc: 0.4284 - val_loss: 1.2281 - val_acc: 0.5029\n",
      "Epoch 149/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.5157 - acc: 0.4064 - val_loss: 1.2140 - val_acc: 0.5526\n",
      "Epoch 150/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.4669 - acc: 0.4269 - val_loss: 1.1806 - val_acc: 0.5702\n",
      "Epoch 151/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.4958 - acc: 0.4284 - val_loss: 1.1752 - val_acc: 0.5439\n",
      "Epoch 152/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.4065 - acc: 0.4371 - val_loss: 1.1939 - val_acc: 0.5263\n",
      "Epoch 153/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.4675 - acc: 0.4167 - val_loss: 1.1708 - val_acc: 0.5526\n",
      "Epoch 154/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.4669 - acc: 0.4254 - val_loss: 1.1855 - val_acc: 0.5526\n",
      "Epoch 155/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.5420 - acc: 0.4284 - val_loss: 1.1821 - val_acc: 0.5439\n",
      "Epoch 156/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.4109 - acc: 0.4708 - val_loss: 1.1621 - val_acc: 0.5146\n",
      "Epoch 157/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.4829 - acc: 0.4137 - val_loss: 1.1520 - val_acc: 0.5731\n",
      "Epoch 158/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.4391 - acc: 0.4181 - val_loss: 1.1504 - val_acc: 0.5526\n",
      "Epoch 159/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.4483 - acc: 0.4430 - val_loss: 1.1738 - val_acc: 0.5643\n",
      "Epoch 160/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.4052 - acc: 0.4649 - val_loss: 1.1458 - val_acc: 0.5468\n",
      "Epoch 161/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.4600 - acc: 0.4371 - val_loss: 1.1522 - val_acc: 0.5497\n",
      "Epoch 162/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.4843 - acc: 0.4167 - val_loss: 1.1276 - val_acc: 0.6053\n",
      "Epoch 163/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.4664 - acc: 0.4488 - val_loss: 1.0993 - val_acc: 0.6053\n",
      "Epoch 164/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.4298 - acc: 0.4357 - val_loss: 1.1103 - val_acc: 0.5877\n",
      "Epoch 165/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.4256 - acc: 0.4459 - val_loss: 1.1143 - val_acc: 0.5819\n",
      "Epoch 166/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.3713 - acc: 0.4488 - val_loss: 1.1222 - val_acc: 0.5614\n",
      "Epoch 167/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.4109 - acc: 0.4459 - val_loss: 1.1217 - val_acc: 0.5760\n",
      "Epoch 168/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.3995 - acc: 0.4678 - val_loss: 1.0843 - val_acc: 0.6023\n",
      "Epoch 169/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.3877 - acc: 0.4415 - val_loss: 1.0995 - val_acc: 0.5965\n",
      "Epoch 170/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.4229 - acc: 0.4503 - val_loss: 1.1058 - val_acc: 0.5877\n",
      "Epoch 171/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.4766 - acc: 0.4488 - val_loss: 1.1080 - val_acc: 0.5819\n",
      "Epoch 172/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.4181 - acc: 0.4503 - val_loss: 1.1227 - val_acc: 0.5614\n",
      "Epoch 173/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.4147 - acc: 0.4503 - val_loss: 1.1395 - val_acc: 0.5614\n",
      "Epoch 174/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.4334 - acc: 0.4649 - val_loss: 1.1138 - val_acc: 0.6111\n",
      "Epoch 175/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.4169 - acc: 0.4401 - val_loss: 1.0911 - val_acc: 0.5848\n",
      "Epoch 176/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.4196 - acc: 0.4503 - val_loss: 1.0859 - val_acc: 0.5702\n",
      "Epoch 177/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.4335 - acc: 0.4576 - val_loss: 1.1107 - val_acc: 0.5936\n",
      "Epoch 178/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.4009 - acc: 0.4868 - val_loss: 1.1469 - val_acc: 0.5848\n",
      "Epoch 179/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.4216 - acc: 0.4298 - val_loss: 1.0889 - val_acc: 0.5906\n",
      "Epoch 180/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.3837 - acc: 0.4547 - val_loss: 1.0687 - val_acc: 0.6199\n",
      "Epoch 181/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 3s 4ms/step - loss: 1.3648 - acc: 0.4737 - val_loss: 1.0585 - val_acc: 0.6199\n",
      "Epoch 182/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.3650 - acc: 0.4561 - val_loss: 1.0848 - val_acc: 0.6140\n",
      "Epoch 183/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.3317 - acc: 0.4825 - val_loss: 1.0592 - val_acc: 0.6170\n",
      "Epoch 184/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.4138 - acc: 0.4605 - val_loss: 1.0634 - val_acc: 0.6170\n",
      "Epoch 185/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.3446 - acc: 0.4722 - val_loss: 1.0669 - val_acc: 0.5994\n",
      "Epoch 186/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.3841 - acc: 0.4810 - val_loss: 1.0549 - val_acc: 0.6316\n",
      "Epoch 187/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.3450 - acc: 0.4722 - val_loss: 1.0545 - val_acc: 0.6433\n",
      "Epoch 188/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.4004 - acc: 0.4664 - val_loss: 1.0636 - val_acc: 0.6462\n",
      "Epoch 189/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.3318 - acc: 0.4854 - val_loss: 1.0708 - val_acc: 0.6287\n",
      "Epoch 190/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.3471 - acc: 0.4766 - val_loss: 1.0687 - val_acc: 0.5965\n",
      "Epoch 191/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.3741 - acc: 0.4898 - val_loss: 1.0326 - val_acc: 0.6257\n",
      "Epoch 192/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.3915 - acc: 0.4854 - val_loss: 1.0318 - val_acc: 0.6345\n",
      "Epoch 193/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.3152 - acc: 0.4956 - val_loss: 1.0232 - val_acc: 0.6257\n",
      "Epoch 194/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.3529 - acc: 0.4678 - val_loss: 1.0349 - val_acc: 0.6316\n",
      "Epoch 195/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.3478 - acc: 0.4985 - val_loss: 1.0437 - val_acc: 0.6170\n",
      "Epoch 196/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.4029 - acc: 0.4547 - val_loss: 1.0318 - val_acc: 0.6520\n",
      "Epoch 197/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.3443 - acc: 0.4854 - val_loss: 1.0109 - val_acc: 0.6462\n",
      "Epoch 198/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.3796 - acc: 0.4971 - val_loss: 1.0086 - val_acc: 0.6462\n",
      "Epoch 199/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.2617 - acc: 0.5117 - val_loss: 1.0056 - val_acc: 0.6520\n",
      "Epoch 200/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.2848 - acc: 0.5029 - val_loss: 0.9835 - val_acc: 0.6608\n",
      "Epoch 201/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.3560 - acc: 0.4942 - val_loss: 1.0578 - val_acc: 0.6140\n",
      "Epoch 202/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.4050 - acc: 0.4415 - val_loss: 1.0030 - val_acc: 0.6579\n",
      "Epoch 203/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.3302 - acc: 0.4854 - val_loss: 0.9911 - val_acc: 0.6842\n",
      "Epoch 204/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.3050 - acc: 0.5175 - val_loss: 1.0241 - val_acc: 0.6550\n",
      "Epoch 205/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.3832 - acc: 0.4795 - val_loss: 0.9874 - val_acc: 0.6696\n",
      "Epoch 206/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.4078 - acc: 0.4649 - val_loss: 1.0230 - val_acc: 0.6491\n",
      "Epoch 207/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.3133 - acc: 0.4942 - val_loss: 0.9982 - val_acc: 0.6608\n",
      "Epoch 208/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.3119 - acc: 0.4635 - val_loss: 0.9925 - val_acc: 0.6725\n",
      "Epoch 209/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.2891 - acc: 0.5058 - val_loss: 0.9856 - val_acc: 0.6871\n",
      "Epoch 210/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.4158 - acc: 0.4868 - val_loss: 1.0351 - val_acc: 0.6520\n",
      "Epoch 211/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.3295 - acc: 0.4956 - val_loss: 1.0134 - val_acc: 0.6608\n",
      "Epoch 212/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.3584 - acc: 0.4576 - val_loss: 0.9964 - val_acc: 0.6550\n",
      "Epoch 213/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.3635 - acc: 0.4868 - val_loss: 1.0384 - val_acc: 0.6404\n",
      "Epoch 214/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.2893 - acc: 0.5073 - val_loss: 1.0269 - val_acc: 0.6404\n",
      "Epoch 215/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.2946 - acc: 0.5205 - val_loss: 0.9950 - val_acc: 0.6579\n",
      "Epoch 216/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.3597 - acc: 0.5000 - val_loss: 0.9778 - val_acc: 0.6901\n",
      "Epoch 217/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.3025 - acc: 0.5088 - val_loss: 0.9618 - val_acc: 0.6696\n",
      "Epoch 218/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.2700 - acc: 0.4927 - val_loss: 0.9862 - val_acc: 0.6813\n",
      "Epoch 219/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.3206 - acc: 0.5175 - val_loss: 0.9812 - val_acc: 0.6784\n",
      "Epoch 220/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.2742 - acc: 0.5190 - val_loss: 0.9813 - val_acc: 0.6550\n",
      "Epoch 221/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.2392 - acc: 0.5365 - val_loss: 0.9537 - val_acc: 0.6959\n",
      "Epoch 222/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.3624 - acc: 0.5146 - val_loss: 0.9565 - val_acc: 0.6725\n",
      "Epoch 223/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.2588 - acc: 0.5044 - val_loss: 0.9494 - val_acc: 0.6667\n",
      "Epoch 224/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.2850 - acc: 0.5102 - val_loss: 0.9568 - val_acc: 0.6842\n",
      "Epoch 225/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.3418 - acc: 0.5000 - val_loss: 0.9664 - val_acc: 0.6871\n",
      "Epoch 226/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.2329 - acc: 0.5263 - val_loss: 0.9648 - val_acc: 0.6579\n",
      "Epoch 227/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.2427 - acc: 0.5161 - val_loss: 0.9464 - val_acc: 0.6667\n",
      "Epoch 228/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.2810 - acc: 0.5132 - val_loss: 0.9487 - val_acc: 0.7018\n",
      "Epoch 229/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.2399 - acc: 0.5175 - val_loss: 0.9484 - val_acc: 0.6608\n",
      "Epoch 230/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.2680 - acc: 0.5263 - val_loss: 0.9655 - val_acc: 0.6579\n",
      "Epoch 231/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.3078 - acc: 0.4985 - val_loss: 0.9497 - val_acc: 0.6637\n",
      "Epoch 232/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.2242 - acc: 0.5278 - val_loss: 0.9351 - val_acc: 0.6754\n",
      "Epoch 233/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.2439 - acc: 0.5307 - val_loss: 0.9322 - val_acc: 0.6637\n",
      "Epoch 234/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.3183 - acc: 0.4942 - val_loss: 0.9333 - val_acc: 0.6988\n",
      "Epoch 235/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.2739 - acc: 0.5117 - val_loss: 0.9622 - val_acc: 0.6813\n",
      "Epoch 236/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.3189 - acc: 0.5219 - val_loss: 0.9363 - val_acc: 0.6901\n",
      "Epoch 237/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.3115 - acc: 0.4927 - val_loss: 0.9740 - val_acc: 0.6754\n",
      "Epoch 238/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.2321 - acc: 0.5175 - val_loss: 0.9379 - val_acc: 0.6725\n",
      "Epoch 239/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.2531 - acc: 0.5541 - val_loss: 0.9402 - val_acc: 0.6930\n",
      "Epoch 240/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.2384 - acc: 0.5278 - val_loss: 0.9442 - val_acc: 0.6725\n",
      "Epoch 241/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 3s 4ms/step - loss: 1.2752 - acc: 0.5146 - val_loss: 0.9439 - val_acc: 0.6696\n",
      "Epoch 242/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.1664 - acc: 0.5658 - val_loss: 0.9194 - val_acc: 0.6725\n",
      "Epoch 243/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.2576 - acc: 0.5365 - val_loss: 0.9205 - val_acc: 0.6842\n",
      "Epoch 244/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.2231 - acc: 0.5351 - val_loss: 0.8972 - val_acc: 0.7018\n",
      "Epoch 245/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.2092 - acc: 0.5439 - val_loss: 0.8797 - val_acc: 0.6988\n",
      "Epoch 246/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.1680 - acc: 0.5541 - val_loss: 0.8856 - val_acc: 0.6754\n",
      "Epoch 247/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.2202 - acc: 0.5556 - val_loss: 0.9019 - val_acc: 0.6813\n",
      "Epoch 248/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.2602 - acc: 0.5453 - val_loss: 0.8943 - val_acc: 0.6901\n",
      "Epoch 249/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.2897 - acc: 0.4927 - val_loss: 0.9241 - val_acc: 0.6725\n",
      "Epoch 250/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.2295 - acc: 0.5292 - val_loss: 0.8997 - val_acc: 0.6988\n",
      "Epoch 251/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.2727 - acc: 0.5190 - val_loss: 0.8807 - val_acc: 0.6901\n",
      "Epoch 252/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.2290 - acc: 0.5175 - val_loss: 0.8791 - val_acc: 0.7105\n",
      "Epoch 253/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.2490 - acc: 0.5263 - val_loss: 0.9039 - val_acc: 0.6988\n",
      "Epoch 254/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.1427 - acc: 0.5614 - val_loss: 0.9040 - val_acc: 0.6901\n",
      "Epoch 255/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.2910 - acc: 0.5526 - val_loss: 0.9050 - val_acc: 0.6959\n",
      "Epoch 256/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.1998 - acc: 0.5482 - val_loss: 0.8951 - val_acc: 0.7105\n",
      "Epoch 257/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.2238 - acc: 0.5482 - val_loss: 0.8957 - val_acc: 0.7135\n",
      "Epoch 258/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.2004 - acc: 0.5292 - val_loss: 0.8782 - val_acc: 0.6988\n",
      "Epoch 259/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.2380 - acc: 0.5278 - val_loss: 0.8996 - val_acc: 0.6871\n",
      "Epoch 260/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.2337 - acc: 0.5424 - val_loss: 0.8822 - val_acc: 0.7105\n",
      "Epoch 261/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.2900 - acc: 0.5409 - val_loss: 0.8762 - val_acc: 0.7105\n",
      "Epoch 262/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.1997 - acc: 0.5585 - val_loss: 0.8793 - val_acc: 0.7105\n",
      "Epoch 263/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.2573 - acc: 0.5292 - val_loss: 0.8977 - val_acc: 0.7076\n",
      "Epoch 264/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.2490 - acc: 0.5468 - val_loss: 0.8889 - val_acc: 0.6667\n",
      "Epoch 265/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.2073 - acc: 0.5541 - val_loss: 0.8891 - val_acc: 0.6813\n",
      "Epoch 266/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.2387 - acc: 0.5497 - val_loss: 0.8693 - val_acc: 0.7105\n",
      "Epoch 267/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.2236 - acc: 0.5599 - val_loss: 0.8860 - val_acc: 0.7193\n",
      "Epoch 268/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.2036 - acc: 0.5395 - val_loss: 0.8796 - val_acc: 0.7164\n",
      "Epoch 269/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.1583 - acc: 0.5585 - val_loss: 0.8820 - val_acc: 0.7076\n",
      "Epoch 270/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.1974 - acc: 0.5526 - val_loss: 0.8705 - val_acc: 0.7222\n",
      "Epoch 271/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.2042 - acc: 0.5512 - val_loss: 0.8656 - val_acc: 0.7164\n",
      "Epoch 272/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.2522 - acc: 0.5190 - val_loss: 0.8750 - val_acc: 0.7310\n",
      "Epoch 273/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.1670 - acc: 0.5673 - val_loss: 0.8653 - val_acc: 0.7222\n",
      "Epoch 274/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.1299 - acc: 0.5804 - val_loss: 0.8606 - val_acc: 0.7222\n",
      "Epoch 275/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.2018 - acc: 0.5702 - val_loss: 0.8630 - val_acc: 0.7193\n",
      "Epoch 276/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.1830 - acc: 0.5614 - val_loss: 0.8868 - val_acc: 0.7047\n",
      "Epoch 277/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.1822 - acc: 0.5687 - val_loss: 0.8598 - val_acc: 0.7251\n",
      "Epoch 278/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.1683 - acc: 0.5789 - val_loss: 0.8641 - val_acc: 0.7164\n",
      "Epoch 279/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.2431 - acc: 0.5760 - val_loss: 0.8626 - val_acc: 0.7047\n",
      "Epoch 280/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.2338 - acc: 0.5629 - val_loss: 0.8666 - val_acc: 0.7105\n",
      "Epoch 281/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.1918 - acc: 0.5512 - val_loss: 0.8753 - val_acc: 0.7105\n",
      "Epoch 282/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.2317 - acc: 0.5424 - val_loss: 0.8591 - val_acc: 0.7047\n",
      "Epoch 283/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.1913 - acc: 0.5453 - val_loss: 0.8366 - val_acc: 0.7193\n",
      "Epoch 284/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.1835 - acc: 0.5570 - val_loss: 0.8482 - val_acc: 0.7427\n",
      "Epoch 285/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.2105 - acc: 0.5746 - val_loss: 0.8425 - val_acc: 0.7193\n",
      "Epoch 286/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.1376 - acc: 0.5512 - val_loss: 0.8139 - val_acc: 0.7573\n",
      "Epoch 287/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.1805 - acc: 0.5906 - val_loss: 0.8145 - val_acc: 0.7456\n",
      "Epoch 288/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.2135 - acc: 0.5570 - val_loss: 0.8086 - val_acc: 0.7661\n",
      "Epoch 289/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.1323 - acc: 0.5906 - val_loss: 0.8082 - val_acc: 0.7544\n",
      "Epoch 290/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.2032 - acc: 0.5482 - val_loss: 0.8223 - val_acc: 0.7632\n",
      "Epoch 291/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.1061 - acc: 0.5716 - val_loss: 0.8143 - val_acc: 0.7310\n",
      "Epoch 292/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.1818 - acc: 0.5687 - val_loss: 0.8259 - val_acc: 0.7310\n",
      "Epoch 293/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.1785 - acc: 0.5716 - val_loss: 0.8227 - val_acc: 0.7310\n",
      "Epoch 294/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.1719 - acc: 0.5746 - val_loss: 0.8128 - val_acc: 0.7251\n",
      "Epoch 295/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.0734 - acc: 0.6155 - val_loss: 0.7960 - val_acc: 0.7485\n",
      "Epoch 296/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.1674 - acc: 0.5746 - val_loss: 0.7887 - val_acc: 0.7398\n",
      "Epoch 297/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.1523 - acc: 0.6053 - val_loss: 0.7751 - val_acc: 0.7749\n",
      "Epoch 298/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.1261 - acc: 0.5877 - val_loss: 0.7845 - val_acc: 0.7485\n",
      "Epoch 299/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.1271 - acc: 0.5994 - val_loss: 0.7844 - val_acc: 0.7661\n",
      "Epoch 300/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.1083 - acc: 0.5950 - val_loss: 0.7980 - val_acc: 0.7544\n",
      "Epoch 301/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 3s 4ms/step - loss: 1.1836 - acc: 0.5877 - val_loss: 0.7863 - val_acc: 0.7485\n",
      "Epoch 302/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0938 - acc: 0.5906 - val_loss: 0.7881 - val_acc: 0.7456\n",
      "Epoch 303/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0649 - acc: 0.6140 - val_loss: 0.7868 - val_acc: 0.7427\n",
      "Epoch 304/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.1537 - acc: 0.5746 - val_loss: 0.7888 - val_acc: 0.7368\n",
      "Epoch 305/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.1419 - acc: 0.5921 - val_loss: 0.7916 - val_acc: 0.7573\n",
      "Epoch 306/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.1176 - acc: 0.6199 - val_loss: 0.7740 - val_acc: 0.7602\n",
      "Epoch 307/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.1510 - acc: 0.5936 - val_loss: 0.7901 - val_acc: 0.7398\n",
      "Epoch 308/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.1431 - acc: 0.5760 - val_loss: 0.7848 - val_acc: 0.7632\n",
      "Epoch 309/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.1023 - acc: 0.5702 - val_loss: 0.7836 - val_acc: 0.7398\n",
      "Epoch 310/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.1122 - acc: 0.5863 - val_loss: 0.7734 - val_acc: 0.7544\n",
      "Epoch 311/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0804 - acc: 0.5994 - val_loss: 0.7675 - val_acc: 0.7515\n",
      "Epoch 312/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.1673 - acc: 0.6111 - val_loss: 0.7736 - val_acc: 0.7602\n",
      "Epoch 313/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.1883 - acc: 0.5804 - val_loss: 0.7806 - val_acc: 0.7602\n",
      "Epoch 314/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0805 - acc: 0.5775 - val_loss: 0.7657 - val_acc: 0.7573\n",
      "Epoch 315/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.1445 - acc: 0.5789 - val_loss: 0.7716 - val_acc: 0.7515\n",
      "Epoch 316/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.1229 - acc: 0.6096 - val_loss: 0.7642 - val_acc: 0.7485\n",
      "Epoch 317/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.1213 - acc: 0.6082 - val_loss: 0.7502 - val_acc: 0.7485\n",
      "Epoch 318/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0528 - acc: 0.6067 - val_loss: 0.7502 - val_acc: 0.7573\n",
      "Epoch 319/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0711 - acc: 0.6184 - val_loss: 0.7549 - val_acc: 0.7427\n",
      "Epoch 320/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.1024 - acc: 0.5863 - val_loss: 0.7599 - val_acc: 0.7427\n",
      "Epoch 321/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.1295 - acc: 0.5936 - val_loss: 0.7419 - val_acc: 0.7544\n",
      "Epoch 322/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.1270 - acc: 0.5921 - val_loss: 0.7519 - val_acc: 0.7602\n",
      "Epoch 323/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0626 - acc: 0.6257 - val_loss: 0.7725 - val_acc: 0.7339\n",
      "Epoch 324/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.1213 - acc: 0.6126 - val_loss: 0.7796 - val_acc: 0.7251\n",
      "Epoch 325/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.1858 - acc: 0.5658 - val_loss: 0.7752 - val_acc: 0.7339\n",
      "Epoch 326/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.1773 - acc: 0.5965 - val_loss: 0.7563 - val_acc: 0.7368\n",
      "Epoch 327/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.1662 - acc: 0.5804 - val_loss: 0.7657 - val_acc: 0.7398\n",
      "Epoch 328/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0524 - acc: 0.6257 - val_loss: 0.7593 - val_acc: 0.7485\n",
      "Epoch 329/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0820 - acc: 0.6096 - val_loss: 0.7563 - val_acc: 0.7398\n",
      "Epoch 330/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.1215 - acc: 0.6053 - val_loss: 0.7418 - val_acc: 0.7456\n",
      "Epoch 331/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0772 - acc: 0.6140 - val_loss: 0.7487 - val_acc: 0.7544\n",
      "Epoch 332/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0764 - acc: 0.6228 - val_loss: 0.7512 - val_acc: 0.7602\n",
      "Epoch 333/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0927 - acc: 0.6038 - val_loss: 0.7563 - val_acc: 0.7544\n",
      "Epoch 334/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0650 - acc: 0.6360 - val_loss: 0.7403 - val_acc: 0.7456\n",
      "Epoch 335/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9980 - acc: 0.6023 - val_loss: 0.7346 - val_acc: 0.7456\n",
      "Epoch 336/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.0761 - acc: 0.6126 - val_loss: 0.7193 - val_acc: 0.7515\n",
      "Epoch 337/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.0946 - acc: 0.6067 - val_loss: 0.7277 - val_acc: 0.7456\n",
      "Epoch 338/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.0458 - acc: 0.6096 - val_loss: 0.7233 - val_acc: 0.7485\n",
      "Epoch 339/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.0431 - acc: 0.6009 - val_loss: 0.7351 - val_acc: 0.7251\n",
      "Epoch 340/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.0991 - acc: 0.5892 - val_loss: 0.7349 - val_acc: 0.7456\n",
      "Epoch 341/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.0621 - acc: 0.6257 - val_loss: 0.7496 - val_acc: 0.7339\n",
      "Epoch 342/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.0559 - acc: 0.6404 - val_loss: 0.7352 - val_acc: 0.7456\n",
      "Epoch 343/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.0604 - acc: 0.6067 - val_loss: 0.7276 - val_acc: 0.7456\n",
      "Epoch 344/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.0644 - acc: 0.5921 - val_loss: 0.7378 - val_acc: 0.7485\n",
      "Epoch 345/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.0237 - acc: 0.6418 - val_loss: 0.7200 - val_acc: 0.7427\n",
      "Epoch 346/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.0238 - acc: 0.6257 - val_loss: 0.7222 - val_acc: 0.7544\n",
      "Epoch 347/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.0801 - acc: 0.5965 - val_loss: 0.7243 - val_acc: 0.7427\n",
      "Epoch 348/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.1006 - acc: 0.5994 - val_loss: 0.7172 - val_acc: 0.7544\n",
      "Epoch 349/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.0919 - acc: 0.6009 - val_loss: 0.7096 - val_acc: 0.7661\n",
      "Epoch 350/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.0881 - acc: 0.6243 - val_loss: 0.7119 - val_acc: 0.7573\n",
      "Epoch 351/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.2107 - acc: 0.5643 - val_loss: 0.7190 - val_acc: 0.7398\n",
      "Epoch 352/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.1303 - acc: 0.6155 - val_loss: 0.7142 - val_acc: 0.7544\n",
      "Epoch 353/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0069 - acc: 0.5936 - val_loss: 0.7039 - val_acc: 0.7544\n",
      "Epoch 354/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.0539 - acc: 0.6009 - val_loss: 0.7204 - val_acc: 0.7456\n",
      "Epoch 355/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.0186 - acc: 0.6257 - val_loss: 0.7100 - val_acc: 0.7544\n",
      "Epoch 356/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.0133 - acc: 0.6111 - val_loss: 0.7099 - val_acc: 0.7661\n",
      "Epoch 357/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.1061 - acc: 0.6111 - val_loss: 0.7113 - val_acc: 0.7456\n",
      "Epoch 358/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0033 - acc: 0.6491 - val_loss: 0.6971 - val_acc: 0.7602\n",
      "Epoch 359/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0045 - acc: 0.6418 - val_loss: 0.7005 - val_acc: 0.7485\n",
      "Epoch 360/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0872 - acc: 0.6140 - val_loss: 0.7065 - val_acc: 0.7632\n",
      "Epoch 361/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0543 - acc: 0.6082 - val_loss: 0.7180 - val_acc: 0.7515\n",
      "Epoch 362/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0719 - acc: 0.6067 - val_loss: 0.6971 - val_acc: 0.7515\n",
      "Epoch 363/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0964 - acc: 0.6053 - val_loss: 0.6994 - val_acc: 0.7544\n",
      "Epoch 364/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.1486 - acc: 0.6023 - val_loss: 0.7267 - val_acc: 0.7485\n",
      "Epoch 365/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0402 - acc: 0.6184 - val_loss: 0.7038 - val_acc: 0.7719\n",
      "Epoch 366/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0320 - acc: 0.6447 - val_loss: 0.6906 - val_acc: 0.7661\n",
      "Epoch 367/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.0521 - acc: 0.6126 - val_loss: 0.6911 - val_acc: 0.7632\n",
      "Epoch 368/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9842 - acc: 0.6243 - val_loss: 0.6850 - val_acc: 0.7690\n",
      "Epoch 369/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0550 - acc: 0.6170 - val_loss: 0.6900 - val_acc: 0.7485\n",
      "Epoch 370/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0600 - acc: 0.6053 - val_loss: 0.6920 - val_acc: 0.7310\n",
      "Epoch 371/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0115 - acc: 0.6316 - val_loss: 0.6840 - val_acc: 0.7602\n",
      "Epoch 372/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.1128 - acc: 0.5965 - val_loss: 0.6911 - val_acc: 0.7690\n",
      "Epoch 373/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0297 - acc: 0.6374 - val_loss: 0.6987 - val_acc: 0.7485\n",
      "Epoch 374/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0601 - acc: 0.6360 - val_loss: 0.6852 - val_acc: 0.7778\n",
      "Epoch 375/1000\n",
      "684/684 [==============================] - 4s 5ms/step - loss: 1.0209 - acc: 0.6491 - val_loss: 0.6830 - val_acc: 0.7427\n",
      "Epoch 376/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.0026 - acc: 0.6316 - val_loss: 0.6790 - val_acc: 0.7310\n",
      "Epoch 377/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.0028 - acc: 0.6228 - val_loss: 0.6748 - val_acc: 0.7632\n",
      "Epoch 378/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0492 - acc: 0.6170 - val_loss: 0.6804 - val_acc: 0.7632\n",
      "Epoch 379/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9843 - acc: 0.6374 - val_loss: 0.6892 - val_acc: 0.7456\n",
      "Epoch 380/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0392 - acc: 0.6170 - val_loss: 0.6891 - val_acc: 0.7661\n",
      "Epoch 381/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0559 - acc: 0.6096 - val_loss: 0.6872 - val_acc: 0.7632\n",
      "Epoch 382/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.0479 - acc: 0.6184 - val_loss: 0.6858 - val_acc: 0.7485\n",
      "Epoch 383/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.0450 - acc: 0.6257 - val_loss: 0.7093 - val_acc: 0.7573\n",
      "Epoch 384/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0221 - acc: 0.6374 - val_loss: 0.6790 - val_acc: 0.7661\n",
      "Epoch 385/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.1404 - acc: 0.6199 - val_loss: 0.7056 - val_acc: 0.7719\n",
      "Epoch 386/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9991 - acc: 0.6418 - val_loss: 0.6707 - val_acc: 0.7953\n",
      "Epoch 387/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.9619 - acc: 0.6564 - val_loss: 0.6742 - val_acc: 0.7807\n",
      "Epoch 388/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.0548 - acc: 0.6126 - val_loss: 0.6756 - val_acc: 0.7749\n",
      "Epoch 389/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0621 - acc: 0.6316 - val_loss: 0.6706 - val_acc: 0.7661\n",
      "Epoch 390/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0301 - acc: 0.6199 - val_loss: 0.6823 - val_acc: 0.7573\n",
      "Epoch 391/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0897 - acc: 0.6140 - val_loss: 0.6887 - val_acc: 0.7573\n",
      "Epoch 392/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9549 - acc: 0.6228 - val_loss: 0.6847 - val_acc: 0.7485\n",
      "Epoch 393/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0061 - acc: 0.6404 - val_loss: 0.6762 - val_acc: 0.7690\n",
      "Epoch 394/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.1146 - acc: 0.6009 - val_loss: 0.6845 - val_acc: 0.7661\n",
      "Epoch 395/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0109 - acc: 0.6477 - val_loss: 0.6881 - val_acc: 0.7749\n",
      "Epoch 396/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9998 - acc: 0.6287 - val_loss: 0.6857 - val_acc: 0.7690\n",
      "Epoch 397/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0211 - acc: 0.6462 - val_loss: 0.6802 - val_acc: 0.7836\n",
      "Epoch 398/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.0002 - acc: 0.6506 - val_loss: 0.6657 - val_acc: 0.7807\n",
      "Epoch 399/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0008 - acc: 0.6564 - val_loss: 0.6622 - val_acc: 0.7719\n",
      "Epoch 400/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0393 - acc: 0.6389 - val_loss: 0.6622 - val_acc: 0.7807\n",
      "Epoch 401/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.9850 - acc: 0.6462 - val_loss: 0.6632 - val_acc: 0.7807\n",
      "Epoch 402/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9789 - acc: 0.6389 - val_loss: 0.6600 - val_acc: 0.7895\n",
      "Epoch 403/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.9888 - acc: 0.6418 - val_loss: 0.6614 - val_acc: 0.7749\n",
      "Epoch 404/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0402 - acc: 0.6287 - val_loss: 0.6744 - val_acc: 0.7749\n",
      "Epoch 405/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0147 - acc: 0.6447 - val_loss: 0.6680 - val_acc: 0.7690A: 1s - loss: 1.0\n",
      "Epoch 406/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9653 - acc: 0.6594 - val_loss: 0.6620 - val_acc: 0.7895\n",
      "Epoch 407/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9585 - acc: 0.6433 - val_loss: 0.6534 - val_acc: 0.7836\n",
      "Epoch 408/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.0317 - acc: 0.6345 - val_loss: 0.6652 - val_acc: 0.7807\n",
      "Epoch 409/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0152 - acc: 0.6257 - val_loss: 0.6680 - val_acc: 0.7573\n",
      "Epoch 410/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0151 - acc: 0.6287 - val_loss: 0.6781 - val_acc: 0.7456\n",
      "Epoch 411/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9386 - acc: 0.6447 - val_loss: 0.6628 - val_acc: 0.7602\n",
      "Epoch 412/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9775 - acc: 0.6360 - val_loss: 0.6653 - val_acc: 0.7573\n",
      "Epoch 413/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0846 - acc: 0.6023 - val_loss: 0.6669 - val_acc: 0.7749\n",
      "Epoch 414/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.0085 - acc: 0.6213 - val_loss: 0.6714 - val_acc: 0.7807\n",
      "Epoch 415/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0009 - acc: 0.6652 - val_loss: 0.6660 - val_acc: 0.7953\n",
      "Epoch 416/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9472 - acc: 0.6608 - val_loss: 0.6554 - val_acc: 0.7895\n",
      "Epoch 417/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9478 - acc: 0.6608 - val_loss: 0.6521 - val_acc: 0.7807\n",
      "Epoch 418/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9915 - acc: 0.6272 - val_loss: 0.6432 - val_acc: 0.7836\n",
      "Epoch 419/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.0715 - acc: 0.6316 - val_loss: 0.6450 - val_acc: 0.7602\n",
      "Epoch 420/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.0013 - acc: 0.6491 - val_loss: 0.6485 - val_acc: 0.7865\n",
      "Epoch 421/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 3s 5ms/step - loss: 0.9708 - acc: 0.6784 - val_loss: 0.6543 - val_acc: 0.7690\n",
      "Epoch 422/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9806 - acc: 0.6740 - val_loss: 0.6489 - val_acc: 0.7836\n",
      "Epoch 423/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0759 - acc: 0.6418 - val_loss: 0.6452 - val_acc: 0.7719\n",
      "Epoch 424/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.0147 - acc: 0.6418 - val_loss: 0.6448 - val_acc: 0.7661\n",
      "Epoch 425/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9854 - acc: 0.6462 - val_loss: 0.6576 - val_acc: 0.7749\n",
      "Epoch 426/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9442 - acc: 0.6564 - val_loss: 0.6471 - val_acc: 0.7895\n",
      "Epoch 427/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0415 - acc: 0.6491 - val_loss: 0.6315 - val_acc: 0.7661\n",
      "Epoch 428/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9527 - acc: 0.6520 - val_loss: 0.6395 - val_acc: 0.7895\n",
      "Epoch 429/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9489 - acc: 0.6506 - val_loss: 0.6380 - val_acc: 0.7778\n",
      "Epoch 430/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.9728 - acc: 0.6725 - val_loss: 0.6470 - val_acc: 0.7690\n",
      "Epoch 431/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9922 - acc: 0.6272 - val_loss: 0.6433 - val_acc: 0.7895\n",
      "Epoch 432/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9808 - acc: 0.6477 - val_loss: 0.6452 - val_acc: 0.7719\n",
      "Epoch 433/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9804 - acc: 0.6462 - val_loss: 0.6454 - val_acc: 0.7807\n",
      "Epoch 434/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9370 - acc: 0.6345 - val_loss: 0.6379 - val_acc: 0.7836\n",
      "Epoch 435/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9126 - acc: 0.6623 - val_loss: 0.6454 - val_acc: 0.7836\n",
      "Epoch 436/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0078 - acc: 0.6564 - val_loss: 0.6419 - val_acc: 0.7895\n",
      "Epoch 437/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9857 - acc: 0.6272 - val_loss: 0.6535 - val_acc: 0.7836\n",
      "Epoch 438/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9766 - acc: 0.6404 - val_loss: 0.6456 - val_acc: 0.7836\n",
      "Epoch 439/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0024 - acc: 0.6447 - val_loss: 0.6388 - val_acc: 0.7807\n",
      "Epoch 440/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.9719 - acc: 0.6594 - val_loss: 0.6348 - val_acc: 0.7924\n",
      "Epoch 441/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9685 - acc: 0.6477 - val_loss: 0.6363 - val_acc: 0.7953\n",
      "Epoch 442/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0086 - acc: 0.6740 - val_loss: 0.6537 - val_acc: 0.7836\n",
      "Epoch 443/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9600 - acc: 0.6535 - val_loss: 0.6277 - val_acc: 0.7982\n",
      "Epoch 444/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9313 - acc: 0.6360 - val_loss: 0.6256 - val_acc: 0.7865\n",
      "Epoch 445/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0085 - acc: 0.6330 - val_loss: 0.6353 - val_acc: 0.7836\n",
      "Epoch 446/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9284 - acc: 0.6652 - val_loss: 0.6254 - val_acc: 0.7953\n",
      "Epoch 447/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0540 - acc: 0.6477 - val_loss: 0.6427 - val_acc: 0.7895\n",
      "Epoch 448/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9284 - acc: 0.6637 - val_loss: 0.6397 - val_acc: 0.7982\n",
      "Epoch 449/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0051 - acc: 0.6374 - val_loss: 0.6292 - val_acc: 0.7982\n",
      "Epoch 450/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9753 - acc: 0.6360 - val_loss: 0.6542 - val_acc: 0.7836\n",
      "Epoch 451/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9859 - acc: 0.6652 - val_loss: 0.6345 - val_acc: 0.8041\n",
      "Epoch 452/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0327 - acc: 0.6316 - val_loss: 0.6288 - val_acc: 0.7807\n",
      "Epoch 453/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9491 - acc: 0.6608 - val_loss: 0.6241 - val_acc: 0.7807\n",
      "Epoch 454/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8771 - acc: 0.6915 - val_loss: 0.6281 - val_acc: 0.7865\n",
      "Epoch 455/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9800 - acc: 0.6345 - val_loss: 0.6298 - val_acc: 0.7836\n",
      "Epoch 456/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.9363 - acc: 0.6389 - val_loss: 0.6336 - val_acc: 0.7953\n",
      "Epoch 457/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.9259 - acc: 0.6477 - val_loss: 0.6250 - val_acc: 0.7836\n",
      "Epoch 458/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9008 - acc: 0.6784 - val_loss: 0.6264 - val_acc: 0.7749\n",
      "Epoch 459/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9923 - acc: 0.6535 - val_loss: 0.6292 - val_acc: 0.7865\n",
      "Epoch 460/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9705 - acc: 0.6623 - val_loss: 0.6256 - val_acc: 0.7807\n",
      "Epoch 461/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.9119 - acc: 0.6696 - val_loss: 0.6156 - val_acc: 0.7836\n",
      "Epoch 462/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9699 - acc: 0.6462 - val_loss: 0.6124 - val_acc: 0.8012\n",
      "Epoch 463/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9219 - acc: 0.6886 - val_loss: 0.6112 - val_acc: 0.8070\n",
      "Epoch 464/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9441 - acc: 0.6491 - val_loss: 0.6117 - val_acc: 0.7953\n",
      "Epoch 465/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9480 - acc: 0.6491 - val_loss: 0.6108 - val_acc: 0.7982\n",
      "Epoch 466/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9739 - acc: 0.6433 - val_loss: 0.6072 - val_acc: 0.7924\n",
      "Epoch 467/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.9528 - acc: 0.6564 - val_loss: 0.6074 - val_acc: 0.8041\n",
      "Epoch 468/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9665 - acc: 0.6579 - val_loss: 0.5972 - val_acc: 0.7953\n",
      "Epoch 469/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9682 - acc: 0.6404 - val_loss: 0.6083 - val_acc: 0.7836\n",
      "Epoch 470/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9460 - acc: 0.6491 - val_loss: 0.6023 - val_acc: 0.7865\n",
      "Epoch 471/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9248 - acc: 0.6520 - val_loss: 0.6068 - val_acc: 0.7807\n",
      "Epoch 472/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.9371 - acc: 0.6594 - val_loss: 0.6047 - val_acc: 0.7807\n",
      "Epoch 473/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9828 - acc: 0.6506 - val_loss: 0.6021 - val_acc: 0.7865\n",
      "Epoch 474/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9138 - acc: 0.6944 - val_loss: 0.6025 - val_acc: 0.7924\n",
      "Epoch 475/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9181 - acc: 0.6769 - val_loss: 0.5931 - val_acc: 0.7924\n",
      "Epoch 476/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9457 - acc: 0.6579 - val_loss: 0.6030 - val_acc: 0.7953\n",
      "Epoch 477/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9426 - acc: 0.6667 - val_loss: 0.5975 - val_acc: 0.8041\n",
      "Epoch 478/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9449 - acc: 0.6535 - val_loss: 0.5865 - val_acc: 0.8041\n",
      "Epoch 479/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9006 - acc: 0.6740 - val_loss: 0.5830 - val_acc: 0.7924\n",
      "Epoch 480/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.9483 - acc: 0.6769 - val_loss: 0.6011 - val_acc: 0.8012\n",
      "Epoch 481/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9004 - acc: 0.6871 - val_loss: 0.5934 - val_acc: 0.8041\n",
      "Epoch 482/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8770 - acc: 0.6754 - val_loss: 0.5851 - val_acc: 0.7924\n",
      "Epoch 483/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9269 - acc: 0.6857 - val_loss: 0.5771 - val_acc: 0.7982\n",
      "Epoch 484/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9055 - acc: 0.6813 - val_loss: 0.5778 - val_acc: 0.7953\n",
      "Epoch 485/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9464 - acc: 0.6623 - val_loss: 0.5947 - val_acc: 0.7895\n",
      "Epoch 486/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9667 - acc: 0.6608 - val_loss: 0.5785 - val_acc: 0.7895\n",
      "Epoch 487/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.9564 - acc: 0.6681 - val_loss: 0.5922 - val_acc: 0.7865\n",
      "Epoch 488/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.9336 - acc: 0.6857 - val_loss: 0.5906 - val_acc: 0.7865\n",
      "Epoch 489/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.0033 - acc: 0.6579 - val_loss: 0.5961 - val_acc: 0.7778\n",
      "Epoch 490/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8866 - acc: 0.6944 - val_loss: 0.5823 - val_acc: 0.7953\n",
      "Epoch 491/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9911 - acc: 0.6857 - val_loss: 0.5768 - val_acc: 0.8070\n",
      "Epoch 492/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9616 - acc: 0.6725 - val_loss: 0.5838 - val_acc: 0.7924\n",
      "Epoch 493/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9822 - acc: 0.6433 - val_loss: 0.5856 - val_acc: 0.7982\n",
      "Epoch 494/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9091 - acc: 0.6813 - val_loss: 0.5937 - val_acc: 0.7895\n",
      "Epoch 495/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9439 - acc: 0.6564 - val_loss: 0.5872 - val_acc: 0.7895\n",
      "Epoch 496/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0055 - acc: 0.6535 - val_loss: 0.5910 - val_acc: 0.7953\n",
      "Epoch 497/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9129 - acc: 0.7091 - val_loss: 0.5801 - val_acc: 0.8012\n",
      "Epoch 498/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.9326 - acc: 0.6652 - val_loss: 0.5766 - val_acc: 0.7982\n",
      "Epoch 499/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.9143 - acc: 0.6652 - val_loss: 0.5735 - val_acc: 0.7953\n",
      "Epoch 500/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8560 - acc: 0.6871 - val_loss: 0.5705 - val_acc: 0.8070\n",
      "Epoch 501/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0012 - acc: 0.6681 - val_loss: 0.5751 - val_acc: 0.7749\n",
      "Epoch 502/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9777 - acc: 0.6594 - val_loss: 0.5786 - val_acc: 0.7836\n",
      "Epoch 503/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8973 - acc: 0.6798 - val_loss: 0.5696 - val_acc: 0.7895\n",
      "Epoch 504/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.9679 - acc: 0.6725 - val_loss: 0.5823 - val_acc: 0.7865\n",
      "Epoch 505/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.9741 - acc: 0.6637 - val_loss: 0.5738 - val_acc: 0.7895\n",
      "Epoch 506/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9170 - acc: 0.6725 - val_loss: 0.5775 - val_acc: 0.7778\n",
      "Epoch 507/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.9009 - acc: 0.6711 - val_loss: 0.5865 - val_acc: 0.7865\n",
      "Epoch 508/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9413 - acc: 0.6784 - val_loss: 0.5790 - val_acc: 0.7895\n",
      "Epoch 509/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.8722 - acc: 0.7135 - val_loss: 0.5682 - val_acc: 0.7982\n",
      "Epoch 510/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.9291 - acc: 0.6769 - val_loss: 0.5720 - val_acc: 0.7924\n",
      "Epoch 511/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9554 - acc: 0.6652 - val_loss: 0.5649 - val_acc: 0.8070\n",
      "Epoch 512/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9316 - acc: 0.6637 - val_loss: 0.5722 - val_acc: 0.7953\n",
      "Epoch 513/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8904 - acc: 0.6930 - val_loss: 0.5743 - val_acc: 0.7982\n",
      "Epoch 514/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.9424 - acc: 0.6652 - val_loss: 0.5673 - val_acc: 0.7924\n",
      "Epoch 515/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.9336 - acc: 0.6813 - val_loss: 0.5601 - val_acc: 0.8070\n",
      "Epoch 516/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9596 - acc: 0.6754 - val_loss: 0.5731 - val_acc: 0.7953\n",
      "Epoch 517/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.8739 - acc: 0.6915 - val_loss: 0.5707 - val_acc: 0.7895\n",
      "Epoch 518/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.9397 - acc: 0.6608 - val_loss: 0.5814 - val_acc: 0.8012\n",
      "Epoch 519/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9272 - acc: 0.6857 - val_loss: 0.5802 - val_acc: 0.7865\n",
      "Epoch 520/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8519 - acc: 0.6667 - val_loss: 0.5716 - val_acc: 0.7924\n",
      "Epoch 521/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0000 - acc: 0.6462 - val_loss: 0.5924 - val_acc: 0.7953\n",
      "Epoch 522/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8714 - acc: 0.6915 - val_loss: 0.5748 - val_acc: 0.7924\n",
      "Epoch 523/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9382 - acc: 0.6784 - val_loss: 0.5767 - val_acc: 0.8070\n",
      "Epoch 524/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9668 - acc: 0.6681 - val_loss: 0.5845 - val_acc: 0.8012\n",
      "Epoch 525/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.8967 - acc: 0.6944 - val_loss: 0.5834 - val_acc: 0.8070\n",
      "Epoch 526/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9017 - acc: 0.6901 - val_loss: 0.5748 - val_acc: 0.8099\n",
      "Epoch 527/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.9295 - acc: 0.6667 - val_loss: 0.5759 - val_acc: 0.7924\n",
      "Epoch 528/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9207 - acc: 0.6784 - val_loss: 0.5661 - val_acc: 0.7953\n",
      "Epoch 529/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9113 - acc: 0.6886 - val_loss: 0.5704 - val_acc: 0.7895\n",
      "Epoch 530/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.8325 - acc: 0.7193 - val_loss: 0.5702 - val_acc: 0.7982\n",
      "Epoch 531/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8589 - acc: 0.6930 - val_loss: 0.5710 - val_acc: 0.7982\n",
      "Epoch 532/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8439 - acc: 0.6988 - val_loss: 0.5720 - val_acc: 0.8012\n",
      "Epoch 533/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9750 - acc: 0.6754 - val_loss: 0.5915 - val_acc: 0.8070\n",
      "Epoch 534/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8599 - acc: 0.6871 - val_loss: 0.5830 - val_acc: 0.8012\n",
      "Epoch 535/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8701 - acc: 0.6784 - val_loss: 0.5767 - val_acc: 0.7953\n",
      "Epoch 536/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.8562 - acc: 0.6988 - val_loss: 0.5653 - val_acc: 0.7982\n",
      "Epoch 537/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9632 - acc: 0.6754 - val_loss: 0.5809 - val_acc: 0.7865\n",
      "Epoch 538/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9202 - acc: 0.6725 - val_loss: 0.5731 - val_acc: 0.7836\n",
      "Epoch 539/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9073 - acc: 0.6871 - val_loss: 0.5752 - val_acc: 0.7924\n",
      "Epoch 540/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.8636 - acc: 0.7091 - val_loss: 0.5685 - val_acc: 0.7924\n",
      "Epoch 541/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9438 - acc: 0.6652 - val_loss: 0.5794 - val_acc: 0.7924\n",
      "Epoch 542/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8856 - acc: 0.6871 - val_loss: 0.5763 - val_acc: 0.7953\n",
      "Epoch 543/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8953 - acc: 0.6871 - val_loss: 0.5733 - val_acc: 0.7953\n",
      "Epoch 544/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9339 - acc: 0.6886 - val_loss: 0.5870 - val_acc: 0.7982\n",
      "Epoch 545/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8812 - acc: 0.6871 - val_loss: 0.6003 - val_acc: 0.7895\n",
      "Epoch 546/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.9342 - acc: 0.6784 - val_loss: 0.5693 - val_acc: 0.8041\n",
      "Epoch 547/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.8684 - acc: 0.6886 - val_loss: 0.5687 - val_acc: 0.7924\n",
      "Epoch 548/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8850 - acc: 0.6754 - val_loss: 0.5702 - val_acc: 0.8216\n",
      "Epoch 549/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9249 - acc: 0.6930 - val_loss: 0.5659 - val_acc: 0.8070\n",
      "Epoch 550/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8650 - acc: 0.7061 - val_loss: 0.5564 - val_acc: 0.8012\n",
      "Epoch 551/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.9230 - acc: 0.6725 - val_loss: 0.5619 - val_acc: 0.8012\n",
      "Epoch 552/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.9307 - acc: 0.6944 - val_loss: 0.5645 - val_acc: 0.7982\n",
      "Epoch 553/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.8846 - acc: 0.6974 - val_loss: 0.5594 - val_acc: 0.7953\n",
      "Epoch 554/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9298 - acc: 0.6930 - val_loss: 0.5774 - val_acc: 0.7982\n",
      "Epoch 555/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9059 - acc: 0.6901 - val_loss: 0.5645 - val_acc: 0.8041\n",
      "Epoch 556/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.8619 - acc: 0.6974 - val_loss: 0.5569 - val_acc: 0.8099\n",
      "Epoch 557/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.8903 - acc: 0.7091 - val_loss: 0.5452 - val_acc: 0.7953\n",
      "Epoch 558/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8889 - acc: 0.6564 - val_loss: 0.5544 - val_acc: 0.8012\n",
      "Epoch 559/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8597 - acc: 0.6842 - val_loss: 0.5546 - val_acc: 0.8041\n",
      "Epoch 560/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9017 - acc: 0.6871 - val_loss: 0.5627 - val_acc: 0.7953\n",
      "Epoch 561/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.8697 - acc: 0.6754 - val_loss: 0.5519 - val_acc: 0.8041\n",
      "Epoch 562/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.8113 - acc: 0.6974 - val_loss: 0.5467 - val_acc: 0.8070\n",
      "Epoch 563/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8722 - acc: 0.7003 - val_loss: 0.5560 - val_acc: 0.8187\n",
      "Epoch 564/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9302 - acc: 0.6827 - val_loss: 0.5560 - val_acc: 0.8129\n",
      "Epoch 565/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8826 - acc: 0.6974 - val_loss: 0.5520 - val_acc: 0.7982\n",
      "Epoch 566/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.8027 - acc: 0.6886 - val_loss: 0.5542 - val_acc: 0.8012\n",
      "Epoch 567/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.8758 - acc: 0.7061 - val_loss: 0.5585 - val_acc: 0.8012\n",
      "Epoch 568/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.8593 - acc: 0.6915 - val_loss: 0.5543 - val_acc: 0.8012\n",
      "Epoch 569/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.8174 - acc: 0.7047 - val_loss: 0.5542 - val_acc: 0.7807\n",
      "Epoch 570/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8408 - acc: 0.7251 - val_loss: 0.5581 - val_acc: 0.7953\n",
      "Epoch 571/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.9580 - acc: 0.6725 - val_loss: 0.5640 - val_acc: 0.7865\n",
      "Epoch 572/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.8407 - acc: 0.7018 - val_loss: 0.5589 - val_acc: 0.7953\n",
      "Epoch 573/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9241 - acc: 0.6959 - val_loss: 0.5510 - val_acc: 0.7982\n",
      "Epoch 574/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9015 - acc: 0.6930 - val_loss: 0.5627 - val_acc: 0.7895\n",
      "Epoch 575/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8739 - acc: 0.6842 - val_loss: 0.5495 - val_acc: 0.7953\n",
      "Epoch 576/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8020 - acc: 0.7032 - val_loss: 0.5451 - val_acc: 0.8012\n",
      "Epoch 577/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.9121 - acc: 0.7047 - val_loss: 0.5633 - val_acc: 0.7953\n",
      "Epoch 578/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.8596 - acc: 0.7266 - val_loss: 0.5598 - val_acc: 0.7895\n",
      "Epoch 579/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.8471 - acc: 0.6930 - val_loss: 0.5367 - val_acc: 0.7953\n",
      "Epoch 580/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.8427 - acc: 0.6827 - val_loss: 0.5489 - val_acc: 0.7982\n",
      "Epoch 581/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.8914 - acc: 0.6886 - val_loss: 0.5424 - val_acc: 0.7982\n",
      "Epoch 582/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.8377 - acc: 0.6988 - val_loss: 0.5470 - val_acc: 0.8041\n",
      "Epoch 583/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.8667 - acc: 0.6988 - val_loss: 0.5513 - val_acc: 0.8012\n",
      "Epoch 584/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.8470 - acc: 0.7120 - val_loss: 0.5491 - val_acc: 0.8012\n",
      "Epoch 585/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.8537 - acc: 0.7105 - val_loss: 0.5509 - val_acc: 0.8099\n",
      "Epoch 586/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.8052 - acc: 0.7149 - val_loss: 0.5518 - val_acc: 0.8070\n",
      "Epoch 587/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.8700 - acc: 0.7003 - val_loss: 0.5426 - val_acc: 0.8099\n",
      "Epoch 588/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.9316 - acc: 0.6842 - val_loss: 0.5356 - val_acc: 0.7953\n",
      "Epoch 589/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8834 - acc: 0.6915 - val_loss: 0.5402 - val_acc: 0.8041\n",
      "Epoch 590/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.8257 - acc: 0.7047 - val_loss: 0.5413 - val_acc: 0.7982\n",
      "Epoch 591/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.8923 - acc: 0.6754 - val_loss: 0.5441 - val_acc: 0.7924\n",
      "Epoch 592/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.9704 - acc: 0.6798 - val_loss: 0.5482 - val_acc: 0.7953\n",
      "Epoch 593/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.9180 - acc: 0.7076 - val_loss: 0.5487 - val_acc: 0.8070\n",
      "Epoch 594/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8154 - acc: 0.7135 - val_loss: 0.5419 - val_acc: 0.7953\n",
      "Epoch 595/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.9152 - acc: 0.6667 - val_loss: 0.5437 - val_acc: 0.8070\n",
      "Epoch 596/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.8764 - acc: 0.7061 - val_loss: 0.5420 - val_acc: 0.8070\n",
      "Epoch 597/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.8156 - acc: 0.6959 - val_loss: 0.5366 - val_acc: 0.7924\n",
      "Epoch 598/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.9078 - acc: 0.7003 - val_loss: 0.5400 - val_acc: 0.7953\n",
      "Epoch 599/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9632 - acc: 0.6827 - val_loss: 0.5551 - val_acc: 0.8129\n",
      "Epoch 600/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.8383 - acc: 0.7061 - val_loss: 0.5522 - val_acc: 0.7982\n",
      "Epoch 601/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8078 - acc: 0.7149 - val_loss: 0.5435 - val_acc: 0.8012\n",
      "Epoch 602/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.8431 - acc: 0.7047 - val_loss: 0.5508 - val_acc: 0.8070\n",
      "Epoch 603/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.7602 - acc: 0.7529 - val_loss: 0.5450 - val_acc: 0.8129\n",
      "Epoch 604/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.8461 - acc: 0.7135 - val_loss: 0.5426 - val_acc: 0.8158\n",
      "Epoch 605/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8854 - acc: 0.7047 - val_loss: 0.5349 - val_acc: 0.8070\n",
      "Epoch 606/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8486 - acc: 0.6974 - val_loss: 0.5346 - val_acc: 0.8099\n",
      "Epoch 607/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8146 - acc: 0.7222 - val_loss: 0.5344 - val_acc: 0.8129\n",
      "Epoch 608/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.9003 - acc: 0.7018 - val_loss: 0.5328 - val_acc: 0.8216\n",
      "Epoch 609/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8139 - acc: 0.7149 - val_loss: 0.5249 - val_acc: 0.8099\n",
      "Epoch 610/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7987 - acc: 0.7237 - val_loss: 0.5355 - val_acc: 0.8158\n",
      "Epoch 611/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8354 - acc: 0.7354 - val_loss: 0.5366 - val_acc: 0.8041\n",
      "Epoch 612/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.8379 - acc: 0.7251 - val_loss: 0.5216 - val_acc: 0.8041\n",
      "Epoch 613/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8375 - acc: 0.6871 - val_loss: 0.5244 - val_acc: 0.8099\n",
      "Epoch 614/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8607 - acc: 0.7018 - val_loss: 0.5304 - val_acc: 0.8070\n",
      "Epoch 615/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8288 - acc: 0.7091 - val_loss: 0.5335 - val_acc: 0.8070\n",
      "Epoch 616/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8676 - acc: 0.7047 - val_loss: 0.5467 - val_acc: 0.8070\n",
      "Epoch 617/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8229 - acc: 0.7208 - val_loss: 0.5456 - val_acc: 0.8012\n",
      "Epoch 618/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.8857 - acc: 0.6754 - val_loss: 0.5421 - val_acc: 0.8070\n",
      "Epoch 619/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8969 - acc: 0.6798 - val_loss: 0.5490 - val_acc: 0.8129\n",
      "Epoch 620/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8177 - acc: 0.6974 - val_loss: 0.5507 - val_acc: 0.7895\n",
      "Epoch 621/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8122 - acc: 0.7149 - val_loss: 0.5263 - val_acc: 0.8070\n",
      "Epoch 622/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9016 - acc: 0.6886 - val_loss: 0.5324 - val_acc: 0.8070\n",
      "Epoch 623/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8598 - acc: 0.7061 - val_loss: 0.5420 - val_acc: 0.8099\n",
      "Epoch 624/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.8023 - acc: 0.7281 - val_loss: 0.5393 - val_acc: 0.8041\n",
      "Epoch 625/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7800 - acc: 0.7061 - val_loss: 0.5383 - val_acc: 0.8041\n",
      "Epoch 626/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8101 - acc: 0.7178 - val_loss: 0.5311 - val_acc: 0.8070\n",
      "Epoch 627/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8426 - acc: 0.6944 - val_loss: 0.5304 - val_acc: 0.8129\n",
      "Epoch 628/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.8049 - acc: 0.7076 - val_loss: 0.5350 - val_acc: 0.8070\n",
      "Epoch 629/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.8202 - acc: 0.7032 - val_loss: 0.5374 - val_acc: 0.7982\n",
      "Epoch 630/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9339 - acc: 0.6637 - val_loss: 0.5361 - val_acc: 0.8129\n",
      "Epoch 631/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8435 - acc: 0.7047 - val_loss: 0.5364 - val_acc: 0.8099\n",
      "Epoch 632/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.8410 - acc: 0.7120 - val_loss: 0.5387 - val_acc: 0.7982\n",
      "Epoch 633/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.8037 - acc: 0.7237 - val_loss: 0.5368 - val_acc: 0.8070\n",
      "Epoch 634/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.8124 - acc: 0.7281 - val_loss: 0.5278 - val_acc: 0.8041\n",
      "Epoch 635/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8059 - acc: 0.7339 - val_loss: 0.5205 - val_acc: 0.8041\n",
      "Epoch 636/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8761 - acc: 0.7135 - val_loss: 0.5220 - val_acc: 0.8099\n",
      "Epoch 637/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.8685 - acc: 0.7178 - val_loss: 0.5331 - val_acc: 0.8129\n",
      "Epoch 638/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.8724 - acc: 0.6901 - val_loss: 0.5247 - val_acc: 0.8099\n",
      "Epoch 639/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.8253 - acc: 0.7222 - val_loss: 0.5350 - val_acc: 0.8129\n",
      "Epoch 640/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8353 - acc: 0.7047 - val_loss: 0.5375 - val_acc: 0.8158\n",
      "Epoch 641/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8554 - acc: 0.6886 - val_loss: 0.5512 - val_acc: 0.8070\n",
      "Epoch 642/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.8947 - acc: 0.7149 - val_loss: 0.5413 - val_acc: 0.8012\n",
      "Epoch 643/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.8513 - acc: 0.7018 - val_loss: 0.5460 - val_acc: 0.7982\n",
      "Epoch 644/1000\n",
      "684/684 [==============================] - 4s 5ms/step - loss: 0.7798 - acc: 0.7339 - val_loss: 0.5263 - val_acc: 0.8041\n",
      "Epoch 645/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.8826 - acc: 0.6974 - val_loss: 0.5280 - val_acc: 0.7982\n",
      "Epoch 646/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.8314 - acc: 0.6930 - val_loss: 0.5360 - val_acc: 0.8041\n",
      "Epoch 647/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.8417 - acc: 0.7047 - val_loss: 0.5337 - val_acc: 0.8099\n",
      "Epoch 648/1000\n",
      "684/684 [==============================] - 4s 5ms/step - loss: 0.8327 - acc: 0.7339 - val_loss: 0.5291 - val_acc: 0.8070\n",
      "Epoch 649/1000\n",
      "684/684 [==============================] - 4s 5ms/step - loss: 0.8331 - acc: 0.7003 - val_loss: 0.5215 - val_acc: 0.8012\n",
      "Epoch 650/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.8253 - acc: 0.7061 - val_loss: 0.5241 - val_acc: 0.8041\n",
      "Epoch 651/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.9457 - acc: 0.6769 - val_loss: 0.5317 - val_acc: 0.8158\n",
      "Epoch 652/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.8162 - acc: 0.7193 - val_loss: 0.5385 - val_acc: 0.7982\n",
      "Epoch 653/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.8929 - acc: 0.6857 - val_loss: 0.5379 - val_acc: 0.7982\n",
      "Epoch 654/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.7966 - acc: 0.7266 - val_loss: 0.5350 - val_acc: 0.8012\n",
      "Epoch 655/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.8124 - acc: 0.7266 - val_loss: 0.5239 - val_acc: 0.8070\n",
      "Epoch 656/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.8048 - acc: 0.7251 - val_loss: 0.5178 - val_acc: 0.8099\n",
      "Epoch 657/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.8630 - acc: 0.7237 - val_loss: 0.5142 - val_acc: 0.8158\n",
      "Epoch 658/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.7480 - acc: 0.7442 - val_loss: 0.5124 - val_acc: 0.8187\n",
      "Epoch 659/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.8078 - acc: 0.7281 - val_loss: 0.5245 - val_acc: 0.8158\n",
      "Epoch 660/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.8367 - acc: 0.6959 - val_loss: 0.5239 - val_acc: 0.8129\n",
      "Epoch 661/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8355 - acc: 0.7193 - val_loss: 0.5282 - val_acc: 0.8158\n",
      "Epoch 662/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8386 - acc: 0.7135 - val_loss: 0.5233 - val_acc: 0.8187\n",
      "Epoch 663/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8095 - acc: 0.7237 - val_loss: 0.5299 - val_acc: 0.8187\n",
      "Epoch 664/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8505 - acc: 0.7178 - val_loss: 0.5156 - val_acc: 0.8246\n",
      "Epoch 665/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8279 - acc: 0.7032 - val_loss: 0.5216 - val_acc: 0.8158\n",
      "Epoch 666/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8320 - acc: 0.7222 - val_loss: 0.5053 - val_acc: 0.8246\n",
      "Epoch 667/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7803 - acc: 0.7266 - val_loss: 0.5094 - val_acc: 0.8216\n",
      "Epoch 668/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8326 - acc: 0.7076 - val_loss: 0.5133 - val_acc: 0.8216\n",
      "Epoch 669/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8112 - acc: 0.7237 - val_loss: 0.5160 - val_acc: 0.8275\n",
      "Epoch 670/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8255 - acc: 0.7193 - val_loss: 0.5160 - val_acc: 0.8246\n",
      "Epoch 671/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7939 - acc: 0.7105 - val_loss: 0.5142 - val_acc: 0.8246\n",
      "Epoch 672/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8063 - acc: 0.7251 - val_loss: 0.5042 - val_acc: 0.8187\n",
      "Epoch 673/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8197 - acc: 0.7266 - val_loss: 0.5206 - val_acc: 0.8216\n",
      "Epoch 674/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8260 - acc: 0.7149 - val_loss: 0.4996 - val_acc: 0.8275\n",
      "Epoch 675/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8412 - acc: 0.7003 - val_loss: 0.4986 - val_acc: 0.8333\n",
      "Epoch 676/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8059 - acc: 0.7325 - val_loss: 0.4977 - val_acc: 0.8304\n",
      "Epoch 677/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7967 - acc: 0.7295 - val_loss: 0.5204 - val_acc: 0.8275\n",
      "Epoch 678/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8296 - acc: 0.7164 - val_loss: 0.5268 - val_acc: 0.8187\n",
      "Epoch 679/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8201 - acc: 0.7368 - val_loss: 0.5095 - val_acc: 0.8187\n",
      "Epoch 680/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7851 - acc: 0.7281 - val_loss: 0.5134 - val_acc: 0.8129\n",
      "Epoch 681/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7793 - acc: 0.7515 - val_loss: 0.5103 - val_acc: 0.8070\n",
      "Epoch 682/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8035 - acc: 0.7266 - val_loss: 0.5131 - val_acc: 0.8187\n",
      "Epoch 683/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7954 - acc: 0.7310 - val_loss: 0.5082 - val_acc: 0.8246\n",
      "Epoch 684/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7818 - acc: 0.7310 - val_loss: 0.5102 - val_acc: 0.8216\n",
      "Epoch 685/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8321 - acc: 0.7222 - val_loss: 0.5051 - val_acc: 0.8070\n",
      "Epoch 686/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8352 - acc: 0.7149 - val_loss: 0.5007 - val_acc: 0.8216\n",
      "Epoch 687/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8056 - acc: 0.6988 - val_loss: 0.5068 - val_acc: 0.8041\n",
      "Epoch 688/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7938 - acc: 0.7266 - val_loss: 0.5171 - val_acc: 0.8099\n",
      "Epoch 689/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8357 - acc: 0.7193 - val_loss: 0.5056 - val_acc: 0.8099\n",
      "Epoch 690/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7812 - acc: 0.7310 - val_loss: 0.5087 - val_acc: 0.8158\n",
      "Epoch 691/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.8053 - acc: 0.7076 - val_loss: 0.5024 - val_acc: 0.8129\n",
      "Epoch 692/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.8093 - acc: 0.7266 - val_loss: 0.5074 - val_acc: 0.8158\n",
      "Epoch 693/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7820 - acc: 0.7178 - val_loss: 0.5117 - val_acc: 0.8158\n",
      "Epoch 694/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7532 - acc: 0.7412 - val_loss: 0.4960 - val_acc: 0.8275\n",
      "Epoch 695/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8201 - acc: 0.7427 - val_loss: 0.4938 - val_acc: 0.8187\n",
      "Epoch 696/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8091 - acc: 0.7208 - val_loss: 0.4831 - val_acc: 0.8363\n",
      "Epoch 697/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8320 - acc: 0.7193 - val_loss: 0.4976 - val_acc: 0.8129\n",
      "Epoch 698/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7884 - acc: 0.7325 - val_loss: 0.5033 - val_acc: 0.8099\n",
      "Epoch 699/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8219 - acc: 0.7018 - val_loss: 0.4954 - val_acc: 0.8216\n",
      "Epoch 700/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7643 - acc: 0.7368 - val_loss: 0.5049 - val_acc: 0.8187\n",
      "Epoch 701/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.7798 - acc: 0.7135 - val_loss: 0.5031 - val_acc: 0.8129\n",
      "Epoch 702/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.8058 - acc: 0.7325 - val_loss: 0.5032 - val_acc: 0.8158\n",
      "Epoch 703/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8170 - acc: 0.7003 - val_loss: 0.5013 - val_acc: 0.8129\n",
      "Epoch 704/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8120 - acc: 0.7442 - val_loss: 0.4988 - val_acc: 0.8099\n",
      "Epoch 705/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7739 - acc: 0.7529 - val_loss: 0.5051 - val_acc: 0.8187\n",
      "Epoch 706/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7954 - acc: 0.7471 - val_loss: 0.5088 - val_acc: 0.8158\n",
      "Epoch 707/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.7690 - acc: 0.7485 - val_loss: 0.5074 - val_acc: 0.8246\n",
      "Epoch 708/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7776 - acc: 0.7076 - val_loss: 0.5052 - val_acc: 0.8187\n",
      "Epoch 709/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8134 - acc: 0.7178 - val_loss: 0.4963 - val_acc: 0.8187\n",
      "Epoch 710/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8308 - acc: 0.7237 - val_loss: 0.4952 - val_acc: 0.8216\n",
      "Epoch 711/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8107 - acc: 0.7281 - val_loss: 0.4881 - val_acc: 0.8275\n",
      "Epoch 712/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.7645 - acc: 0.7442 - val_loss: 0.5039 - val_acc: 0.8187\n",
      "Epoch 713/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8177 - acc: 0.7442 - val_loss: 0.5091 - val_acc: 0.8216\n",
      "Epoch 714/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8054 - acc: 0.7105 - val_loss: 0.5091 - val_acc: 0.8158\n",
      "Epoch 715/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7896 - acc: 0.7398 - val_loss: 0.5032 - val_acc: 0.8158\n",
      "Epoch 716/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7830 - acc: 0.7237 - val_loss: 0.5016 - val_acc: 0.8158\n",
      "Epoch 717/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8210 - acc: 0.7135 - val_loss: 0.5058 - val_acc: 0.8158\n",
      "Epoch 718/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7534 - acc: 0.7325 - val_loss: 0.5097 - val_acc: 0.8187\n",
      "Epoch 719/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8244 - acc: 0.7295 - val_loss: 0.5001 - val_acc: 0.8158\n",
      "Epoch 720/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8231 - acc: 0.7310 - val_loss: 0.4956 - val_acc: 0.8129\n",
      "Epoch 721/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8174 - acc: 0.7222 - val_loss: 0.5076 - val_acc: 0.8129\n",
      "Epoch 722/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.7941 - acc: 0.7222 - val_loss: 0.5012 - val_acc: 0.8187\n",
      "Epoch 723/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7533 - acc: 0.7368 - val_loss: 0.5054 - val_acc: 0.8099\n",
      "Epoch 724/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8302 - acc: 0.7325 - val_loss: 0.5035 - val_acc: 0.8129\n",
      "Epoch 725/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7769 - acc: 0.7383 - val_loss: 0.4994 - val_acc: 0.8187\n",
      "Epoch 726/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7516 - acc: 0.7339 - val_loss: 0.4809 - val_acc: 0.8216\n",
      "Epoch 727/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7379 - acc: 0.7354 - val_loss: 0.4835 - val_acc: 0.8158\n",
      "Epoch 728/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7803 - acc: 0.7354 - val_loss: 0.4867 - val_acc: 0.8099\n",
      "Epoch 729/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8161 - acc: 0.7237 - val_loss: 0.5011 - val_acc: 0.8158\n",
      "Epoch 730/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8161 - acc: 0.7222 - val_loss: 0.4898 - val_acc: 0.8187\n",
      "Epoch 731/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8183 - acc: 0.7310 - val_loss: 0.4936 - val_acc: 0.8099\n",
      "Epoch 732/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7968 - acc: 0.7251 - val_loss: 0.4951 - val_acc: 0.8216\n",
      "Epoch 733/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7574 - acc: 0.7339 - val_loss: 0.4865 - val_acc: 0.8099\n",
      "Epoch 734/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8189 - acc: 0.7164 - val_loss: 0.4868 - val_acc: 0.8158\n",
      "Epoch 735/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7610 - acc: 0.7383 - val_loss: 0.4966 - val_acc: 0.8129\n",
      "Epoch 736/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8190 - acc: 0.7149 - val_loss: 0.4908 - val_acc: 0.8187\n",
      "Epoch 737/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7340 - acc: 0.7500 - val_loss: 0.4836 - val_acc: 0.8216\n",
      "Epoch 738/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.8016 - acc: 0.7383 - val_loss: 0.4854 - val_acc: 0.8099\n",
      "Epoch 739/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7990 - acc: 0.7310 - val_loss: 0.4844 - val_acc: 0.8216\n",
      "Epoch 740/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8118 - acc: 0.7368 - val_loss: 0.4927 - val_acc: 0.8216\n",
      "Epoch 741/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8256 - acc: 0.7237 - val_loss: 0.4878 - val_acc: 0.8187\n",
      "Epoch 742/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7579 - acc: 0.7295 - val_loss: 0.4967 - val_acc: 0.8187\n",
      "Epoch 743/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7880 - acc: 0.7471 - val_loss: 0.5000 - val_acc: 0.8099\n",
      "Epoch 744/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8647 - acc: 0.7237 - val_loss: 0.4889 - val_acc: 0.8158\n",
      "Epoch 745/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7766 - acc: 0.7281 - val_loss: 0.4942 - val_acc: 0.8070\n",
      "Epoch 746/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7891 - acc: 0.7237 - val_loss: 0.4948 - val_acc: 0.8070\n",
      "Epoch 747/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8112 - acc: 0.7339 - val_loss: 0.5002 - val_acc: 0.8070\n",
      "Epoch 748/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7840 - acc: 0.7368 - val_loss: 0.4903 - val_acc: 0.8099\n",
      "Epoch 749/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.8071 - acc: 0.7178 - val_loss: 0.4974 - val_acc: 0.8099\n",
      "Epoch 750/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7574 - acc: 0.7281 - val_loss: 0.4871 - val_acc: 0.8187\n",
      "Epoch 751/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7893 - acc: 0.7266 - val_loss: 0.4832 - val_acc: 0.8158\n",
      "Epoch 752/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7866 - acc: 0.7310 - val_loss: 0.4781 - val_acc: 0.8158\n",
      "Epoch 753/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7322 - acc: 0.7398 - val_loss: 0.4807 - val_acc: 0.8129\n",
      "Epoch 754/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8620 - acc: 0.7135 - val_loss: 0.4776 - val_acc: 0.8158\n",
      "Epoch 755/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.7255 - acc: 0.7646 - val_loss: 0.4806 - val_acc: 0.8158\n",
      "Epoch 756/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.7808 - acc: 0.7398 - val_loss: 0.4798 - val_acc: 0.8275\n",
      "Epoch 757/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7899 - acc: 0.7325 - val_loss: 0.4857 - val_acc: 0.8158\n",
      "Epoch 758/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7429 - acc: 0.7529 - val_loss: 0.4725 - val_acc: 0.8275\n",
      "Epoch 759/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8336 - acc: 0.7193 - val_loss: 0.4800 - val_acc: 0.8187\n",
      "Epoch 760/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8198 - acc: 0.7325 - val_loss: 0.4844 - val_acc: 0.8187\n",
      "Epoch 761/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.8019 - acc: 0.7222 - val_loss: 0.4841 - val_acc: 0.8129\n",
      "Epoch 762/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8013 - acc: 0.7427 - val_loss: 0.4818 - val_acc: 0.8304\n",
      "Epoch 763/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7456 - acc: 0.7573 - val_loss: 0.4841 - val_acc: 0.8187\n",
      "Epoch 764/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8054 - acc: 0.7208 - val_loss: 0.4831 - val_acc: 0.8158\n",
      "Epoch 765/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8035 - acc: 0.7310 - val_loss: 0.4711 - val_acc: 0.8216\n",
      "Epoch 766/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.7400 - acc: 0.7632 - val_loss: 0.4781 - val_acc: 0.8129\n",
      "Epoch 767/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7855 - acc: 0.7310 - val_loss: 0.4839 - val_acc: 0.8246\n",
      "Epoch 768/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8271 - acc: 0.7383 - val_loss: 0.4826 - val_acc: 0.8187\n",
      "Epoch 769/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7433 - acc: 0.7749 - val_loss: 0.4743 - val_acc: 0.8187\n",
      "Epoch 770/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8100 - acc: 0.7105 - val_loss: 0.4778 - val_acc: 0.8158\n",
      "Epoch 771/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.8165 - acc: 0.7149 - val_loss: 0.4826 - val_acc: 0.8129\n",
      "Epoch 772/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8196 - acc: 0.7266 - val_loss: 0.4783 - val_acc: 0.8129\n",
      "Epoch 773/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7949 - acc: 0.7558 - val_loss: 0.4728 - val_acc: 0.8216\n",
      "Epoch 774/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.6794 - acc: 0.7632 - val_loss: 0.4707 - val_acc: 0.8333\n",
      "Epoch 775/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7781 - acc: 0.7471 - val_loss: 0.4761 - val_acc: 0.8246\n",
      "Epoch 776/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8039 - acc: 0.7339 - val_loss: 0.4844 - val_acc: 0.8246\n",
      "Epoch 777/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8651 - acc: 0.7149 - val_loss: 0.4816 - val_acc: 0.8129\n",
      "Epoch 778/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7712 - acc: 0.7281 - val_loss: 0.4729 - val_acc: 0.8187\n",
      "Epoch 779/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7754 - acc: 0.7368 - val_loss: 0.4728 - val_acc: 0.8275\n",
      "Epoch 780/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7361 - acc: 0.7339 - val_loss: 0.4713 - val_acc: 0.8216\n",
      "Epoch 781/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7821 - acc: 0.7208 - val_loss: 0.4689 - val_acc: 0.8216\n",
      "Epoch 782/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7296 - acc: 0.7427 - val_loss: 0.4691 - val_acc: 0.8187\n",
      "Epoch 783/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7975 - acc: 0.7368 - val_loss: 0.4649 - val_acc: 0.8246\n",
      "Epoch 784/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7309 - acc: 0.7398 - val_loss: 0.4601 - val_acc: 0.8246\n",
      "Epoch 785/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7452 - acc: 0.7281 - val_loss: 0.4614 - val_acc: 0.8363\n",
      "Epoch 786/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8416 - acc: 0.7208 - val_loss: 0.4593 - val_acc: 0.8363\n",
      "Epoch 787/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8753 - acc: 0.7061 - val_loss: 0.4733 - val_acc: 0.8187\n",
      "Epoch 788/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7846 - acc: 0.7310 - val_loss: 0.4700 - val_acc: 0.8304\n",
      "Epoch 789/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7394 - acc: 0.7573 - val_loss: 0.4625 - val_acc: 0.8129\n",
      "Epoch 790/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7454 - acc: 0.7398 - val_loss: 0.4626 - val_acc: 0.8158\n",
      "Epoch 791/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8418 - acc: 0.7135 - val_loss: 0.4801 - val_acc: 0.8099\n",
      "Epoch 792/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7935 - acc: 0.7471 - val_loss: 0.4698 - val_acc: 0.8216\n",
      "Epoch 793/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.6939 - acc: 0.7602 - val_loss: 0.4725 - val_acc: 0.8129\n",
      "Epoch 794/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7727 - acc: 0.7266 - val_loss: 0.4691 - val_acc: 0.8216\n",
      "Epoch 795/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7718 - acc: 0.7485 - val_loss: 0.4767 - val_acc: 0.8099\n",
      "Epoch 796/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7466 - acc: 0.7354 - val_loss: 0.4674 - val_acc: 0.8187\n",
      "Epoch 797/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7474 - acc: 0.7237 - val_loss: 0.4694 - val_acc: 0.8070\n",
      "Epoch 798/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7746 - acc: 0.7383 - val_loss: 0.4706 - val_acc: 0.8246\n",
      "Epoch 799/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7666 - acc: 0.7398 - val_loss: 0.4748 - val_acc: 0.8304\n",
      "Epoch 800/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8273 - acc: 0.7164 - val_loss: 0.4628 - val_acc: 0.8304\n",
      "Epoch 801/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7724 - acc: 0.7412 - val_loss: 0.4815 - val_acc: 0.8187\n",
      "Epoch 802/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7164 - acc: 0.7471 - val_loss: 0.4716 - val_acc: 0.8275\n",
      "Epoch 803/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.7427 - acc: 0.7398 - val_loss: 0.4677 - val_acc: 0.8333\n",
      "Epoch 804/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7415 - acc: 0.7471 - val_loss: 0.4739 - val_acc: 0.8246\n",
      "Epoch 805/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7473 - acc: 0.7368 - val_loss: 0.4697 - val_acc: 0.8333\n",
      "Epoch 806/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7545 - acc: 0.7368 - val_loss: 0.4700 - val_acc: 0.8216\n",
      "Epoch 807/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7698 - acc: 0.7412 - val_loss: 0.4679 - val_acc: 0.8129\n",
      "Epoch 808/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7719 - acc: 0.7529 - val_loss: 0.4687 - val_acc: 0.8216\n",
      "Epoch 809/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.7765 - acc: 0.7310 - val_loss: 0.4569 - val_acc: 0.8304\n",
      "Epoch 810/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7862 - acc: 0.7588 - val_loss: 0.4683 - val_acc: 0.8187\n",
      "Epoch 811/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8151 - acc: 0.7339 - val_loss: 0.4635 - val_acc: 0.8246\n",
      "Epoch 812/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7428 - acc: 0.7646 - val_loss: 0.4693 - val_acc: 0.8275\n",
      "Epoch 813/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8094 - acc: 0.7266 - val_loss: 0.4606 - val_acc: 0.8275\n",
      "Epoch 814/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7654 - acc: 0.7485 - val_loss: 0.4641 - val_acc: 0.8275\n",
      "Epoch 815/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7469 - acc: 0.7456 - val_loss: 0.4642 - val_acc: 0.8275\n",
      "Epoch 816/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7557 - acc: 0.7427 - val_loss: 0.4639 - val_acc: 0.8246\n",
      "Epoch 817/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7254 - acc: 0.7325 - val_loss: 0.4658 - val_acc: 0.8304\n",
      "Epoch 818/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7936 - acc: 0.7281 - val_loss: 0.4694 - val_acc: 0.8275\n",
      "Epoch 819/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7560 - acc: 0.7427 - val_loss: 0.4722 - val_acc: 0.8158\n",
      "Epoch 820/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7444 - acc: 0.7266 - val_loss: 0.4728 - val_acc: 0.8187\n",
      "Epoch 821/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7365 - acc: 0.7485 - val_loss: 0.4717 - val_acc: 0.8099\n",
      "Epoch 822/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7777 - acc: 0.7325 - val_loss: 0.4624 - val_acc: 0.8275\n",
      "Epoch 823/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7858 - acc: 0.7515 - val_loss: 0.4702 - val_acc: 0.8246\n",
      "Epoch 824/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8095 - acc: 0.7281 - val_loss: 0.4688 - val_acc: 0.8216\n",
      "Epoch 825/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.7256 - acc: 0.7515 - val_loss: 0.4648 - val_acc: 0.8246\n",
      "Epoch 826/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7348 - acc: 0.7208 - val_loss: 0.4585 - val_acc: 0.8363\n",
      "Epoch 827/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8291 - acc: 0.7383 - val_loss: 0.4640 - val_acc: 0.8392\n",
      "Epoch 828/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7157 - acc: 0.7500 - val_loss: 0.4634 - val_acc: 0.8275\n",
      "Epoch 829/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.7458 - acc: 0.7398 - val_loss: 0.4533 - val_acc: 0.8275\n",
      "Epoch 830/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.7360 - acc: 0.7456 - val_loss: 0.4637 - val_acc: 0.8275\n",
      "Epoch 831/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.8090 - acc: 0.7383 - val_loss: 0.4509 - val_acc: 0.8304\n",
      "Epoch 832/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.7669 - acc: 0.7295 - val_loss: 0.4525 - val_acc: 0.8392\n",
      "Epoch 833/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.7245 - acc: 0.7632 - val_loss: 0.4439 - val_acc: 0.8450\n",
      "Epoch 834/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.7533 - acc: 0.7412 - val_loss: 0.4518 - val_acc: 0.8216\n",
      "Epoch 835/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.7933 - acc: 0.7368 - val_loss: 0.4616 - val_acc: 0.8275\n",
      "Epoch 836/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.7719 - acc: 0.7646 - val_loss: 0.4637 - val_acc: 0.8187\n",
      "Epoch 837/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.7453 - acc: 0.7368 - val_loss: 0.4671 - val_acc: 0.8099\n",
      "Epoch 838/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8149 - acc: 0.7456 - val_loss: 0.4667 - val_acc: 0.8187\n",
      "Epoch 839/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.7414 - acc: 0.7471 - val_loss: 0.4623 - val_acc: 0.8187\n",
      "Epoch 840/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.7618 - acc: 0.7383 - val_loss: 0.4738 - val_acc: 0.8216\n",
      "Epoch 841/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 3s 5ms/step - loss: 0.7282 - acc: 0.7500 - val_loss: 0.4653 - val_acc: 0.8275loss: 0.702\n",
      "Epoch 842/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.7612 - acc: 0.7325 - val_loss: 0.4663 - val_acc: 0.8304\n",
      "Epoch 843/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.6894 - acc: 0.7880 - val_loss: 0.4653 - val_acc: 0.8246\n",
      "Epoch 844/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7842 - acc: 0.7456 - val_loss: 0.4617 - val_acc: 0.8216\n",
      "Epoch 845/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7948 - acc: 0.7471 - val_loss: 0.4591 - val_acc: 0.8216\n",
      "Epoch 846/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7422 - acc: 0.7471 - val_loss: 0.4605 - val_acc: 0.8158\n",
      "Epoch 847/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7774 - acc: 0.7383 - val_loss: 0.4610 - val_acc: 0.8187\n",
      "Epoch 848/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8026 - acc: 0.7368 - val_loss: 0.4703 - val_acc: 0.8216\n",
      "Epoch 849/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7368 - acc: 0.7675 - val_loss: 0.4605 - val_acc: 0.8246\n",
      "Epoch 850/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.6706 - acc: 0.7602 - val_loss: 0.4545 - val_acc: 0.8275\n",
      "Epoch 851/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7023 - acc: 0.7646 - val_loss: 0.4601 - val_acc: 0.8216\n",
      "Epoch 852/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7941 - acc: 0.7354 - val_loss: 0.4638 - val_acc: 0.8158\n",
      "Epoch 853/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7088 - acc: 0.7573 - val_loss: 0.4636 - val_acc: 0.8216\n",
      "Epoch 854/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7385 - acc: 0.7617 - val_loss: 0.4564 - val_acc: 0.8158\n",
      "Epoch 855/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7758 - acc: 0.7368 - val_loss: 0.4615 - val_acc: 0.8187\n",
      "Epoch 856/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.6991 - acc: 0.7675 - val_loss: 0.4594 - val_acc: 0.8275\n",
      "Epoch 857/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7803 - acc: 0.7558 - val_loss: 0.4569 - val_acc: 0.8275\n",
      "Epoch 858/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7587 - acc: 0.7456 - val_loss: 0.4563 - val_acc: 0.8421\n",
      "Epoch 859/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8010 - acc: 0.7573 - val_loss: 0.4565 - val_acc: 0.8392\n",
      "Epoch 860/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7908 - acc: 0.7091 - val_loss: 0.4641 - val_acc: 0.8275\n",
      "Epoch 861/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.7234 - acc: 0.7705 - val_loss: 0.4748 - val_acc: 0.8158\n",
      "Epoch 862/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.7895 - acc: 0.7383 - val_loss: 0.4642 - val_acc: 0.8129\n",
      "Epoch 863/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7038 - acc: 0.7763 - val_loss: 0.4647 - val_acc: 0.8246\n",
      "Epoch 864/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7366 - acc: 0.7398 - val_loss: 0.4703 - val_acc: 0.8187\n",
      "Epoch 865/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7159 - acc: 0.7515 - val_loss: 0.4663 - val_acc: 0.8246\n",
      "Epoch 866/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7999 - acc: 0.7544 - val_loss: 0.4673 - val_acc: 0.8216\n",
      "Epoch 867/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7847 - acc: 0.7237 - val_loss: 0.4654 - val_acc: 0.8246\n",
      "Epoch 868/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7421 - acc: 0.7398 - val_loss: 0.4483 - val_acc: 0.8421\n",
      "Epoch 869/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7576 - acc: 0.7485 - val_loss: 0.4490 - val_acc: 0.8304\n",
      "Epoch 870/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7446 - acc: 0.7646 - val_loss: 0.4377 - val_acc: 0.8509\n",
      "Epoch 871/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7631 - acc: 0.7295 - val_loss: 0.4622 - val_acc: 0.8216\n",
      "Epoch 872/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.7588 - acc: 0.7588 - val_loss: 0.4569 - val_acc: 0.8187\n",
      "Epoch 873/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7988 - acc: 0.7368 - val_loss: 0.4649 - val_acc: 0.8158\n",
      "Epoch 874/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7449 - acc: 0.7266 - val_loss: 0.4638 - val_acc: 0.8216\n",
      "Epoch 875/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.6743 - acc: 0.7617 - val_loss: 0.4663 - val_acc: 0.8041\n",
      "Epoch 876/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7584 - acc: 0.7310 - val_loss: 0.4612 - val_acc: 0.8216\n",
      "Epoch 877/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7447 - acc: 0.7339 - val_loss: 0.4626 - val_acc: 0.8216\n",
      "Epoch 878/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.7381 - acc: 0.7529 - val_loss: 0.4566 - val_acc: 0.8216\n",
      "Epoch 879/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7743 - acc: 0.7427 - val_loss: 0.4579 - val_acc: 0.8187\n",
      "Epoch 880/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.6809 - acc: 0.7661 - val_loss: 0.4508 - val_acc: 0.8304\n",
      "Epoch 881/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7711 - acc: 0.7310 - val_loss: 0.4643 - val_acc: 0.8012\n",
      "Epoch 882/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.7485 - acc: 0.7442 - val_loss: 0.4604 - val_acc: 0.8129\n",
      "Epoch 883/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.6944 - acc: 0.7661 - val_loss: 0.4503 - val_acc: 0.8304\n",
      "Epoch 884/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.6906 - acc: 0.7573 - val_loss: 0.4587 - val_acc: 0.8275\n",
      "Epoch 885/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7424 - acc: 0.7588 - val_loss: 0.4607 - val_acc: 0.8187\n",
      "Epoch 886/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7258 - acc: 0.7515 - val_loss: 0.4582 - val_acc: 0.8304\n",
      "Epoch 887/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7432 - acc: 0.7544 - val_loss: 0.4642 - val_acc: 0.8275\n",
      "Epoch 888/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.6632 - acc: 0.7778 - val_loss: 0.4535 - val_acc: 0.8246\n",
      "Epoch 889/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.7151 - acc: 0.7778 - val_loss: 0.4622 - val_acc: 0.8246\n",
      "Epoch 890/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7328 - acc: 0.7354 - val_loss: 0.4615 - val_acc: 0.8246\n",
      "Epoch 891/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7108 - acc: 0.7500 - val_loss: 0.4581 - val_acc: 0.8275\n",
      "Epoch 892/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.6462 - acc: 0.7749 - val_loss: 0.4475 - val_acc: 0.8275\n",
      "Epoch 893/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7176 - acc: 0.7456 - val_loss: 0.4553 - val_acc: 0.8187\n",
      "Epoch 894/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.6725 - acc: 0.7719 - val_loss: 0.4576 - val_acc: 0.8216\n",
      "Epoch 895/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7221 - acc: 0.7500 - val_loss: 0.4587 - val_acc: 0.8187\n",
      "Epoch 896/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7903 - acc: 0.7383 - val_loss: 0.4591 - val_acc: 0.8187\n",
      "Epoch 897/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7068 - acc: 0.7471 - val_loss: 0.4534 - val_acc: 0.8187\n",
      "Epoch 898/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7315 - acc: 0.7661 - val_loss: 0.4492 - val_acc: 0.8216\n",
      "Epoch 899/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.6769 - acc: 0.7690 - val_loss: 0.4519 - val_acc: 0.8216\n",
      "Epoch 900/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7484 - acc: 0.7529 - val_loss: 0.4498 - val_acc: 0.8275\n",
      "Epoch 901/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7120 - acc: 0.7719 - val_loss: 0.4476 - val_acc: 0.8275\n",
      "Epoch 902/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.6802 - acc: 0.7792 - val_loss: 0.4523 - val_acc: 0.8187\n",
      "Epoch 903/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7021 - acc: 0.7632 - val_loss: 0.4476 - val_acc: 0.8275\n",
      "Epoch 904/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7003 - acc: 0.7734 - val_loss: 0.4487 - val_acc: 0.8304\n",
      "Epoch 905/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.7486 - acc: 0.7734 - val_loss: 0.4365 - val_acc: 0.8275\n",
      "Epoch 906/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7030 - acc: 0.7456 - val_loss: 0.4391 - val_acc: 0.8246\n",
      "Epoch 907/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7041 - acc: 0.7573 - val_loss: 0.4364 - val_acc: 0.8246\n",
      "Epoch 908/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.6962 - acc: 0.7661 - val_loss: 0.4474 - val_acc: 0.8158\n",
      "Epoch 909/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7226 - acc: 0.7529 - val_loss: 0.4490 - val_acc: 0.8158\n",
      "Epoch 910/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7020 - acc: 0.7544 - val_loss: 0.4469 - val_acc: 0.8099\n",
      "Epoch 911/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7667 - acc: 0.7602 - val_loss: 0.4352 - val_acc: 0.8275\n",
      "Epoch 912/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8086 - acc: 0.7427 - val_loss: 0.4336 - val_acc: 0.8333\n",
      "Epoch 913/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8044 - acc: 0.7237 - val_loss: 0.4414 - val_acc: 0.8304\n",
      "Epoch 914/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7295 - acc: 0.7529 - val_loss: 0.4431 - val_acc: 0.8187\n",
      "Epoch 915/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7090 - acc: 0.7515 - val_loss: 0.4506 - val_acc: 0.8158\n",
      "Epoch 916/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7169 - acc: 0.7529 - val_loss: 0.4461 - val_acc: 0.8246\n",
      "Epoch 917/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8044 - acc: 0.7251 - val_loss: 0.4421 - val_acc: 0.8392\n",
      "Epoch 918/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7455 - acc: 0.7646 - val_loss: 0.4503 - val_acc: 0.8246\n",
      "Epoch 919/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7228 - acc: 0.7500 - val_loss: 0.4534 - val_acc: 0.8304\n",
      "Epoch 920/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.6731 - acc: 0.7719 - val_loss: 0.4466 - val_acc: 0.8246\n",
      "Epoch 921/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7352 - acc: 0.7471 - val_loss: 0.4358 - val_acc: 0.8333\n",
      "Epoch 922/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7477 - acc: 0.7412 - val_loss: 0.4467 - val_acc: 0.8099\n",
      "Epoch 923/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7514 - acc: 0.7485 - val_loss: 0.4528 - val_acc: 0.8129\n",
      "Epoch 924/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.6910 - acc: 0.7749 - val_loss: 0.4529 - val_acc: 0.8304\n",
      "Epoch 925/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7230 - acc: 0.7500 - val_loss: 0.4513 - val_acc: 0.8304\n",
      "Epoch 926/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7114 - acc: 0.7661 - val_loss: 0.4400 - val_acc: 0.8333\n",
      "Epoch 927/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7631 - acc: 0.7485 - val_loss: 0.4407 - val_acc: 0.8246\n",
      "Epoch 928/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7390 - acc: 0.7529 - val_loss: 0.4434 - val_acc: 0.8187\n",
      "Epoch 929/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.6722 - acc: 0.7763 - val_loss: 0.4385 - val_acc: 0.8246\n",
      "Epoch 930/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7317 - acc: 0.7442 - val_loss: 0.4405 - val_acc: 0.8275\n",
      "Epoch 931/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7607 - acc: 0.7442 - val_loss: 0.4362 - val_acc: 0.8363\n",
      "Epoch 932/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7628 - acc: 0.7339 - val_loss: 0.4385 - val_acc: 0.8363\n",
      "Epoch 933/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7376 - acc: 0.7544 - val_loss: 0.4436 - val_acc: 0.8275\n",
      "Epoch 934/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.6731 - acc: 0.7617 - val_loss: 0.4330 - val_acc: 0.8480\n",
      "Epoch 935/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8422 - acc: 0.7339 - val_loss: 0.4573 - val_acc: 0.8216\n",
      "Epoch 936/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7026 - acc: 0.7602 - val_loss: 0.4441 - val_acc: 0.8509\n",
      "Epoch 937/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7534 - acc: 0.7471 - val_loss: 0.4501 - val_acc: 0.8421\n",
      "Epoch 938/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7329 - acc: 0.7588 - val_loss: 0.4435 - val_acc: 0.8421\n",
      "Epoch 939/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7263 - acc: 0.7661 - val_loss: 0.4426 - val_acc: 0.8304\n",
      "Epoch 940/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7335 - acc: 0.7588 - val_loss: 0.4323 - val_acc: 0.8392\n",
      "Epoch 941/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7510 - acc: 0.7529 - val_loss: 0.4367 - val_acc: 0.8333\n",
      "Epoch 942/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7202 - acc: 0.7471 - val_loss: 0.4393 - val_acc: 0.8421\n",
      "Epoch 943/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.7312 - acc: 0.7588 - val_loss: 0.4326 - val_acc: 0.8363\n",
      "Epoch 944/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7828 - acc: 0.7383 - val_loss: 0.4397 - val_acc: 0.8304\n",
      "Epoch 945/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7088 - acc: 0.7690 - val_loss: 0.4400 - val_acc: 0.8333\n",
      "Epoch 946/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7249 - acc: 0.7544 - val_loss: 0.4391 - val_acc: 0.8275\n",
      "Epoch 947/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7705 - acc: 0.7544 - val_loss: 0.4433 - val_acc: 0.8275\n",
      "Epoch 948/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.7709 - acc: 0.7485 - val_loss: 0.4371 - val_acc: 0.8333\n",
      "Epoch 949/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.6944 - acc: 0.7719 - val_loss: 0.4452 - val_acc: 0.8246\n",
      "Epoch 950/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7509 - acc: 0.7544 - val_loss: 0.4297 - val_acc: 0.8363\n",
      "Epoch 951/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7834 - acc: 0.7719 - val_loss: 0.4367 - val_acc: 0.8246\n",
      "Epoch 952/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7844 - acc: 0.7368 - val_loss: 0.4449 - val_acc: 0.8187\n",
      "Epoch 953/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7455 - acc: 0.7558 - val_loss: 0.4430 - val_acc: 0.8246\n",
      "Epoch 954/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.6635 - acc: 0.7822 - val_loss: 0.4263 - val_acc: 0.8392\n",
      "Epoch 955/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.6842 - acc: 0.7749 - val_loss: 0.4275 - val_acc: 0.8363\n",
      "Epoch 956/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.6942 - acc: 0.7617 - val_loss: 0.4325 - val_acc: 0.8304\n",
      "Epoch 957/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7151 - acc: 0.7602 - val_loss: 0.4305 - val_acc: 0.8363\n",
      "Epoch 958/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7412 - acc: 0.7529 - val_loss: 0.4291 - val_acc: 0.8304\n",
      "Epoch 959/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7493 - acc: 0.7573 - val_loss: 0.4355 - val_acc: 0.8304\n",
      "Epoch 960/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7697 - acc: 0.7383 - val_loss: 0.4414 - val_acc: 0.8275\n",
      "Epoch 961/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7413 - acc: 0.7675 - val_loss: 0.4415 - val_acc: 0.8246\n",
      "Epoch 962/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7174 - acc: 0.7719 - val_loss: 0.4411 - val_acc: 0.8187\n",
      "Epoch 963/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.6908 - acc: 0.7792 - val_loss: 0.4381 - val_acc: 0.8187\n",
      "Epoch 964/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7406 - acc: 0.7442 - val_loss: 0.4396 - val_acc: 0.8158\n",
      "Epoch 965/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7928 - acc: 0.7281 - val_loss: 0.4444 - val_acc: 0.8216\n",
      "Epoch 966/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7517 - acc: 0.7690 - val_loss: 0.4375 - val_acc: 0.8363\n",
      "Epoch 967/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8057 - acc: 0.7456 - val_loss: 0.4452 - val_acc: 0.8216\n",
      "Epoch 968/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7216 - acc: 0.7602 - val_loss: 0.4424 - val_acc: 0.8246\n",
      "Epoch 969/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7387 - acc: 0.7515 - val_loss: 0.4394 - val_acc: 0.8216\n",
      "Epoch 970/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7184 - acc: 0.7617 - val_loss: 0.4371 - val_acc: 0.8129\n",
      "Epoch 971/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7189 - acc: 0.7617 - val_loss: 0.4292 - val_acc: 0.8216\n",
      "Epoch 972/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.6600 - acc: 0.7807 - val_loss: 0.4237 - val_acc: 0.8363\n",
      "Epoch 973/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7397 - acc: 0.7500 - val_loss: 0.4284 - val_acc: 0.8333\n",
      "Epoch 974/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.6745 - acc: 0.7734 - val_loss: 0.4247 - val_acc: 0.8304\n",
      "Epoch 975/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7060 - acc: 0.7515 - val_loss: 0.4295 - val_acc: 0.8246\n",
      "Epoch 976/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7428 - acc: 0.7690 - val_loss: 0.4331 - val_acc: 0.8216\n",
      "Epoch 977/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.6851 - acc: 0.7573 - val_loss: 0.4222 - val_acc: 0.8392\n",
      "Epoch 978/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7084 - acc: 0.7807 - val_loss: 0.4262 - val_acc: 0.8275\n",
      "Epoch 979/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.6703 - acc: 0.7661 - val_loss: 0.4191 - val_acc: 0.8421\n",
      "Epoch 980/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7154 - acc: 0.7558 - val_loss: 0.4111 - val_acc: 0.8567\n",
      "Epoch 981/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7636 - acc: 0.7485 - val_loss: 0.4291 - val_acc: 0.8509\n",
      "Epoch 982/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.6775 - acc: 0.7865 - val_loss: 0.4198 - val_acc: 0.8450\n",
      "Epoch 983/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7206 - acc: 0.7500 - val_loss: 0.4108 - val_acc: 0.8421\n",
      "Epoch 984/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7532 - acc: 0.7632 - val_loss: 0.4139 - val_acc: 0.8392\n",
      "Epoch 985/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7626 - acc: 0.7778 - val_loss: 0.4252 - val_acc: 0.8275\n",
      "Epoch 986/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7854 - acc: 0.7427 - val_loss: 0.4221 - val_acc: 0.8275\n",
      "Epoch 987/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7523 - acc: 0.7515 - val_loss: 0.4218 - val_acc: 0.8275\n",
      "Epoch 988/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.6999 - acc: 0.7778 - val_loss: 0.4146 - val_acc: 0.8421\n",
      "Epoch 989/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7089 - acc: 0.7734 - val_loss: 0.4195 - val_acc: 0.8304\n",
      "Epoch 990/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7268 - acc: 0.7719 - val_loss: 0.4221 - val_acc: 0.8333\n",
      "Epoch 991/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.6784 - acc: 0.7690 - val_loss: 0.4208 - val_acc: 0.8304\n",
      "Epoch 992/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.6761 - acc: 0.7661 - val_loss: 0.4239 - val_acc: 0.8187\n",
      "Epoch 993/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7039 - acc: 0.7485 - val_loss: 0.4269 - val_acc: 0.8392\n",
      "Epoch 994/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7596 - acc: 0.7632 - val_loss: 0.4245 - val_acc: 0.8333\n",
      "Epoch 995/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7431 - acc: 0.7485 - val_loss: 0.4295 - val_acc: 0.8392\n",
      "Epoch 996/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.6713 - acc: 0.7763 - val_loss: 0.4237 - val_acc: 0.8333\n",
      "Epoch 997/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7291 - acc: 0.7705 - val_loss: 0.4248 - val_acc: 0.8363\n",
      "Epoch 998/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.6682 - acc: 0.7719 - val_loss: 0.4248 - val_acc: 0.8392\n",
      "Epoch 999/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.6955 - acc: 0.7500 - val_loss: 0.4170 - val_acc: 0.8480\n",
      "Epoch 1000/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.6898 - acc: 0.7763 - val_loss: 0.4097 - val_acc: 0.8538\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pickle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-d7bf982d527d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./history/model213182331.h5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./history/history213182331.pkl'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfile_pi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_pi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'pickle' is not defined"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train_shuffle, Y_train_shuffle,validation_data=(x_test, Y_test), epochs=1000, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(\"./history/model26032024.h5\")\n",
    "with open('./history/history26032024.pkl', 'wb') as file_pi:\n",
    "    pickle.dump(history.history, file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = load_model(\"./history/model26032024.h5\")\n",
    "with open('./history/history26032024.pkl', 'rb') as handle:\n",
    "    load_history = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "342/342 [==============================] - 0s 301us/step\n",
      "Test score: 0.409651071007\n",
      "Test accuracy: 0.853801170288\n"
     ]
    }
   ],
   "source": [
    "score, acc = model.evaluate(x_test, Y_test)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# list all data in history\n",
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x26189dd9978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3Xd4VFX6wPHvm94IgSS00HuVKkUU\naSrN3nvHupa1gYp1betvbevaRdeuCxYUFARBmoB06b2EGgIESAhp5/fHuZnMJJNKJm3ez/PkmVvO\nvXNuBubN6WKMQSmllAIIqOwMKKWUqjo0KCillHLRoKCUUspFg4JSSikXDQpKKaVcNCgopZRy0aCg\nVAmJyMci8o8Spt0mIkNP9j5KVTQNCkoppVw0KCillHLRoKBqFKfa5iERWSkiqSLyoYjUF5GfReSo\niEwXkTpu6c8TkdUiclhEZolIB7dz3UVkqXPd10BYvvcaJSLLnWvni8gpZczzrSKySUQOisgkEWnk\nHBcReVVE9otIivNMnZ1zI0RkjZO3XSLyYJl+YUrlo0FB1UQXA2cBbYFzgZ+BR4E47L/5ewBEpC3w\nJXAfEA9MAX4UkRARCQG+Bz4F6gL/c+6Lc20PYDxwGxALvAtMEpHQ0mRURAYDLwCXAQ2B7cBXzumz\ngQHOc8QAlwPJzrkPgduMMbWAzsBvpXlfpQqjQUHVRP82xuwzxuwC5gALjTHLjDEngO+A7k66y4HJ\nxphfjTGZwP8B4cBpQF8gGHjNGJNpjJkA/On2HrcC7xpjFhpjso0x/wVOONeVxtXAeGPMUid/Y4F+\nItIcyARqAe0BMcasNcbsca7LBDqKSLQx5pAxZmkp31cprzQoqJpon9v2cS/7Uc52I+xf5gAYY3KA\nnUCCc26X8ZwxcrvbdjPgAafq6LCIHAaaONeVRv48HMOWBhKMMb8BbwL/AfaJyHsiEu0kvRgYAWwX\nkd9FpF8p31cprzQoKH+2G/vlDtg6fOwX+y5gD5DgHMvV1G17J/CcMSbG7SfCGPPlSeYhElsdtQvA\nGPOGMaYn0AlbjfSQc/xPY8z5QD1sNdc3pXxfpbzSoKD82TfASBEZIiLBwAPYKqD5wB9AFnCPiASJ\nyEVAb7dr3wduF5E+ToNwpIiMFJFapczDF8CNItLNaY94HlvdtU1ETnXuHwykAulAttPmcbWI1Haq\nvY4A2Sfxe1DKRYOC8lvGmPXANcC/gQPYRulzjTEZxpgM4CLgBuAQtv3hW7drF2PbFd50zm9y0pY2\nDzOAccBEbOmkFXCFczoaG3wOYauYkrHtHgDXAttE5Ahwu/McSp000UV2lFJK5dKSglJKKRcNCkop\npVw0KCillHLRoKCUUsolqLIzUFpxcXGmefPmlZ0NpZSqVpYsWXLAGBNfXLpqFxSaN2/O4sWLKzsb\nSilVrYjI9uJTafWRUkopNxoUlFJKuWhQUEop5eKzNgURCQNmA6HO+0wwxjyZL00o8AnQEzuE/3Jj\nzLbSvldmZiaJiYmkp6efdL6rurCwMBo3bkxwcHBlZ0UpVQP5sqH5BDDYGHPMmdBrroj8bIxZ4Jbm\nZuCQMaa1iFwBvISdY6ZUEhMTqVWrFs2bN8dzUsuaxRhDcnIyiYmJtGjRorKzo5SqgXxWfWSsY85u\nsPOTf6Kl84H/OtsTgCFShm/19PR0YmNja3RAABARYmNj/aJEpJSqHD5tUxCRQBFZDuwHfjXGLMyX\nJAE7Lz3GmCwgBTuXfP77jBaRxSKyOCkpqbD3Kte8V1X+8pxKqcrh06DgLFPYDWgM9M5ddNyNt2+4\nAtO2GmPeM8b0Msb0io8vduyFV+kZ2ew9nEp2Tk6ZrldKKX9QIb2PjDGHgVnAsHynErErXSEiQUBt\n4KBP8nD8IA3SNpCRfrzc73348GHeeuutUl83YsQIDh8+XO75UUqpsvJZUBCReBGJcbbDgaHAunzJ\nJgHXO9uXAL8ZHy3wkNtb50RmZrnfu7CgkJ1d9GJYU6ZMISYmptzzo5RSZeXL3kcNgf+KSCA2+Hxj\njPlJRJ4BFhtjJgEfAp+KyCZsCeGKwm93cgID7aNmZ2WV+73HjBnD5s2b6datG8HBwURFRdGwYUOW\nL1/OmjVruOCCC9i5cyfp6ence++9jB49GsibsuPYsWMMHz6c008/nfnz55OQkMAPP/xAeHh4uedV\nKaWK4rOgYIxZCXT3cvwJt+104NLyfN+nf1zNmt1HvGQoBzLTyJQjBAeHlOqeHRtF8+S5nQo9/+KL\nL7Jq1SqWL1/OrFmzGDlyJKtWrXJ1Gx0/fjx169bl+PHjnHrqqVx88cXExnq2p2/cuJEvv/yS999/\nn8suu4yJEydyzTW6wqJSqmJVuwnxTp7vlx/t3bu3xziCN954g++++w6AnTt3snHjxgJBoUWLFnTr\n1g2Anj17sm3bNp/nUyml8qtxQaHQv+hzsmDvXyRJHPENm/g0D5GRka7tWbNmMX36dP744w8iIiIY\nOHCg13EGoaGhru3AwECOHy//BnGllCqO/8x9JIH21ZR/l9RatWpx9OhRr+dSUlKoU6cOERERrFu3\njgULFnhNp5RSVUGNKykUSsRWHPkgKMTGxtK/f386d+5MeHg49evXd50bNmwY77zzDqeccgrt2rWj\nb9++5f7+SilVXsRHPUB9plevXib/Ijtr166lQ4cOxV6bs3sFySaKuEYtq/XI4JI+r1JK5RKRJcaY\nXsWl85/qIwARAjBk51SvQKiUUhXFr4KCIQDBoDFBKaW886ugkFtSyKlmVWZKKVVR/Cwo5JYUNCgo\npZQ3fhYUnJKCTpSqlFJe+VdQQEsKSilVFP8KCgEBPmlTKOvU2QCvvfYaaWlp5ZofpZQqK78KCiLi\nk5KCBgWlVE3hPyOaASSAAHLKvU3Bferss846i3r16vHNN99w4sQJLrzwQp5++mlSU1O57LLLSExM\nJDs7m3HjxrFv3z52797NoEGDiIuLY+bMmeWbMaWUKqWaFxR+HgN7//J6SrLSCc7JIjowAgJLUUhq\n0AWGv1joafeps6dNm8aECRNYtGgRxhjOO+88Zs+eTVJSEo0aNWLy5MmAnROpdu3avPLKK8ycOZO4\nuLhSPaZSSvmCf1UfOT/Gh9NnT5s2jWnTptG9e3d69OjBunXr2LhxI126dGH69Ok88sgjzJkzh9q1\na/ssD0opVVY1r6RQxF/0pOzCpCaRHNGORjG+WdXMGMPYsWO57bbbCpxbsmQJU6ZMYezYsZx99tk8\n8cQTXu6glFKVx69KCjgNzeU995H71NnnnHMO48eP59ixYwDs2rWL/fv3s3v3biIiIrjmmmt48MEH\nWbp0aYFrlVKqstW8kkJRJMBWH5Xz9NnuU2cPHz6cq666in79+gEQFRXFZ599xqZNm3jooYcICAgg\nODiYt99+G4DRo0czfPhwGjZsqA3NSqlK51dTZ3NsHxzZzfbgVjSLj/ZRDn1Pp85WSpWWTp3tTWAI\nACE5utSlUkp5419BIdiunRxgsio5I0opVTXVmKBQomqw3NXWqlmVmbvqVt2nlKpeakRQCAsLIzk5\nuQRfmDYoVNcvVmMMycnJhIWFVXZWlFI1VI3ofdS4cWMSExNJSkoqOqHJgZT9pJDGoZRjFZO5chYW\nFkbjxo0rOxtKqRqqRgSF4OBgWrRoUXzCzOPw3Gm8lHUlDz/7NpJbnaSUUgqoIdVHJRZgY2CAySYj\nW1faUUqp/PwrKEggAMGSRdqJ7ErOjFJKVT3+FRQCAsghgEBySM3QbqlKKZWffwUFwAQEEUQ2xzO0\npKCUUvn5LCiISBMRmSkia0VktYjc6yXNQBFJEZHlzo/Ppw3NDQqpGhSUUqoAX/Y+ygIeMMYsFZFa\nwBIR+dUYsyZfujnGmFE+zIcnCSSIbI6la/WRUkrl57OSgjFmjzFmqbN9FFgLJPjq/UpKAoMJJIeZ\n6/dXdlaUUqrKqZA2BRFpDnQHFno53U9EVojIzyLSqZDrR4vIYhFZXOwAtWIEBgUTFxHA2j1HTuo+\nSilVE/k8KIhIFDARuM8Yk/+beCnQzBjTFfg38L23exhj3jPG9DLG9IqPjz+5DAUEERsRwJak1JO7\nj1JK1UA+DQoiEowNCJ8bY77Nf94Yc8QYc8zZngIEi4hvV7APCKJ2aAB7j6Rz7IS2KyillDtf9j4S\n4ENgrTHmlULSNHDSISK9nfwk+ypPAAQEEW2XVWDOhpOrilJKqZrGlyWF/sC1wGC3LqcjROR2Ebnd\nSXMJsEpEVgBvAFcYX09hGhBEeKB9izs+X+rTt1JKqerGZ11SjTFzyZ2ruvA0bwJv+ioPXgUEESp5\nYxSysnMICvS7MXxKKeWV/30bhkYRmpPm2t17JL0SM6OUUlWL/wWFiFgC0w+5dlN1YjyllHLxw6BQ\nF9IO8tENpwLoxHhKKeXG/4JCeF1ISyYi2D76r2v2VXKGlFKq6vC/oBARC9kniAzIBODtWZuZrV1T\nlVIK8MugUBeAqJwU16GfV+2trNwopVSV4odBIda+ZOcFhcRDaYWlVkopv+K3QSEyKy8o7D9yorJy\no5RSVYr/BYVwW30UmX2ERY8N4YpTm7DvqI5VUEop8Meg4JQUSEumXq0wOjSM5nBaJjuSbRVS8rET\npGk3VaWUn/K/oBAeY1/nvgpA54TaAHw8fxu/rtlHz39M54L/zKus3CmlVKXy5XKcVVNAoH09ugeA\n6DD7Kxg/byvj520FYMO+Y5WSNaWUqmz+V1IAqNvKvh4/RK2w4MrNi1JKVSH+GRR63Whf/3setcL8\nr7CklFKF8c+gkO50R927koiQwMrNi1JKVSH+GRQSetnX0Gichd+UUkrhr0Gh3TBo1AOiG4ExjOjS\noLJzpJRSVYJ/BgWA9iMhaR2k7CQuKrSyc6OUUlWC/waF2Nb29bUuPDi0JQ+e3dbjtE6prZTyR/4b\nFEIiXZvRHOfuwW08Tt/6yWL+/vXyis6VUkpVKv8NCsHheduZqQCEBXv+Or5dtqsic6SUUpXOj4NC\nRN52hp336PkLu1RSZpRSqmrw36DgVn2UW1K4qEfjSsqMUkpVDf4bFNyrj3Ys9JqkRVyk1+NKKVVT\n+XFQcPvCnzq2wOm29aM4kZldgRlSSqnK579BITIWzn2jwOHv7jyNZy/ozKnN63IiK6cSMqaUUpXH\nf4MCQM/rIaQWxHdwHeretA7X9m1GaFCgBgWllN/x76AA0PE8yCi4fkJocAAZGhSUUn5Gg0JkHBzd\nC8eSPA6HBgWQkZ1DTo6ppIwppVTF81lQEJEmIjJTRNaKyGoRuddLGhGRN0Rkk4isFJEevspPobpe\nBTlZMO81j8OhQXZK7ZaPTmHtniMVni2llKoMviwpZAEPGGM6AH2Bu0SkY740w4E2zs9o4G0f5se7\neu0hpgn88Sbk5FUXNa2bN7ht+Otz2HckvcKzppRSFc1nQcEYs8cYs9TZPgqsBRLyJTsf+MRYC4AY\nEWnoqzwV6vAO+7p7mevQkNa16Neirmt/7sYDFZ0rpZSqcBXSpiAizYHuQP5RYgnATrf9RAoGDkRk\ntIgsFpHFSUlJ+U+fvNP/bl8/GAyZxyH9CGH/TODLtrPY8vwIwoMDWb1bq5CUUjWfz4OCiEQBE4H7\njDH5v1m9LXtWoGXXGPOeMaaXMaZXfHx8+Weyx7V52ymJkOaUCpZ/QUCA0LpeFBv3HwXgHz+tYf5m\nLTUopWomnwYFEQnGBoTPjTHfekmSCDRx228M7PZlnryKdAs0J45CdqbdDrC/njb1oti0/xg5OYYP\n5m7lqve9T4uhlFLVnS97HwnwIbDWGPNKIckmAdc5vZD6AinGmD2+ylOhQmtBuxF2e9lneeMWxP56\nWtePYk9KOknHTlR41pRSqiL5sqTQH7gWGCwiy52fESJyu4jc7qSZAmwBNgHvA3f6MD9FG/y4fV38\nIZzwDAoJMXbyvNkbPNszUo5nVlj2lFKqIgT56sbGmLl4bzNwT2OAu3yVh1KJdmvfzrBTaSN2rELu\nGs4PTVjpSvLD8l3c+9Vy3rmmJ8M6N6iwbCqllC/piOZc4THQ43qIrFeg+qhuZEiB5Kt2pQDw7dLE\nCsuiUkr5mgYFd1H1IHU/bJ5p9wNsSaFBdFiBpO/P2QrAobSMCsueUkr5mgYFdxFx9nXFF/bVKSnU\niQzhuztPo3Z4MPG1Qj0uCQrQX6FSqubQbzR3obUKPdW9aR1WPHk2n93cx+N4UKCQk2M4npHN0h2H\nsM0kSilVPfmsoblaMvmmys4q2AU1IiTQYz9AhJenreftWZsBeHxkB245o6XPsqiUUr6kJQV3LQZ4\n7mceL5AkNMjzV/b7hiRXQACYtKLix94ppVR50aDgrk4zeColbz8zFXYv91hrIS4qlGv6NmXKPWd4\nvcXeFJ1NVSlVfWlQ8Oa6H6BWQ1tSeO9MeDcvAAQECP+4oAsdG0V7vXT/UR31rJSqvjQoeNNyIPS4\nDjLT7P7R0s28kXoiq9yzpJRSFUGDQmGCw4tNcm3fZsREBPPYiA4exzfsO+qrXCmllE9pUChMZD3P\n/fSUAkmevaAzy584m1sHePY2uvCt+SzbcciXuVNKKZ/QoFCY6Eae+xNvKdXlr/y6oRwzo5RSFaNE\nQUFE7hWRaGeK6w9FZKmInO3rzFWqevmWk96/tsjkMx8cyHvX9nTtL9952Be5UkopnyppSeEmZ9W0\ns4F44EbgRZ/lqiqoVR8e2Za3HxkHUx6C1GSvyVvERXJ2pwZc2bspAEfTs0jPzK6AjCqlVPkpaVDI\nnQJ7BPCRMWYFxUyLXSOE14GrJ9jt3ctg0Xsw4+kiL3nhoi6c1ioWgHu/WsbB1AxS0nTdBaVU9VDS\noLBERKZhg8JUEakF5BRzTc3Q5iwIdJsEL7v4WVFfv6I7AL+u2UePZ3/l9H/+xpLth/j5r4pfVE4p\npUqjpEHhZmAMcKoxJg0IxlYh+Yfs0g1Ii68VygfX9SLHmRvvaHoWF789nzs+X+qDzCmlVPkpaVDo\nB6w3xhwWkWuAx4GCfTRrqvqd87ZLOAvqwHbxPsqMUkr5TkmDwttAmoh0BR4GtgOf+CxXVc3N00p9\nSVCg9vZVSlU/Jf3mynLWUz4feN0Y8zpQ+OIDNU1IJDTqYbf3rT6pWyUeslNn7Ek5rr2TlFJVTkmD\nwlERGQtcC0wWkUBsu4L/uOkXu4bzvr9g+x8w49lCu6fmuuG05pzSuLbHsdNfmknioTT6vfAb93y5\nzJc5VkqpUitpULgcOIEdr7AXSABe9lmuqqKgUOg92m5/NAzm/B/M+VeRlzx1Xicm3X16gePzNh0A\nYNqafeWeTaWUOhklCgpOIPgcqC0io4B0Y4z/tCnkim3tuZ9VtrUTNu0/Vg6ZUUqp8lfSaS4uAxYB\nlwKXAQtF5BJfZqxKCg6DThfl7R/eUaLLggI8x/m9P2era3vbgVSSdA0GpVQVISVZaF5EVgBnGWP2\nO/vxwHRjTFcf56+AXr16mcWLF1f02+bJTIedC2DxR7BpBgwaC1MfhXYj4covvF6yPTmVEa/PITWj\n8IblrS+MQET4ZdVemsdF0L6B90V8lFKqLERkiTGmV3HpStqmEJAbEBzJpbi2ZgkOs4vwtDgDMo7a\ngACwfnKhlzSLjWR4l4ZF3naPs4zn7Z8tYdhrc8ops0opVTol/WL/RUSmisgNInIDMBmY4rtsVQO9\nboZRr3oey0yHVd96Tf74yA7EReVNl9EsNsLj/Lbk1HLPolJKlVZQSRIZYx4SkYuB/tiJ8N4zxnzn\n05xVdSLQ6ybIzoSfH4bQaPhlDCz5CGo3hia9PZLHRISw+PGhpGVksSclnRaxkbR8NC+uPvrtX8x4\nYGAFP4RSSnkqcRWQMWaiMebvxpj7/T4guOtzG3S9Ck4csQEBbKAoRERIEK3iowgIEOY8PMh1fFty\nGmv3HPF1bpVSqkhFBgUROSoiR7z8HBUR/QbLFZevq6qULNY2qRtB1yYxrv1R/57rNd3Xf+6g+ZjJ\nHE3XKbiVUr5V5LeXMaaWMSbay08tY0yR3WNEZLyI7BeRVYWcHygiKSKy3Pl54mQepFKd/nfP/cy0\nEl/63R2neT1+/ptzme8Mcnv39y0A7DuiXVeVUr5VojaFMvoYeJOiJ86bY4wZ5cM8VAwRiE6AI7vs\nfikGtQUEeF+raEViCld9sNDjWGAhaZVSqrz4rFupMWY2cNBX969yrv5f3nbm8VJduu3FkTSsHUZU\naBDX9G1aaLrMbP9Y10gpVXkqe6xBPxFZISI/i0inwhKJyGgRWSwii5OSkioyfyVXvxPc95fdnnhz\nkY3N3sx6aCBLxg3lzoGtC02zYEsy/56xUWdXVUr5jC+rj4qzFGhmjDkmIiOA74E23hIaY94D3gM7\nornislhKQeF520f3QkyTEl8aGhQIQGxUSKFpnvjBTttdKyyIYyeyeHvWZlY/M6xseVVKKS8qraRg\njDlijDnmbE8BgkUkrrLyUy5Co/K2575StlsEBfLQOe14dET7QtPsTknn/6ZtIDUjW6uUlFLlqtKC\ngog0EBFxtns7eSl6gYKqLjgcLnzPbi8eDyu+LtNt7hrUmnM6NSj0/AG3CfSOHNduqkqp8uOzoCAi\nXwJ/AO1EJFFEbhaR20XkdifJJcAqZ7K9N4ArTElm56vq6rs1jXw3Go7tLzxtEZrFRvLtnacx6pSC\ncybtTslryD7vzXl8tyyxTO+hlFL5lWiW1Kqk0mdJLYkf78sb3Vy3JbQdBsNeKNOtHvhmBROXen7p\nBwYI2Tmen9sv951B07oRRIR4byY6mJrB8cxsEmLCvZ5XStVs5T1LqiqNMx/J2z64BRa8VeZbZeUU\nbDPIHxAAhr02h45PTHX1TNp2IJWU45lMXrmHN3/bSI9nf6X/i7+VOR9KKf9Qmb2Paq5aXtoDUpMh\nMrbUt7r9zFYs3naIK05twgdzt9IiLpLlOw8DcGH3BCJCAvl8Yd5iP+3H/cKT53bk6R/XlDn7Sin/\npSUFXxCB63+CYLfpsTf/BlkZpb5Vh4bRzBszmL8NacOKJ8/m5UtOcZ3rklCbJ88tOLxDA4JSqqw0\nKPhKizPgpqlw4bt2/9tb4OtrYMLNcHBr0dcWISosr3B3bb9mhAQFMLRD/RJfv++InYLjUGqGdmdV\nShWgQcGXGp4CXa+A+A52f+NUWDUB1k6CwzvLdMsG0WGMG9WR+WMGExxoP75OjUq+dGef52dw/9fL\n6f7srzw8YWWZ8qCUqrk0KFSE2+fYNZxz/foEvNYZytDzS0S4+fQWNHLrRXTzGS1KdY/vlu1yveaW\nHJRSCjQoVIzAYNvOkF9q+czjFB0WXOZr7/96ebnkQSlVM2hQqCjGS/39tHFlKi1489LFXfjf7f34\n+1ltS3VdWkY2O5LTaD5mMk/+4HXpC6WUH9HBaxVlzwqYcBMkb/I8Ht8e7lro/ZoyuvPzJQjC5L/2\nFJu2VlgQR9OzXPsrnzr7pEoeSqmqSQevVTUNu8LflhQ8nrQO0sp32Ym3ru7JuFEdXfuX9mxcaFr3\ngACQkmbnUvpt3T7mbjzAO79vZsn2Q7z520aSjurKb0rVdDp4raKNO2CX65z3Bsz5P3vsny3gzoUQ\n385720MZhAXnxft/XnIKS3cconNCbX5YvrvI6z5bsJ0Hz2nHTR8XLI0t35nCB9cX+4eGUqoa06BQ\n0QKDIbA2DBkHkfHwizMlxlt9oFEPGD2zXN4md30GsD2WZjwwEIAhHepzz5fLCr3u3dlbiA73Xn10\nJF1nZFWqptPqo8rU93ao7bb85u6lkJ1VePpSCA2yH23+hudzvcy6mt/LU9d7Pb5o60FS0jKZuCSR\nSSuKLnEopaonLSlUtusnwZZZMP1JSE+B/WvsGs9N+5zUbQMChG0vjixwXEQ4t2sjfizjl/ptny1m\nwRbbBrIl6RhfLNzB3EcGExKkf18oVRNo76Oq4uAWeKN73v4VXwIG/vofXPJRubU1gJ3q4tmf1vDL\nqr1keZlxtSy8BSClVNVR0t5HGhSqCmPg6Rjv5+5eDHFel68+KcnHThAYINzy38WMPKUh7erX4qoP\nSt49NiQogIwsO/7i/G6NuLhHYwa0jT/pfK3alcLxzGxObV73pO+llLK0S2p1IwLnvuH93IapPnnL\n2KhQYiJCmHDHadzYvwW98n0JX9QjocjrcwMCwA/Ld3Pd+EUkHko76XyN+vdcLn3nj5O+j1Kq9DQo\nVCU9r4coL2sxTHsMpj/t87cPDvSsoqoTEeLaHty+HvcPLX609MfztgGweNtB17xK+46kc9uni0lx\n1pNevvMw3y7VJUSVqoo0KFQ1d/4BHS+As571PD73Ffj62nIf6OZO8rVbBAXY/UeGtWf8Dady79Di\nq7A+mLuVJdsPcsk7fzDi9TkA/GPyWqau3sdv6/YBcP34Rfz9mxU6GZ9SVZAGhaomoi5c9l/of0/B\nc2snweyXKywrAU5QyCmi3WnkKQ2JrxXqcezit23VT3JqBsYYdhy0VUoxTskjNtK+/rSy+Gk4lFIV\nS4NCVfbABhizAx7fn3cs/3rPR/fCvNfLbWK9n+89g98eOJMljw8l0Ck5uK8JfUG3Rq7tszvW51+X\nduV4Rnah92sxdgornOVDl+2wrzERdnDcwdSip83IchYB+nZpIv9b7H39CW/rVSulyk6DQlVWqz6E\n1YagULj2u7zjGak2CLzQBP7Vzq7PcGBjubxlh4bRtIyPIjYqlJ7N6gBwSuParvOvXdHdtSRoZGgQ\nYcGB1C5kBHR+b8zYyP6j6a6SQ3pm0Su/pTrB5u/frOAhLwsC/bB8F60encL25NQSvb9SqngaFKqL\nVoPh0o/t9n/Pg1kvwIkjeeezjpf7Ww5qX49Fjw5hYLt6Hse7OEGib0vbW+mzW0o+0K73czM4cMyu\nVf3h3K3sPlx4vtMyih7d/eMKW/20bu9RcnKMLi+qVDnQoFCdxLa2r7sWw+8veZ47ftgnb1kvOqzA\nsfYNoln8+FAu69UEgBZxkWx6bniZ7v/QhBWFnpu/KdmjFLBsxyGaj5nMzoO53V5t1ZEAt36ymDaP\n/VymPCil8ug0F9VJ3VaFn0v3TVAoTFyUZ+NyUGDZ/r6YtymZTxdsZ9z3q3jnmp6s2ZNX+nngf54B\n4xunXWH2xiSu7tOM3OaE7Bz+DamwAAAgAElEQVTDjHX7UUqdPC0pVCchEXDhexARa/cHjs079811\ncGhbpWQrl/tUF23qRQHwzjU9ir1u3Pd2xbdHJq7kjRmFt43kdpnNDQa5o/HzBw93b8zYyGcLtgN2\nsJ37gDulVEFaUqhuul4ODbrA8s9hwEMQEgnTHrfn3jwVulwGHc6FdsMqNZuxUSFs3A8RIUHUjw5l\n35HiF+jJHdxWGKeHrCsY5PY7SnPr/ZSVneNRannl1w0ArN6dwpeLdhIXFcLix88qxZMo5V+0pFAd\n1e8I5zwHAYFw2t/yjmdnwPLPYNLddj95M/x4X7lNx10S39zWj4l39OO8rnaKjPrRYSx8dGipJsw7\nvXWc1+OfLdgBwBM/rGb17hRmrU8qkCa9kJLAl4ts1VNuI3d+Kccz+X1Dwfsp5W80KNQEt86E0Oi8\n/YxU+GUsfHE5LPkI9iy3x9MO+nRENEDvFnXp2awuV/VpyqLHhtCuQS3XuZZxkcRFhfDFLX1oFhtR\n6D3qRYcWei7XyDfmej2+7UAq6/YeYWVi4W0ss9YXbH+48/MlXD9+EYdSvQcNpfyFz2ZJFZHxwChg\nvzGms5fzArwOjADSgBuMMUuLu2+NnSW1vMx8vmDPpGsmwsbpsPBtu/9USsXnC8jMzsEYO7vqiaxs\njIH2434BoH2DWmTnGDbuP8YdA1vx9qzNrut6NI1h6Y7SN6Rf0rMxE5Z4n2Mpf8nl1Oemk3T0BCO7\nNOTC7gkM7Vi/1O+nVFVWFWZJ/RgoqmJ7ONDG+RkNvO3DvPiPDucVPPbZxXkBASD1QMXlx01wYIBr\nMZ7QoEDCgvOWDP3+rv50a2KnDk+ICfe47rp+zcv0foUFBMgbLZ3f5L/2cMsn+keH8l8+a2g2xswW\nkeZFJDkf+MTYosoCEYkRkYbGGJ0Q52Q06Gyrk35+GBL/9J7m8HaI9F5vX1lCgwJ4dEQHhnSoT6v4\nSI9z+bu/5qoTEcyhtLKtG52Wmc2rU9byV2IKi7cfKtM9Vu1KITk1g5jwYGatT2JA2zhaxkcVGOG9\n6/BxosOCqBVWspHfSlWmyux9lAC4T2iT6BwrEBREZDS2NEHTpk3zn1b5JfSwo59f7eT9/JZZ0KhH\nua7mVlZN60aw42AaIkKdyBCGdW6AMYZ7BrfmSHoWv29IorXTvRVg4h39XBPundI4psyNww9+s4Jp\na/YVen7CkkQiQwIZ3qXwNa1H/duzXePV6Rto36AWv9w3wON4/xd/o0VcJDMfHFimvCpVkSqzodnb\nN5LXBg5jzHvGmF7GmF7x8Se/spdfqN244LFQZw6jGc/ARyM8z2VlQNIG3+crnx/u6s+v93t+iYoI\nfz+7HU+d14mZDw6kQe0w2jsN1j2a1uHr0X0B6JwQ7XFd54RoLu3p5bm9KCogADz4vxXc8flSDqdl\nsCflOO/P3kKvf0wv9r7r9h5l/9GCU4JvPWBHZhtjWLAlmeq24qHyH5VZUkgEmrjtNwbKtpq88u6O\nPyArHeo0h9QkqNUQXnR+5Tvmw4/3QkxTCImCpZ/Cvr/gwU0QVXGBt05kCHUiQ4pN98Wtfdl6IBUR\noU/LWD668VRObx3Hf2bmNUg3j43koXPasSclnbmbyqfdpNszv3rs546DmFfE/a/9YBFT7x9ATo7h\nSHpe9dayHYfYnpzGfV8v5/xujXjq3E4lenZvVuw8zPn/mce0+wewef8xBrarR3hIYPEXKlWMyiwp\nTAKuE6svkKLtCeWsfkdblRRRF+LbQVg09Lg+7/ySj22p4eeHbUAAOFo143LdyBDXrK0Ag9rVIzgw\ngIa18+ZmqhMRQr3osEIn6Hvzqu4Fjo08pfDqIW8OpmWwds8Rbvy4kPYaYP2+o/z96+UMeeV3j6By\n3fhFbE+28zb9sHw3N3y0qNj3u/bDhXR/ZlqB41P+sv9VXpiyljs+X8qLP68t1XO4K6zRXfknnwUF\nEfkS+ANoJyKJInKziNwuIrc7SaYAW4BNwPvAnb7Ki3Iz6lX4WxE9f98dAHtXVVx+TtLshwex5plz\nuOX0Fjw0rJ3r+LwxgwukHXVKowLHmtSJoGVcZIHjhen93AyGvz6n2Okyvl22y1VllCssONCjGWdF\nYgq3fbq4QDp3czYe8NqYHuQsnbrLmWV2/9GiR4wfz8jm2ImCgxhnrN1H68d+Zs3uI16uUv7Il72P\nrizmvAHu8tX7q0IEBEJsKxiXDJlpsHsZfJKvG+vGaWByICDIljaqsODAAIIDA3h8lGc+E2LC+e9N\nvRkzcSWf3tyHyFBbtfLV6L6EBQeydPshnvlpDSnHMzmlcW22FPHF/MSojjzz05qTzmvS0RMs2JLs\ncWzq6n1MXZ3XvvHQOe24a1Br7vtqmceKdkfSM4l2ei+9N3uzq9rsyHH7RR8eXHTV0ekv/UZyakaB\n8RnT19r3XrbzEB0bRXu7VPkZHdHsrwKDbHVSyzPhrkVw5VfwhDPaecbT8O4Z8Ha/ys3jSTqzbTx/\njB1C63pRNKxtxz70bRlLtyYxJNSx+7sPH+f5i7pwRps46kaG0NUZK+Huwu4J5Zan+ZuTizz/8tT1\nAHy/fDfvz9nqOn7KU9NYt9f+Nf/PX9a7ju911rkOK6Y9IbmQkdq57d3itd+H8kcaFJRtb2g33JYi\nOl/see6FJvCfvvDXBNg6p3Ly5wN9W8ZSPzqUOwa2IiIkiE9v7sPScWfRqLbn+hEfXt+LOpEhLH58\nKP1axlZI3l4opH1g2Gv295+7dra78OBA9h9N5+1Zm109m5buOMQD36xwVTG5O5yWoUuZKq90llTl\nqddNsGpi3v6JI5B0BCbebPfrd7HTZhw/ZOdU6npF5eTzJNUOD2bho0MLHHf/wp18z+l0amS78cZF\nhfLl6L68Pn0jr063XXfPaBPHnI0HePGiLkxasbvYUkBJvfv7lkLPXfPBQtfa2e5yjKH3czMAGNA2\njtCgQC56az4Ae1I8g0JaRhbdnvmVczrVdw20e/S7v7iqj44BUlpSUPk16OK5H5ivy+S+v+BfbeGt\nPvDdbXbivT0F10+urqJC7N9Jb1zZ3RUQ3N07tE3e9pA2hAUHcHanBkQ41TdvX523fsSpzet4XPv8\nhfl+t2Uwd9MBAr2UFD6at821nZ1jWOo2Stu9ofqfv6xjxOu2xDF19T6+WVz4VCBVyecLtxfZDViV\nHw0KylNYbbjiS/j7Wrj4Qxj9Owx9CloM8J5+wVsw+e8VmUOfGjuiPbcNaMnwzg0KTfP6Fd344Lpe\n9Gpel3XPDqduZAjhTjDJyM7h5tNbAPDRjb09rouLKjgmoWvjgoGnON56Eblbt+coD0/MC9Tua12/\nNWsz25LTvF3GP35aUyGD6q7+YAHfL9sFwKcLtrN0h/dpRq7+YAEfzbPtKo99t4qrP1jo87wpDQrK\nm/YjILoRdLnE9j46/X64/kcYmwj3rYI+t3umT/wTDm2vnLyWs5iIEMaO6EBwEcuLnt+t4CyqvZ1S\nQcPa4Ywb1ZFtL44kKjSIFy6ypYO7BrUiKtSztnZQu3jeuqYnU+8bwEPntGPKPWcQUsZlTd25BwQo\nfvGiXB/M3cr6fUe564ulrkBS3kEiJ8cwb1My931tp3Mf9/0qVzVXfvM2JfP0j2s8glp1GlORkZVD\nZjXKby4NCqrkQmtBTBMY/pKdfvupFGg1xJ776qrKzVslu6ZvM6bdP4DeLep6HL+kZ2MeOKstdw9q\n43F8+t8H8NGNvUmICaddg1rcNag1HRtFs+G54R5zPZWHw6WYNHDYa3OYvHIPV763gNQTWbQYO8VV\ngpi1fj+PTFjJ1NV7ycnxnK7DGMOm/cc87rX/aHqBL/G0zGy8+Wnlbo8A5D4OZG9K3rQhrR/7uUTP\nkZVd+V/Ipzw9ldNe/K1S81AW2tCsTs7Qp2DzDDi2D55rBM362eqnoLJN31BdiQht69cqcDw4MIC/\nDbEBoamzsNDT53Widb2CaYsTFxVKgBQ/UK08rEhModOTUwFbgsgxMN6pyvl68U5GdmnI5L/2cF2/\nZtw/tC2TVuzmyUmref2Kbvyyai8pxzOZvzmZG05rziU9G3M4LRMReG92XiO6exC4+4tlxN4ayk8r\ndzNv0wHGDG/vOuetuqz/i78xoksDHhvpfRzNqH/PZd3eo6Va8a+8pWfmkJ7p+8+qvGlJQZ2chqdA\nv7vt3EqZqbBpOqz7qbJzVSU1rhPB5udHcP1pzYtMl78K6YpT7XxVPZvF8PY1PbxdUsCILoW3iTR3\nW/XunsGtS3S/3ICQa7IzzcYnf2yn+7O/8s7vdjDdvV8t5+dVe109sT6ev41R/57LNR8u5OoPFnrM\navv6jI0e95y4NJHPF+5gW3Iat3+WN+refQ1usIs17Tp83DWO46lJq2k+ZjJr99hxHCt2Hmbd3qMA\nfLZgO79vSKL5mMnsPGjbUsqzSmzW+v38viHJa7ffklq394hHFVll06CgTl7vWyHWrXpk1UT49jZI\nWl9j2hrKi7eeQ/m9eVV31xf35b2acLEz82tCTAQJMfb4g2e3Zc7Dg3jnmh4M7VCvwD3euronv9x3\nhtf7P3dhF+o5o6Uv7NGYdl5KOKW1J6XgzLDFeW26Z1AobFGkJ37wnHYlKV9J6eP52wAY/vocFmxJ\n5vz/zHOde/z7VVw/3s4x9ee2g9z/9XJajJ3C+7O3cCQ9kyvfW8Br0zfw8tR1vDJtPd8tS+TN3zzz\nlSszO4cTWZ4B6oaP/uT68Yvo/+JvzFxXcJnX4uw6fJxhr83h3q+Wl/paX9HqI3Xy6jSHvzmrlU1w\nG+ew8iv72ulC6HIZtB0GAQFwYJNd5Ce84OhhBS3jo5j10CBmb0iif+s4AgOEd6/tyZlt4wkLDmTx\n40OpGxFCQIDQpG4EA9rG0/EJW9Xzz4tPoVaY/W/dvkE09wxpwxszNnJe10Y8Mrw96ZnZtIqPIsgJ\nTkEBwiuXd3Wted29aQyHUjNcPZTuH9rWNS6jsmzY59lWsb2Q3lMAV7y3oNBzH8/fxspEuxTtc1PW\n8tPK3axITOGPLQXHl9w9uE2BYxe9NZ+/dqUUWiW1bMchBrUvGKABvv5zB2e0iefXNfs4kZXN6AGt\nAFsNBrBoq+fa6YfTMhj3w2qeOrcjsYUsMuUrWlJQ5avb1QWPrf4OvroSPrsIju6FN3vCy63sGg6q\nUAPaxrtKFud0auBavjQuKtRjkJ37vEeXndrEY2Ggge3sNOiX9mpMQkw4reJtI/YlvWyVVHR4MJ0a\n1eazm+3MsqFBAa5BbCueOJt7h7Zh/A15y/reNahVuT9naV35ft4Xf+5ssSWRW6WUa0Vi4WuV3/jR\nIpqPmezRc+uvXUWvbZ6R7b1aKiUtk0cm/sVpL/7Gk5NW8/yUdeTkGMbPzauSc+/tZozh4/nb+HHF\nbj5bsKPI9/QFLSmo8tVyEIx8xU6XkZkGf34Iy7+wU3JvmQn/cmYyzcmy8yv1vBG6X217NqkykSJW\n0OvRtA5rnjmHiBDP/+r3DWnDbQNaEhmaO77CVouEBQdy6xktubF/C9cX1eD29Vn06BDia4UiIoQF\nBfKvX/NKD0M71GP62tJVnTw6oj3PT1lXqmu8eW5yyacML25mW3cz19u2j3/+so7nChl0mJ5ZsK1j\n2Y5DXJivi623RZcmrdjtMcniCbd7nf7STFcbRWAAfDh3K1GhgVx+asWMONegoMpXQACc6kyJER4D\nQ8bBmY/YRX0+Od8zbdI6+OURu71zgS05XP6ZvYcqlWfO70TnBO8D4fIHBLDTeUS6jZvInRAvNtJ+\n8QcHegaaetF5c0L1axULv9pBfE3qRtCjqR2jse9IOpnZOZz+0kyPawe0jWe2WwPzRT0SuLpPs3IJ\nCrsOH6dBdJhrYsDy9vnCHTStG8FtZ+aVkM58eSZRoUGc2tyz+/GHc7fy4dyt+W/BWa/OLnBs0TbP\n6qKsHMPWA6ks2X7Io9H6wLEMPp5vA3BFBQWpbssC9urVyyxevLiys6HKYvX38L/rod1IOO8NeKUD\nZOerQmo1GK751nP96DTnP1CE539CVX6ycwxvz9rEdac1d03RXZT9R9I9AoW7o+mZBAcG8Muqvdz3\n9XIeOqcdg9vXY/jrc+jRNIZv7+wPwH9mbnLNCtuxYTRbD6RyvJBxDPn1bFaHJc5UHpPu7s95b84r\n5oqTk9sFt7wkxISXqMdSr2Z1WOw856wHB9K8FGt/5CciS4wxvYpNp0FBVShj7E9AAGRnwZz/g1kv\neKap2wqCwqDXjdCwK3x4lj3+VNF1uqrqmb/pAD2b1yE4IICXp63n6j5NaVzH9qA6mJpBj2ftynS5\njbd7U9JpUDuM5mMmAzDqlIb8tHIP53ZtxHldG3HrJ4sJDw7kutOa8e7vW/jb4NY8cLatksy95uIe\njZm41LMn05jh7Xnx56JLJme2jeeqPk257dMl5fcLKGcnM+6ipEFBq49UxRLJKwUEBkH3a2HxeDjr\nWQgMhgk3wkFn3eUpD3peawxkZ9p0IvDumZB+GO5eYu+lqpzTWse5th8Z1t7jXN3IEJaOO8ujMbdB\nvqnL37yqB286g+X3O1VEgQHC2R3r8+7vWzi3a95qevPHDCY7x5AQE050eBAfzdvGB9f1on3DWiTE\nhBcbFM7v1qhEpaTSuu3MlkXOfNuvZazXHlCVRf8nqcpVOwEedOvy2GoQzP4/+OPNgmlf7QxHEuHs\n5yAi1k7dDbB+CtRpZleLa9BV2ySqkbqRIdSNLNno99yG78AAoWezugX+am4UE+7afvLcTowb2dHr\n2hP5jejSgMRDx7moR2NW7y59afTxkR3459T1hTZk3z+0Lae1inONl8jVOSGaVbuOcHqbuBIHhS1J\nx2gZX77ToOSnQUFVLeF14Jzn7E/yZtg6G1ISbTXTEadKYNpjntd8c23edr+7YfA4W4JISbQli2bV\newU5ZcVEBHNdv2Zc2rNJidLnDwihQQG0iIt0dU2ddv8AaocHU9+tbaRWaMlLCo+P7MCpzevStUkM\nczcdYNb6pAJpOjWKJiw4kDPbxvP9Xf35+s+dfLnIdjN9+rzOXPz2fAa3r+dqW3H33Z2nFejJ9OxP\nawrMvlveNCioqiu2lf0BOPUWWP45ZB6HP9+36zyERMGhfL09FrxlG7SPuNUpx7WDG3+GyIpZOU2d\nvIu6J9CkboTHMRHhmfM7l/mea54ZhgAtH50C4HWuqtoRNii0iItkaId6XNKzCee8VrD30PMXdvFY\nlKhzo9rMWp/Ed3eexuXvLXCVGto3yFv3uluTGDo0rOUKCj2b1SmyjaBDw2gu69XYY82Ld67tWYon\nLhttaFbVT9pBu3RoWG1Y8DYc2gan/Q0ObIBPLwK8/JtuN9KuSb3jD7jwPUjoCckbYeOvEBQKzU+H\nrBOwbS70v6ein0hVoOU7D3MoNaPQ0cfbDqTSKCackKAAj8ZwgK0vjPA6LiQrO4fF2w/Rt2Usuw4f\nZ29KOiLQoUE04fnWz24+ZjJX92nqMf7horfmsXTHYWY/NIhfVu/h1jNaIiIYY0jLyOaRiStJqBPO\n2OEdyvzc2vtI+adD22DfGkhcBEf3wbDn4af77ajqknpkG4RG28Cj/F56Zjbtx/0CnFzvn1xZ2TkE\niHhUb6Ucz2TrgVS6NfHd1C8aFJTKdWw/zHwO6rSA6U+W/LqzntVSgwLsvEZxUaEFqrSqE+2SqlSu\nqHpw7ut2u83Ztgqp1022EfrEEbvO9F/fFLzu13G2+2v7UfYeQRU7MZmqOro3rVN8ohpCSwpKgR0D\nIQI52bZtIeMYvD8YUnbmpZFA6DAKEnpB3zvtaOzsExAW4zkCuzQObISDW6Ht2eXzHEoVQquPlDpZ\nWSdgwy/wzXXFp23QBW6bAyeOwoapdp3rkEgbbCbcBJHxcObDtnTy3W1w3r/t2IqnnPmKnjxc9sCi\nVAloUFCqvKTsgqj68Nf/4PvbS3ZNWAyc8YCtgnLX7HTYPrdg+r8thbWTIKYZdL7o5POsVD4aFJTy\nhWP7YfNM+GUMdDjXlia6XGrHR2yeUT7vMeQJaD7ADuTbPANWfgPRjex05J0uKJ/3UH5Hg4JSFSkn\nG/assO0MMc3sKOvEP+2qdDf+AtENYd1kOLYPGnWHZZ9Dk97Q5iw71uL3l0r2PvU722Ax+HHY+5ct\nwUy8xbZt3LcKYpzRvjsWwKL3oM050PVyz3sc2gY/3A3DX4L6ncrzt6CqMA0KSlW2nGxASjYX0+7l\ndonSV92+pGOaQbsRsPDtkr1fWAz0uc22W8x9Je947abQqBtgoNUQmP0yHNllz13+mW03qdUQBj1m\n548yRicYrIGqRFAQkWHA60Ag8IEx5sV8528AXgacf6G8aYz5oKh7alBQNdrRfXaktgRAkNtEcdv/\nsA3eQ5+EgGCY/2/oegVsd9YRaNi14BTkpdVigJ1rCuDBTWCy4eAWG0QGPGznkMpMt11ztVG82qn0\noCAigcAG4CwgEfgTuNIYs8YtzQ1AL2PM3SW9rwYFpQpxdB98fgnsXQlDn7KljKWfQNcrbZDJzoD3\nzrRpr/8JVn4N63+G+h1h32pIK2amzobd8mam7X8fDHkSUpPssqs7F9qpQtb+6ASNABuoGnX35ROr\nUqgKQaEf8JQx5hxnfyyAMeYFtzQ3oEFBqYqTfsSuh537l37u+Iw9K2HOv2DAQ/BO//J7v/qd7Xv2\nvhXqdbRrc8/+JxzdCwk94LJPtdRRQapCULgEGGaMucXZvxbo4x4AnKDwApCELVXcb4zZ6eVeo4HR\nAE2bNu25fft2n+RZKQWkHrDtIbuX2WnKW58Fw16wbQ97VsCR3bD0v3npWw2xU5XvWmJLCI16wK4S\n/uHW8wY4fsi2g0TG20b0iFhbwti5wJZyaje2adNT7Cy5tRrYXmDH9kODss+a6m+qQlC4FDgnX1Do\nbYz5m1uaWOCYMeaEiNwOXGaMGVzUfbWkoFQVMPN52DQDbplu/9I3xjZutx8F8e3s/pKP4af7bA8s\nkwOH7ZTRdL/WVi3lX1nPm4AgO0VJWjL8+kTB822HQ8uBEB4DTfvBvNdsVdigx2wbiYhd9nX6kzag\nDHkCVn8L3a621Vz718I310O74XZ69ugEO+16dOO8VQJzS1PVXFUICsVWH+VLHwgcNMbULuq+GhSU\nqiaMsSWI8ELmDTq2H/780LZTxLeHmKa2AT2hByRtsEEkPAYOn0TNQJ0WtsE8NyCVVVQDOxVJw67Q\n9Sq7hrh7r7LM45CVbke0Rze253YusjPtJvh+DYSSqApBIQhbJTQE27voT+AqY8xqtzQNjTF7nO0L\ngUeMMX2Luq8GBaX8iDEw42lYM8kuuDR4nG0T2bnQViOF14F3B9i0gx6HNkNh1URY9W1et1uAjufb\nEsuOBfZad3Vb2S/71d+WPF9B4bbqKiLWjj3ZvSzvXJ0WduXAr5zFpS/7BBqfaheJSt5sx6f0vNGW\naJI32Qb/Mx6Exr4NHpUeFJxMjABew3ZJHW+MeU5EngEWG2MmicgLwHlAFnAQuMMYU+Tq2hoUlFIl\nsvk3+PRC6H0bjPhn3vHM47YNIyTSjkgPDrfHnm9ozz9x0JYsln8BDU+xQWPVBIhrC0nr7frh2Rnl\nn99eN9kg0/ECW0KKTrDVVge3QNqhkw4aVSIo+IIGBaWUTyRvtj8lmbF2yce2x9bxQ7ZXVZ/R8Mdb\n0HoI7FtlV/Rb/zOc9wZMusc2wNfrYM/lqtPctmOkp8Cyz+DoHs/3CAiyvbVyxXeA22Z7jl8pBQ0K\nSilV1WSkwt5VtnQS2xpCnEV7DmyyjfLb59lGeXcJvWw1U/phGPkKnHpzmd5aF9lRSqmqJiQSmvYp\neDyuNdzwk21DWfgOHN4J3a60o9tjmtrjE28pvNG+HGlQUEqpqkIE+t7h/fglH1ZIFkowU5dSSil/\noUFBKaWUiwYFpZRSLhoUlFJKuWhQUEop5aJBQSmllIsGBaWUUi4aFJRSSrlUu2kuRCQJKOtcunHA\ngXLMTnWgz+wf9Jn9w8k8czNjTHxxiapdUDgZIrK4JHN/1CT6zP5Bn9k/VMQza/WRUkopFw0KSiml\nXPwtKLxX2RmoBPrM/kGf2T/4/Jn9qk1BKaVU0fytpKCUUqoIGhSUUkq5+E1QEJFhIrJeRDaJyJjK\nzk95EZEmIjJTRNaKyGoRudc5XldEfhWRjc5rHee4iMgbzu9hpYj0qNwnKBsRCRSRZSLyk7PfQkQW\nOs/7tYiEOMdDnf1NzvnmlZnvkyEiMSIyQUTWOZ93v5r8OYvI/c6/6VUi8qWIhNXEz1lExovIfhFZ\n5Xas1J+riFzvpN8oIteXNT9+ERREJBD4DzAc6AhcKSIdKzdX5SYLeMAY0wHoC9zlPNsYYIYxpg0w\nw9kH+zto4/yMBt6u+CyXi3uBtW77LwGvOs97CMhdyPZm4JAxpjXwqpOuunod+MUY0x7oin3+Gvk5\ni0gCcA/QyxjTGQgErqBmfs4fA8PyHSvV5yoidYEngT5Ab+DJ3EBSasaYGv8D9AOmuu2PBcZWdr58\n9Kw/AGcB64GGzrGGwHpn+13gSrf0rnTV5Qdo7PxHGQz8BAh2lGdQ/s8bmAr0c7aDnHRS2c9QhmeO\nBrbmz3tN/ZyBBGAnUNf53H4CzqmpnzPQHFhV1s8VuBJ41+24R7rS/PhFSYG8f2C5Ep1jNYpTZO4O\nLATqG2P2ADiv9ZxkNeF38RrwMJDj7McCh40xWc6++zO5ntc5n+Kkr25aAknAR0612QciEkkN/ZyN\nMbuA/wN2AHuwn9sSav7nnKu0n2u5fd7+EhTEy7Ea1RdXRKKAicB9xpgjRSX1cqza/C5EZBSw3xiz\nxP2wl6SmBOeqkyCgB/C2MaY7kEpelYI31fq5naqP84EWQCMgElt1kl9N+5yLU9hzltvz+0tQSASa\nuO03BnZXUl7KnYgEYwPC58aYb53D+0SkoXO+IbDfOV7dfxf9gfNEZBvwFbYK6TUgRkSCnDTuz+R6\nXud8beBgRWa4nCQCifhspVIAAAMRSURBVMaYhc7+BGyQqKmf81BgqzEmyRiTCXwLnEbN/5xzlfZz\nLbfP21+Cwp9AG6fnQgi2wWpSJeepXIiIAB8Ca40xr7idmgTk9kC4HtvWkHv8OqcXQ18gJbeYWh0Y\nY8YaYxobY5pjP8ffjDFXAzOBS5xk+Z839/dwiZO+2v0FaYzZC+wUkXbOoSHAGmro54ytNuorIhHO\nv/Hc563Rn7Ob0n6uU4GzRaSOU8o62zlWepXdwFKBDTkjgA3AZuCxys5POT7X6dhi4kpgufMzAluf\nOgPY6LzWddILtifWZuAvbO+OSn+OMj77QOAnZ7slsAjYBPwPCHWOhzn7m5zzLSs73yfxvN2Axc5n\n/T1QpyZ/zsDTwDpgFfApEFoTP2fgS2y7SSb2L/6by/K5Ajc5z78JuLGs+dFpLpRSSrn4S/WRUkqp\nEtCgoJRSykWDglJKKRcNCkoppVw0KCillHLRoKBUBRKRgbkzuypVFWlQUEop5aJBQSkvROQaEVkk\nIstF5F1n/YZjIvIvEVkqIjNEJN5J201EFjjz23/nNvd9axGZLiIrnGtaObePclsX4XNnxK5SVYIG\nBaXyEZEOwOVAf2NMNyAbuBo7KdtSY0wP4Hfs/PUAnwCPGGNOwY4yzT3+OfAfY0xX7Lw9udNMdAfu\nw67t0RI7n5NSVUJQ8UmU8jtDgJ7An84f8eHYCclygK+dNJ8B34pIbSDGGPO7c/y/wP9EpBaQYIz5\nDsAYkw7g3G+RMSbR2V+OnUt/ru8fS6niaVBQqiAB/muMGetxUGRcvnRFzRFTVJXQCbftbPT/oapC\ntPpIqYJmAJeISD1wrZfbDPv/JXeGzquAucaYFOCQiJzhHL8W+N3YNS0SReQC5x6hIhJRoU+hVBno\nXyhK5WOMWSMijwPTRCQAO3vlXdiFbTqJyBLsyl6XO5dcD7zjfOlvAW50jl8LvCsizzj3uLQCH0Op\nMtFZUpUqIRE5ZoyJqux8KOVLWn2klFLKRUsKSimlXLSkoJRSykWDglJKKRcNCkoppVw0KCillHLR\noKCUUsrl/wG+wolkRmFnVAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x26189e5fc88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 527us/step\n"
     ]
    }
   ],
   "source": [
    "x_predict = np.zeros([0, timesteps, dimensions])\n",
    "y_actual = np.zeros([0])\n",
    "\n",
    "for word_no, word in enumerate(words):\n",
    "    for data_no in range(3):\n",
    "        try:\n",
    "            with open(\"./record/{}/json_{}.txt\".format(word, data_no)) as json_data:\n",
    "                json_data = json.load(json_data)\n",
    "        except Exception as s:\n",
    "            print ('error log:', s)\n",
    "\n",
    "        _timesteps = get_timesteps(json_data, pick_frame_every_no)\n",
    "        _timesteps = np.vstack((_timesteps, np.zeros([timesteps - _timesteps.shape[0], dimensions])))\n",
    "        x_predict = np.vstack((x_predict, [_timesteps]))\n",
    "        y_actual = np.append(y_actual, word_no)\n",
    "        \n",
    "x_predict_norm = (x_predict-x_mean)/x_std\n",
    "    \n",
    "prediction = model.predict(x_predict_norm, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_word_index = np.argmax(prediction, axis = 1)\n",
    "\n",
    "prediction_words = np.zeros([0, 2])\n",
    "\n",
    "for idx in prediction_word_index:\n",
    "    prediction_words = np.vstack((prediction_words, [idx, words[idx]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['0' 'come quickly']\n",
      " ['0' 'come quickly']\n",
      " ['0' 'come quickly']\n",
      " ['1' 'emergency']\n",
      " ['1' 'emergency']\n",
      " ['1' 'emergency']\n",
      " ['2' 'father']\n",
      " ['2' 'father']\n",
      " ['2' 'father']\n",
      " ['3' 'fever']\n",
      " ['5' 'headache']\n",
      " ['5' 'headache']\n",
      " ['4' 'good luck']\n",
      " ['4' 'good luck']\n",
      " ['4' 'good luck']\n",
      " ['5' 'headache']\n",
      " ['5' 'headache']\n",
      " ['5' 'headache']\n",
      " ['6' 'hello']\n",
      " ['6' 'hello']\n",
      " ['6' 'hello']\n",
      " ['14' 'not ok']\n",
      " ['7' 'help']\n",
      " ['7' 'help']\n",
      " ['8' 'hi']\n",
      " ['8' 'hi']\n",
      " ['8' 'hi']\n",
      " ['9' 'hungry']\n",
      " ['9' 'hungry']\n",
      " ['9' 'hungry']\n",
      " ['10' 'like']\n",
      " ['10' 'like']\n",
      " ['9' 'hungry']\n",
      " ['11' 'mother']\n",
      " ['11' 'mother']\n",
      " ['11' 'mother']\n",
      " ['12' 'mother_father']\n",
      " ['12' 'mother_father']\n",
      " ['12' 'mother_father']\n",
      " ['13' 'mother_mother']\n",
      " ['13' 'mother_mother']\n",
      " ['13' 'mother_mother']\n",
      " ['14' 'not ok']\n",
      " ['14' 'not ok']\n",
      " ['14' 'not ok']\n",
      " ['15' 'quickly']\n",
      " ['10' 'like']\n",
      " ['15' 'quickly']\n",
      " ['16' 'sorry']\n",
      " ['16' 'sorry']\n",
      " ['16' 'sorry']\n",
      " ['17' 'tomorrow']\n",
      " ['17' 'tomorrow']\n",
      " ['17' 'tomorrow']\n",
      " ['18' 'yogurt']\n",
      " ['9' 'hungry']\n",
      " ['18' 'yogurt']]\n"
     ]
    }
   ],
   "source": [
    "print(prediction_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
