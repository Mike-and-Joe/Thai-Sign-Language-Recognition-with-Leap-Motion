{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import GRU, Dense, Dropout, Input, concatenate\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import Adam\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# variable\n",
    "words = [\n",
    "    'come quickly', 'emergency', 'father', 'fever', 'good luck',\n",
    "    'headache', 'hello', 'help', 'hi', 'hungry',\n",
    "    'like', 'mother', 'mother_father', 'mother_mother', 'not ok',\n",
    "    'quickly', 'sorry', 'tomorrow', 'yogurt'\n",
    "]\n",
    "data_per_word = 27\n",
    "data_length = 2 * data_per_word * len(words)\n",
    "timesteps = 50\n",
    "dimensions = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_feature(frame):\n",
    "    finger_name = ['thumb', 'index', 'middle', 'ring', 'pinky']\n",
    "#     coordinate = ['x', 'y', 'z']\n",
    "    fingertip_pos = np.zeros([2, 5, 3]) # [cooridinates x fingers]\n",
    "    feature = np.zeros([22])\n",
    "    hand_pos = np.zeros([12])\n",
    "#     finger_tip = {}\n",
    "    if 'right' in frame['hands']:\n",
    "        hand_pos[0:6] = np.array([frame['hands']['right']['hand_palm_position'][0],\n",
    "                                  frame['hands']['right']['hand_palm_position'][1],\n",
    "                                  frame['hands']['right']['hand_palm_position'][2],\n",
    "                                  frame['hands']['right']['yaw'], \n",
    "                                  frame['hands']['right']['roll'], \n",
    "                                  frame['hands']['right']['pitch']])\n",
    "        for idx, finger in enumerate(finger_name):\n",
    "#             fingertip_pos[2 + idx, :] = np.array(frame['hands']['right']['fingers'][finger]['bones']['distal']['next_joint'])\n",
    "            fingertip_pos[0, idx, :] = np.array(frame['hands']['right']['fingers'][finger]['bones']['distal']['next_joint'])\n",
    "    if 'left' in frame['hands']:\n",
    "        hand_pos[6:12] = np.array([frame['hands']['left']['hand_palm_position'][0],\n",
    "                                   frame['hands']['left']['hand_palm_position'][1],\n",
    "                                   frame['hands']['left']['hand_palm_position'][2],\n",
    "                                   frame['hands']['left']['yaw'], \n",
    "                                   frame['hands']['left']['roll'], \n",
    "                                   frame['hands']['left']['pitch']])\n",
    "#         fingertip_pos[8, :] = np.array(frame['hands']['left']['hand_palm_position'])\n",
    "        for idx, finger in enumerate(finger_name):\n",
    "#             fingertip_pos[4 + 5 + idx, :] = np.array(frame['hands']['left']['fingers'][finger]['bones']['distal']['next_joint'])\n",
    "            fingertip_pos[1, idx, :] = np.array(frame['hands']['left']['fingers'][finger]['bones']['distal']['next_joint'])\n",
    "    fingertip_pos_shift = np.roll(fingertip_pos, 1, axis=1)\n",
    "    feature[0:10] = np.linalg.norm(fingertip_pos - fingertip_pos_shift, axis=2).reshape(10)\n",
    "    feature[10:22] = hand_pos\n",
    "\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_euclid_dis_tips_and_palm_feature(frame):\n",
    "    finger_name = ['thumb', 'index', 'middle', 'ring', 'pinky']\n",
    "    hand_name = ['left', 'right']\n",
    "    \n",
    "    fingertip_pos = np.zeros([2, 5, 3])\n",
    "    \n",
    "    hand_palm_pos = np.zeros([2, 3])\n",
    "    hand_palm_rpy = np.zeros([2, 3])\n",
    "    dist_fingertip_palm = np.zeros([10])\n",
    "    dist_btw_fingertip = np.zeros([10])\n",
    "    \n",
    "    feature = np.zeros([2*3 + 2*3 + 10 + 10])\n",
    "    \n",
    "    for hand_idx, hand in enumerate(hand_name):\n",
    "        if not hand in frame['hands']:\n",
    "            continue\n",
    "        hand_palm_pos[hand_idx] = np.array(frame['hands'][hand]['hand_palm_position'])\n",
    "        hand_palm_rpy[hand_idx] = np.array([ frame['hands'][hand]['roll'],\n",
    "                                                    frame['hands'][hand]['pitch'],\n",
    "                                                    frame['hands'][hand]['yaw']])\n",
    "        for finger_idx, finger in enumerate(finger_name):\n",
    "            fingertip_pos[hand_idx, finger_idx] = (\n",
    "                np.array(frame['hands'][hand]['fingers'][finger]['bones']['distal']['next_joint'])\n",
    "            )\n",
    "            \n",
    "            dist_fingertip_palm[hand_idx*5 + finger_idx] = np.linalg.norm(\n",
    "                fingertip_pos[hand_idx, finger_idx] - hand_palm_pos[hand_idx]\n",
    "            )\n",
    "            \n",
    "    fingertip_pos_shift = np.roll(fingertip_pos, 1, axis=1)\n",
    "    dist_btw_fingertip = np.linalg.norm(fingertip_pos - fingertip_pos_shift, axis=2)\n",
    "        \n",
    "    feature[0:6] = hand_palm_pos.reshape(6)\n",
    "    feature[6:12] = hand_palm_rpy.reshape(6)\n",
    "    feature[12:22] = dist_fingertip_palm.T\n",
    "    feature[22:32] = dist_btw_fingertip.reshape(10)\n",
    "    \n",
    "#     print(feature[12+5:12+6])\n",
    "#     print(frame['hands']['right']['fingers']['thumb']['bones']['distal']['next_joint'])\n",
    "#     print(hand_palm_pos[1])\n",
    "    return feature\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_timesteps(json_data, pick_frame_every_no): \n",
    "    timesteps = np.zeros([0, dimensions])\n",
    "    for frame_no, frame in enumerate(json_data):\n",
    "        if frame_no % pick_frame_every_no != 0 or not frame['hands']:\n",
    "            continue\n",
    "#         feature = get_feature(frame)\n",
    "        feature = get_euclid_dis_tips_and_palm_feature(frame)\n",
    "        timesteps = np.vstack((timesteps, feature))\n",
    "    return timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_fake_speedup_timesteps_1(percent, json_data, pick_frame_every_no):\n",
    "    return get_timesteps(json_data, pick_frame_every_no*(100+percent)//100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_fake_speedup_timesteps_2(percent, old_timesteps, old_pick_frame_every_no):\n",
    "    timesteps = np.zeros([0, dimensions])\n",
    "    pick_frame_every_no = old_pick_frame_every_no*(100+percent)//100\n",
    "    timesteps_length = (old_timesteps.shape[0] * old_pick_frame_every_no) // pick_frame_every_no\n",
    "    \n",
    "    for new_index in range(1, timesteps_length):\n",
    "        start_old_index = (new_index * pick_frame_every_no) // old_pick_frame_every_no\n",
    "        x1 = old_pick_frame_every_no*start_old_index\n",
    "        x2 = old_pick_frame_every_no*(start_old_index + 1)\n",
    "        h1, h2 = old_timesteps[start_old_index : start_old_index + 2]\n",
    "        _x = (new_index * pick_frame_every_no)\n",
    "        \n",
    "        feature = ((_x-x1)/(x2-x1))*(h2-h1) + h1\n",
    "        \n",
    "        timesteps = np.vstack((timesteps, feature))\n",
    "        \n",
    "    return timesteps\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_frame = 0\n",
    "for word_no, word in enumerate(words):\n",
    "    for data_no in range(data_per_word):\n",
    "        try:\n",
    "            with open(\"./record/{}/json_{}.txt\".format(word, data_no)) as json_data:\n",
    "                json_data = json.load(json_data)\n",
    "        except Exception as s:\n",
    "            print ('error log:', s)\n",
    "        \n",
    "        if max_frame < len(json_data):\n",
    "            max_frame = len(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "speedup = 10\n",
    "pick_frame_every_no = int((max_frame * (speedup < 0 and (100-speedup)/100 or 1)) // 50 + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.zeros([0, timesteps, dimensions])\n",
    "y = np.zeros([0])\n",
    "for word_no, word in enumerate(words):\n",
    "    for data_no in range(data_per_word):\n",
    "        try:\n",
    "            with open(\"./record/{}/json_{}.txt\".format(word, data_no)) as json_data:\n",
    "                json_data = json.load(json_data)\n",
    "        except Exception as s:\n",
    "            print ('error log:', s)\n",
    "        \n",
    "        _timesteps = get_timesteps(json_data, pick_frame_every_no)\n",
    "        __timesteps = np.vstack((_timesteps, np.zeros([timesteps - _timesteps.shape[0], dimensions])))\n",
    "        x = np.vstack((x, [__timesteps]))\n",
    "        y = np.append(y, word_no)\n",
    "        \n",
    "        _timesteps = get_fake_speedup_timesteps_2(+10, _timesteps, pick_frame_every_no)\n",
    "        __timesteps = np.vstack((_timesteps, np.zeros([timesteps - _timesteps.shape[0], dimensions])))\n",
    "        x = np.vstack((x, [__timesteps]))\n",
    "        y = np.append(y, word_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_std = x.std(axis=(0,1), keepdims=True)\n",
    "x_mean = x.mean(axis=(0,1), keepdims=True)\n",
    "x_norm = (x-x_mean)/x_std\n",
    "# x_norm = (x-x_min)/(x_max-x_min)\n",
    "# x_norm = 2*(x-(x_max+x_min)/2)/(x_max-x_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = np.zeros([data_length * 2 // 3, timesteps, dimensions])\n",
    "y_train = np.zeros([data_length * 2 // 3])\n",
    "x_test = np.zeros([data_length // 3, timesteps, dimensions])\n",
    "y_test = np.zeros([data_length // 3])\n",
    "for idx in range(data_length):\n",
    "    if idx % 3 == 2:\n",
    "        x_test[idx // 3] = x_norm[idx]\n",
    "        y_test[idx // 3] = y[idx]\n",
    "    else:\n",
    "        x_train[idx - idx // 3] = x_norm[idx]\n",
    "        y_train[idx - idx // 3] = y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shuffle_train = np.arange(len(x_train))\n",
    "np.random.shuffle(shuffle_train)\n",
    "x_train_shuffle = np.zeros([data_length * 2 // 3, timesteps, dimensions])\n",
    "y_train_shuffle = np.zeros([data_length * 2 // 3])\n",
    "for idx, item in enumerate(shuffle_train):\n",
    "    x_train_shuffle[idx] = x_train[item]\n",
    "    y_train_shuffle[idx] = y_train[item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# encoding label\n",
    "Y_train_shuffle = np_utils.to_categorical(y_train_shuffle, len(words))\n",
    "Y_test = np_utils.to_categorical(y_test, len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fingers = Input(shape=(timesteps, dimensions), name='fingers')\n",
    "fingers_layers = GRU(64, activation='tanh', recurrent_activation='hard_sigmoid', dropout=0.2, recurrent_dropout=0.2)(fingers)\n",
    "fingers_layers = Dense(64, activation='relu')(fingers_layers)\n",
    "fingers_layers = Dropout(0.2)(fingers_layers)\n",
    "fingers_layers = Dense(64, activation='relu')(fingers_layers)\n",
    "fingers_layers = Dropout(0.2)(fingers_layers)\n",
    "fingers_layers = Dense(64, activation='relu')(fingers_layers)\n",
    "fingers_layers = Dropout(0.2)(fingers_layers)\n",
    "output_layer = Dense(len(words), activation='softmax')(fingers_layers)\n",
    "model = Model(inputs=fingers, outputs=output_layer)\n",
    "adam = Adam(lr=0.01, decay=0.0005)\n",
    "model.compile(optimizer=adam,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 684 samples, validate on 342 samples\n",
      "Epoch 1/1000\n",
      "684/684 [==============================] - 6s 9ms/step - loss: 2.9860 - acc: 0.0395 - val_loss: 2.9403 - val_acc: 0.0702\n",
      "Epoch 2/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 2.9430 - acc: 0.0658 - val_loss: 2.7888 - val_acc: 0.0877\n",
      "Epoch 3/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 2.8344 - acc: 0.0863 - val_loss: 2.6340 - val_acc: 0.1374\n",
      "Epoch 4/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 2.7626 - acc: 0.1170 - val_loss: 2.6032 - val_acc: 0.1462\n",
      "Epoch 5/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 2.6526 - acc: 0.1272 - val_loss: 2.4004 - val_acc: 0.1579\n",
      "Epoch 6/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 2.5867 - acc: 0.1213 - val_loss: 2.3907 - val_acc: 0.2018\n",
      "Epoch 7/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 2.5833 - acc: 0.1418 - val_loss: 2.4818 - val_acc: 0.1871\n",
      "Epoch 8/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 2.4063 - acc: 0.1886 - val_loss: 2.2495 - val_acc: 0.2427\n",
      "Epoch 9/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 2.3972 - acc: 0.1784 - val_loss: 2.1400 - val_acc: 0.2368\n",
      "Epoch 10/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 2.4333 - acc: 0.1959 - val_loss: 2.1820 - val_acc: 0.2251\n",
      "Epoch 11/1000\n",
      "684/684 [==============================] - 4s 5ms/step - loss: 2.3348 - acc: 0.2061 - val_loss: 2.1229 - val_acc: 0.2310\n",
      "Epoch 12/1000\n",
      "684/684 [==============================] - 4s 6ms/step - loss: 2.2707 - acc: 0.2032 - val_loss: 2.1171 - val_acc: 0.2953\n",
      "Epoch 13/1000\n",
      "684/684 [==============================] - 4s 5ms/step - loss: 2.2099 - acc: 0.2281 - val_loss: 2.0428 - val_acc: 0.2339\n",
      "Epoch 14/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 2.2424 - acc: 0.2061 - val_loss: 1.9793 - val_acc: 0.2865\n",
      "Epoch 15/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 2.1686 - acc: 0.2383 - val_loss: 1.9208 - val_acc: 0.2836\n",
      "Epoch 16/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 2.1643 - acc: 0.2442 - val_loss: 1.9295 - val_acc: 0.2456\n",
      "Epoch 17/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 2.1050 - acc: 0.2354 - val_loss: 1.8678 - val_acc: 0.3450\n",
      "Epoch 18/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 2.1753 - acc: 0.2295 - val_loss: 1.8518 - val_acc: 0.3538\n",
      "Epoch 19/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 2.1118 - acc: 0.2178 - val_loss: 1.7434 - val_acc: 0.3860\n",
      "Epoch 20/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 2.0211 - acc: 0.2734 - val_loss: 1.6963 - val_acc: 0.4064\n",
      "Epoch 21/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 2.0569 - acc: 0.2602 - val_loss: 1.7370 - val_acc: 0.3626\n",
      "Epoch 22/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 2.0371 - acc: 0.2705 - val_loss: 1.7045 - val_acc: 0.3450\n",
      "Epoch 23/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.9698 - acc: 0.2690 - val_loss: 1.6595 - val_acc: 0.3889\n",
      "Epoch 24/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.9335 - acc: 0.2763 - val_loss: 1.5516 - val_acc: 0.4327\n",
      "Epoch 25/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.9027 - acc: 0.3085 - val_loss: 1.5786 - val_acc: 0.4006\n",
      "Epoch 26/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.8833 - acc: 0.2807 - val_loss: 1.4756 - val_acc: 0.4298\n",
      "Epoch 27/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.8799 - acc: 0.3099 - val_loss: 1.4905 - val_acc: 0.4532\n",
      "Epoch 28/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.8699 - acc: 0.3129 - val_loss: 1.4461 - val_acc: 0.4561\n",
      "Epoch 29/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.8329 - acc: 0.3202 - val_loss: 1.3928 - val_acc: 0.4678\n",
      "Epoch 30/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.7938 - acc: 0.3363 - val_loss: 1.4737 - val_acc: 0.4444\n",
      "Epoch 31/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.8004 - acc: 0.3231 - val_loss: 1.4216 - val_acc: 0.4561\n",
      "Epoch 32/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.8071 - acc: 0.3436 - val_loss: 1.6033 - val_acc: 0.4240\n",
      "Epoch 33/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.7532 - acc: 0.3538 - val_loss: 1.3420 - val_acc: 0.5175\n",
      "Epoch 34/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.8015 - acc: 0.3670 - val_loss: 1.4000 - val_acc: 0.4649\n",
      "Epoch 35/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.8023 - acc: 0.3304 - val_loss: 1.4404 - val_acc: 0.5000\n",
      "Epoch 36/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.7646 - acc: 0.3421 - val_loss: 1.3682 - val_acc: 0.5058\n",
      "Epoch 37/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.8069 - acc: 0.3348 - val_loss: 1.3988 - val_acc: 0.5029\n",
      "Epoch 38/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.6902 - acc: 0.3655 - val_loss: 1.2813 - val_acc: 0.5234\n",
      "Epoch 39/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.6422 - acc: 0.3918 - val_loss: 1.2888 - val_acc: 0.4854\n",
      "Epoch 40/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.6985 - acc: 0.3611 - val_loss: 1.3958 - val_acc: 0.4678\n",
      "Epoch 41/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.6392 - acc: 0.3904 - val_loss: 1.2924 - val_acc: 0.5088\n",
      "Epoch 42/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.6230 - acc: 0.3787 - val_loss: 1.2601 - val_acc: 0.5205\n",
      "Epoch 43/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.6453 - acc: 0.4137 - val_loss: 1.2834 - val_acc: 0.4971\n",
      "Epoch 44/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.6142 - acc: 0.3874 - val_loss: 1.2624 - val_acc: 0.5439loss: \n",
      "Epoch 45/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.6654 - acc: 0.3509 - val_loss: 1.2536 - val_acc: 0.5205\n",
      "Epoch 46/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.6339 - acc: 0.4167 - val_loss: 1.2219 - val_acc: 0.5263\n",
      "Epoch 47/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.5954 - acc: 0.3874 - val_loss: 1.2171 - val_acc: 0.5088\n",
      "Epoch 48/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6590 - acc: 0.3743 - val_loss: 1.2215 - val_acc: 0.5731\n",
      "Epoch 49/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.5735 - acc: 0.4240 - val_loss: 1.1948 - val_acc: 0.5731\n",
      "Epoch 50/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.5952 - acc: 0.4094 - val_loss: 1.1964 - val_acc: 0.5439\n",
      "Epoch 51/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.5509 - acc: 0.3918 - val_loss: 1.1902 - val_acc: 0.5468\n",
      "Epoch 52/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.5966 - acc: 0.3918 - val_loss: 1.2228 - val_acc: 0.5614\n",
      "Epoch 53/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.5584 - acc: 0.4167 - val_loss: 1.1877 - val_acc: 0.5760\n",
      "Epoch 54/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.5244 - acc: 0.3801 - val_loss: 1.1459 - val_acc: 0.5760\n",
      "Epoch 55/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.5824 - acc: 0.3816 - val_loss: 1.1635 - val_acc: 0.5643\n",
      "Epoch 56/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.5871 - acc: 0.4123 - val_loss: 1.1679 - val_acc: 0.5614\n",
      "Epoch 57/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.5771 - acc: 0.3874 - val_loss: 1.1597 - val_acc: 0.5936\n",
      "Epoch 58/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.5448 - acc: 0.4225 - val_loss: 1.1445 - val_acc: 0.5877\n",
      "Epoch 59/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.5364 - acc: 0.4357 - val_loss: 1.1688 - val_acc: 0.5731\n",
      "Epoch 60/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.5579 - acc: 0.4196 - val_loss: 1.1362 - val_acc: 0.5760\n",
      "Epoch 61/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 3s 4ms/step - loss: 1.4729 - acc: 0.4298 - val_loss: 1.1497 - val_acc: 0.5497\n",
      "Epoch 62/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.5008 - acc: 0.4064 - val_loss: 1.1310 - val_acc: 0.6199\n",
      "Epoch 63/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.5036 - acc: 0.4444 - val_loss: 1.1259 - val_acc: 0.5439\n",
      "Epoch 64/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.4662 - acc: 0.4254 - val_loss: 1.0829 - val_acc: 0.5994\n",
      "Epoch 65/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.4683 - acc: 0.4357 - val_loss: 1.1053 - val_acc: 0.5906\n",
      "Epoch 66/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.5073 - acc: 0.4547 - val_loss: 1.1072 - val_acc: 0.5585\n",
      "Epoch 67/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.4747 - acc: 0.4298 - val_loss: 1.0878 - val_acc: 0.6082\n",
      "Epoch 68/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.4226 - acc: 0.4459 - val_loss: 1.0684 - val_acc: 0.5965\n",
      "Epoch 69/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.4601 - acc: 0.4357 - val_loss: 1.0899 - val_acc: 0.5877\n",
      "Epoch 70/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.4360 - acc: 0.4561 - val_loss: 1.0715 - val_acc: 0.6199\n",
      "Epoch 71/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.4755 - acc: 0.4386 - val_loss: 1.0480 - val_acc: 0.5614\n",
      "Epoch 72/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.3924 - acc: 0.4693 - val_loss: 1.0068 - val_acc: 0.6170\n",
      "Epoch 73/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.4169 - acc: 0.4708 - val_loss: 1.0236 - val_acc: 0.6374\n",
      "Epoch 74/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.4387 - acc: 0.4547 - val_loss: 1.0090 - val_acc: 0.6287\n",
      "Epoch 75/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.4394 - acc: 0.4561 - val_loss: 1.0208 - val_acc: 0.6316\n",
      "Epoch 76/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.3771 - acc: 0.4854 - val_loss: 0.9991 - val_acc: 0.6316\n",
      "Epoch 77/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.3737 - acc: 0.5205 - val_loss: 0.9820 - val_acc: 0.6404\n",
      "Epoch 78/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.3813 - acc: 0.4795 - val_loss: 0.9979 - val_acc: 0.6462\n",
      "Epoch 79/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.3405 - acc: 0.4985 - val_loss: 0.9591 - val_acc: 0.6667\n",
      "Epoch 80/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.3376 - acc: 0.4942 - val_loss: 0.9863 - val_acc: 0.6170\n",
      "Epoch 81/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.3430 - acc: 0.4971 - val_loss: 0.9784 - val_acc: 0.6813\n",
      "Epoch 82/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.3706 - acc: 0.4898 - val_loss: 1.0019 - val_acc: 0.6725\n",
      "Epoch 83/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.3470 - acc: 0.4839 - val_loss: 0.9606 - val_acc: 0.7018\n",
      "Epoch 84/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.3561 - acc: 0.4971 - val_loss: 0.9610 - val_acc: 0.6637\n",
      "Epoch 85/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.3520 - acc: 0.5102 - val_loss: 0.9960 - val_acc: 0.6404\n",
      "Epoch 86/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.3937 - acc: 0.4591 - val_loss: 1.0154 - val_acc: 0.6520\n",
      "Epoch 87/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.3314 - acc: 0.5073 - val_loss: 1.0277 - val_acc: 0.6462\n",
      "Epoch 88/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.3074 - acc: 0.4942 - val_loss: 0.9315 - val_acc: 0.6637\n",
      "Epoch 89/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.3313 - acc: 0.5175 - val_loss: 0.9729 - val_acc: 0.6579\n",
      "Epoch 90/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.2679 - acc: 0.5058 - val_loss: 0.9656 - val_acc: 0.6550\n",
      "Epoch 91/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.2610 - acc: 0.5146 - val_loss: 0.9500 - val_acc: 0.6901\n",
      "Epoch 92/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.2516 - acc: 0.5249 - val_loss: 0.9312 - val_acc: 0.6696\n",
      "Epoch 93/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.2269 - acc: 0.5526 - val_loss: 0.8999 - val_acc: 0.6871\n",
      "Epoch 94/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.2304 - acc: 0.5453 - val_loss: 0.8789 - val_acc: 0.6959\n",
      "Epoch 95/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.2708 - acc: 0.5249 - val_loss: 0.8639 - val_acc: 0.7018\n",
      "Epoch 96/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.3623 - acc: 0.5380 - val_loss: 0.8693 - val_acc: 0.6842\n",
      "Epoch 97/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.2912 - acc: 0.5102 - val_loss: 0.8626 - val_acc: 0.6930\n",
      "Epoch 98/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.1900 - acc: 0.5439 - val_loss: 0.8445 - val_acc: 0.7105\n",
      "Epoch 99/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.2143 - acc: 0.5439 - val_loss: 0.8814 - val_acc: 0.6813\n",
      "Epoch 100/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.2531 - acc: 0.5029 - val_loss: 0.8707 - val_acc: 0.7076\n",
      "Epoch 101/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.2062 - acc: 0.5497 - val_loss: 0.8674 - val_acc: 0.6988\n",
      "Epoch 102/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.1954 - acc: 0.5424 - val_loss: 0.8481 - val_acc: 0.6930\n",
      "Epoch 103/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.2169 - acc: 0.5526 - val_loss: 0.8589 - val_acc: 0.7222\n",
      "Epoch 104/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.2092 - acc: 0.5468 - val_loss: 0.8690 - val_acc: 0.6813\n",
      "Epoch 105/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.2507 - acc: 0.5234 - val_loss: 0.8749 - val_acc: 0.6959\n",
      "Epoch 106/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.1710 - acc: 0.5439 - val_loss: 0.8891 - val_acc: 0.6696\n",
      "Epoch 107/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.2475 - acc: 0.5205 - val_loss: 0.8797 - val_acc: 0.6784\n",
      "Epoch 108/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.2485 - acc: 0.5380 - val_loss: 0.8842 - val_acc: 0.7105\n",
      "Epoch 109/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.2047 - acc: 0.5687 - val_loss: 0.8277 - val_acc: 0.7193\n",
      "Epoch 110/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.1615 - acc: 0.5731 - val_loss: 0.8308 - val_acc: 0.6784\n",
      "Epoch 111/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.2390 - acc: 0.5439 - val_loss: 0.8897 - val_acc: 0.6404\n",
      "Epoch 112/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.2050 - acc: 0.5482 - val_loss: 0.8461 - val_acc: 0.6959\n",
      "Epoch 113/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.2106 - acc: 0.5424 - val_loss: 0.8244 - val_acc: 0.6930\n",
      "Epoch 114/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.2312 - acc: 0.5687 - val_loss: 0.8220 - val_acc: 0.7105\n",
      "Epoch 115/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.2476 - acc: 0.5541 - val_loss: 0.8463 - val_acc: 0.7047\n",
      "Epoch 116/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.1940 - acc: 0.5629 - val_loss: 0.8381 - val_acc: 0.6988\n",
      "Epoch 117/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.2048 - acc: 0.5365 - val_loss: 0.8251 - val_acc: 0.7222\n",
      "Epoch 118/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.1126 - acc: 0.5804 - val_loss: 0.8102 - val_acc: 0.7164\n",
      "Epoch 119/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.2680 - acc: 0.5512 - val_loss: 0.8187 - val_acc: 0.7251\n",
      "Epoch 120/1000\n",
      "684/684 [==============================] - 4s 5ms/step - loss: 1.1775 - acc: 0.5848 - val_loss: 0.8091 - val_acc: 0.7076\n",
      "Epoch 121/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 3s 4ms/step - loss: 1.1400 - acc: 0.5716 - val_loss: 0.8105 - val_acc: 0.7047\n",
      "Epoch 122/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.1692 - acc: 0.5746 - val_loss: 0.8207 - val_acc: 0.6842\n",
      "Epoch 123/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.1972 - acc: 0.5658 - val_loss: 0.8002 - val_acc: 0.7164\n",
      "Epoch 124/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0904 - acc: 0.5892 - val_loss: 0.8185 - val_acc: 0.7018\n",
      "Epoch 125/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.2265 - acc: 0.5468 - val_loss: 0.7950 - val_acc: 0.7105\n",
      "Epoch 126/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.1670 - acc: 0.5643 - val_loss: 0.7942 - val_acc: 0.7193\n",
      "Epoch 127/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.1808 - acc: 0.5819 - val_loss: 0.7809 - val_acc: 0.7251\n",
      "Epoch 128/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.1416 - acc: 0.5760 - val_loss: 0.8003 - val_acc: 0.7047\n",
      "Epoch 129/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.1249 - acc: 0.5599 - val_loss: 0.7748 - val_acc: 0.7164\n",
      "Epoch 130/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.1353 - acc: 0.5673 - val_loss: 0.7803 - val_acc: 0.7193\n",
      "Epoch 131/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.1626 - acc: 0.5760 - val_loss: 0.8145 - val_acc: 0.7105\n",
      "Epoch 132/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.0905 - acc: 0.5980 - val_loss: 0.7811 - val_acc: 0.7193\n",
      "Epoch 133/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.1608 - acc: 0.5629 - val_loss: 0.7625 - val_acc: 0.7164\n",
      "Epoch 134/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.1698 - acc: 0.5585 - val_loss: 0.7484 - val_acc: 0.7339\n",
      "Epoch 135/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.1105 - acc: 0.5892 - val_loss: 0.7785 - val_acc: 0.7368\n",
      "Epoch 136/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.1108 - acc: 0.5775 - val_loss: 0.7676 - val_acc: 0.7456\n",
      "Epoch 137/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.1357 - acc: 0.5863 - val_loss: 0.7703 - val_acc: 0.7310\n",
      "Epoch 138/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.1184 - acc: 0.5731 - val_loss: 0.7836 - val_acc: 0.7310\n",
      "Epoch 139/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.1165 - acc: 0.5863 - val_loss: 0.7667 - val_acc: 0.7310\n",
      "Epoch 140/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0860 - acc: 0.5994 - val_loss: 0.7494 - val_acc: 0.7515\n",
      "Epoch 141/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.0841 - acc: 0.5950 - val_loss: 0.7627 - val_acc: 0.7515\n",
      "Epoch 142/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.0947 - acc: 0.5833 - val_loss: 0.7581 - val_acc: 0.7515\n",
      "Epoch 143/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.0946 - acc: 0.5746 - val_loss: 0.7567 - val_acc: 0.7368\n",
      "Epoch 144/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.1305 - acc: 0.5965 - val_loss: 0.7543 - val_acc: 0.7339\n",
      "Epoch 145/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.0835 - acc: 0.5863 - val_loss: 0.7543 - val_acc: 0.7339\n",
      "Epoch 146/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.1336 - acc: 0.5833 - val_loss: 0.7741 - val_acc: 0.7339\n",
      "Epoch 147/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.0834 - acc: 0.5965 - val_loss: 0.7639 - val_acc: 0.7251\n",
      "Epoch 148/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0957 - acc: 0.6155 - val_loss: 0.7599 - val_acc: 0.7368\n",
      "Epoch 149/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.0952 - acc: 0.6126 - val_loss: 0.7519 - val_acc: 0.7544\n",
      "Epoch 150/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0944 - acc: 0.6096 - val_loss: 0.7456 - val_acc: 0.7544\n",
      "Epoch 151/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.1537 - acc: 0.6053 - val_loss: 0.7550 - val_acc: 0.7310\n",
      "Epoch 152/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.1196 - acc: 0.5863 - val_loss: 0.7634 - val_acc: 0.7310\n",
      "Epoch 153/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.0431 - acc: 0.5994 - val_loss: 0.7464 - val_acc: 0.7544\n",
      "Epoch 154/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.0330 - acc: 0.6082 - val_loss: 0.7111 - val_acc: 0.7632\n",
      "Epoch 155/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.0938 - acc: 0.6053 - val_loss: 0.7516 - val_acc: 0.7339\n",
      "Epoch 156/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.0630 - acc: 0.6023 - val_loss: 0.7165 - val_acc: 0.7427\n",
      "Epoch 157/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.0805 - acc: 0.6111 - val_loss: 0.7290 - val_acc: 0.7427\n",
      "Epoch 158/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.0287 - acc: 0.6213 - val_loss: 0.7403 - val_acc: 0.7339\n",
      "Epoch 159/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.0674 - acc: 0.6257 - val_loss: 0.7149 - val_acc: 0.7573\n",
      "Epoch 160/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.0812 - acc: 0.5863 - val_loss: 0.7369 - val_acc: 0.7310\n",
      "Epoch 161/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.0625 - acc: 0.5921 - val_loss: 0.7409 - val_acc: 0.7427\n",
      "Epoch 162/1000\n",
      "684/684 [==============================] - 4s 5ms/step - loss: 1.0630 - acc: 0.5965 - val_loss: 0.7204 - val_acc: 0.7485\n",
      "Epoch 163/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.0977 - acc: 0.5921 - val_loss: 0.7029 - val_acc: 0.7427\n",
      "Epoch 164/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.0835 - acc: 0.6243 - val_loss: 0.7136 - val_acc: 0.7427\n",
      "Epoch 165/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0546 - acc: 0.6404 - val_loss: 0.7099 - val_acc: 0.7427\n",
      "Epoch 166/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.1190 - acc: 0.5965 - val_loss: 0.7223 - val_acc: 0.7456\n",
      "Epoch 167/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0494 - acc: 0.6301 - val_loss: 0.7036 - val_acc: 0.7427\n",
      "Epoch 168/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0400 - acc: 0.6053 - val_loss: 0.7048 - val_acc: 0.7456\n",
      "Epoch 169/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0025 - acc: 0.6330 - val_loss: 0.6869 - val_acc: 0.7368\n",
      "Epoch 170/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.1236 - acc: 0.6170 - val_loss: 0.7307 - val_acc: 0.7193\n",
      "Epoch 171/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.1356 - acc: 0.5965 - val_loss: 0.7209 - val_acc: 0.7193\n",
      "Epoch 172/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0583 - acc: 0.6023 - val_loss: 0.7221 - val_acc: 0.7339\n",
      "Epoch 173/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0736 - acc: 0.6023 - val_loss: 0.7090 - val_acc: 0.7544\n",
      "Epoch 174/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9926 - acc: 0.6477 - val_loss: 0.7032 - val_acc: 0.7485\n",
      "Epoch 175/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0808 - acc: 0.6096 - val_loss: 0.7261 - val_acc: 0.7368\n",
      "Epoch 176/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9621 - acc: 0.6287 - val_loss: 0.6983 - val_acc: 0.7485\n",
      "Epoch 177/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 1.0027 - acc: 0.6170 - val_loss: 0.7093 - val_acc: 0.7427\n",
      "Epoch 178/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9954 - acc: 0.6330 - val_loss: 0.6940 - val_acc: 0.7749\n",
      "Epoch 179/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0623 - acc: 0.5921 - val_loss: 0.7055 - val_acc: 0.7661\n",
      "Epoch 180/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0512 - acc: 0.6301 - val_loss: 0.7206 - val_acc: 0.7573\n",
      "Epoch 181/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0026 - acc: 0.6360 - val_loss: 0.7098 - val_acc: 0.7368\n",
      "Epoch 182/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0432 - acc: 0.6243 - val_loss: 0.6963 - val_acc: 0.7368\n",
      "Epoch 183/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0218 - acc: 0.6374 - val_loss: 0.6937 - val_acc: 0.7456\n",
      "Epoch 184/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9891 - acc: 0.6009 - val_loss: 0.6928 - val_acc: 0.7398\n",
      "Epoch 185/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0292 - acc: 0.6360 - val_loss: 0.6925 - val_acc: 0.7515\n",
      "Epoch 186/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9619 - acc: 0.6623 - val_loss: 0.6809 - val_acc: 0.7632\n",
      "Epoch 187/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0459 - acc: 0.6345 - val_loss: 0.6800 - val_acc: 0.7749\n",
      "Epoch 188/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.1108 - acc: 0.6243 - val_loss: 0.6953 - val_acc: 0.7544\n",
      "Epoch 189/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0552 - acc: 0.6330 - val_loss: 0.6954 - val_acc: 0.7398\n",
      "Epoch 190/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9773 - acc: 0.6389 - val_loss: 0.6834 - val_acc: 0.7398\n",
      "Epoch 191/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9814 - acc: 0.6126 - val_loss: 0.6885 - val_acc: 0.7544\n",
      "Epoch 192/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0368 - acc: 0.6053 - val_loss: 0.6854 - val_acc: 0.7544\n",
      "Epoch 193/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9667 - acc: 0.6374 - val_loss: 0.6786 - val_acc: 0.7661\n",
      "Epoch 194/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9737 - acc: 0.6506 - val_loss: 0.6560 - val_acc: 0.7602\n",
      "Epoch 195/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9116 - acc: 0.6579 - val_loss: 0.6548 - val_acc: 0.7573\n",
      "Epoch 196/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0357 - acc: 0.6360 - val_loss: 0.6965 - val_acc: 0.7368\n",
      "Epoch 197/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9698 - acc: 0.6462 - val_loss: 0.6666 - val_acc: 0.7661\n",
      "Epoch 198/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9714 - acc: 0.6433 - val_loss: 0.6705 - val_acc: 0.7573\n",
      "Epoch 199/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8930 - acc: 0.6637 - val_loss: 0.6486 - val_acc: 0.7690\n",
      "Epoch 200/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9867 - acc: 0.6784 - val_loss: 0.6654 - val_acc: 0.7398\n",
      "Epoch 201/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9574 - acc: 0.6550 - val_loss: 0.6527 - val_acc: 0.7544\n",
      "Epoch 202/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0225 - acc: 0.6491 - val_loss: 0.6628 - val_acc: 0.7456\n",
      "Epoch 203/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9521 - acc: 0.6652 - val_loss: 0.6728 - val_acc: 0.7515\n",
      "Epoch 204/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9785 - acc: 0.6594 - val_loss: 0.6645 - val_acc: 0.7573\n",
      "Epoch 205/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9471 - acc: 0.6506 - val_loss: 0.6513 - val_acc: 0.7632\n",
      "Epoch 206/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9855 - acc: 0.6404 - val_loss: 0.6489 - val_acc: 0.7602\n",
      "Epoch 207/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0177 - acc: 0.6272 - val_loss: 0.6722 - val_acc: 0.7427\n",
      "Epoch 208/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9980 - acc: 0.6374 - val_loss: 0.6656 - val_acc: 0.7515\n",
      "Epoch 209/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9429 - acc: 0.6506 - val_loss: 0.6291 - val_acc: 0.7719\n",
      "Epoch 210/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9279 - acc: 0.6681 - val_loss: 0.6295 - val_acc: 0.7778\n",
      "Epoch 211/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9332 - acc: 0.6594 - val_loss: 0.6226 - val_acc: 0.7661\n",
      "Epoch 212/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9802 - acc: 0.6330 - val_loss: 0.6396 - val_acc: 0.7778\n",
      "Epoch 213/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9756 - acc: 0.6506 - val_loss: 0.6397 - val_acc: 0.7602\n",
      "Epoch 214/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9694 - acc: 0.6462 - val_loss: 0.6137 - val_acc: 0.7778\n",
      "Epoch 215/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0095 - acc: 0.6608 - val_loss: 0.6145 - val_acc: 0.7749\n",
      "Epoch 216/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9089 - acc: 0.6711 - val_loss: 0.6192 - val_acc: 0.7836\n",
      "Epoch 217/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9481 - acc: 0.6404 - val_loss: 0.5976 - val_acc: 0.7690\n",
      "Epoch 218/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9407 - acc: 0.6579 - val_loss: 0.5972 - val_acc: 0.7865\n",
      "Epoch 219/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9152 - acc: 0.6404 - val_loss: 0.6132 - val_acc: 0.7719\n",
      "Epoch 220/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9156 - acc: 0.6652 - val_loss: 0.5995 - val_acc: 0.7807\n",
      "Epoch 221/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9917 - acc: 0.6360 - val_loss: 0.6077 - val_acc: 0.7865\n",
      "Epoch 222/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0102 - acc: 0.6360 - val_loss: 0.6354 - val_acc: 0.7749\n",
      "Epoch 223/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9116 - acc: 0.6579 - val_loss: 0.6420 - val_acc: 0.7690\n",
      "Epoch 224/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8871 - acc: 0.6652 - val_loss: 0.6131 - val_acc: 0.7778\n",
      "Epoch 225/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9475 - acc: 0.6477 - val_loss: 0.6501 - val_acc: 0.7661\n",
      "Epoch 226/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9312 - acc: 0.6462 - val_loss: 0.6363 - val_acc: 0.7749\n",
      "Epoch 227/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9816 - acc: 0.6360 - val_loss: 0.6377 - val_acc: 0.7807\n",
      "Epoch 228/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9291 - acc: 0.6696 - val_loss: 0.6195 - val_acc: 0.7690\n",
      "Epoch 229/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9634 - acc: 0.6637 - val_loss: 0.6302 - val_acc: 0.7719\n",
      "Epoch 230/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9114 - acc: 0.6681 - val_loss: 0.6103 - val_acc: 0.7719\n",
      "Epoch 231/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9477 - acc: 0.6681 - val_loss: 0.6012 - val_acc: 0.7807\n",
      "Epoch 232/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9536 - acc: 0.6535 - val_loss: 0.6214 - val_acc: 0.7690\n",
      "Epoch 233/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9893 - acc: 0.6389 - val_loss: 0.6059 - val_acc: 0.7865\n",
      "Epoch 234/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8895 - acc: 0.6667 - val_loss: 0.5995 - val_acc: 0.7924\n",
      "Epoch 235/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9222 - acc: 0.6637 - val_loss: 0.6000 - val_acc: 0.7865\n",
      "Epoch 236/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9318 - acc: 0.6462 - val_loss: 0.6063 - val_acc: 0.7895\n",
      "Epoch 237/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8914 - acc: 0.6944 - val_loss: 0.5938 - val_acc: 0.7895\n",
      "Epoch 238/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9661 - acc: 0.6711 - val_loss: 0.6056 - val_acc: 0.7865\n",
      "Epoch 239/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9078 - acc: 0.6696 - val_loss: 0.5862 - val_acc: 0.7895\n",
      "Epoch 240/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8330 - acc: 0.6857 - val_loss: 0.6107 - val_acc: 0.7719\n",
      "Epoch 241/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8798 - acc: 0.6886 - val_loss: 0.6154 - val_acc: 0.7749\n",
      "Epoch 242/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9078 - acc: 0.6681 - val_loss: 0.5962 - val_acc: 0.7865\n",
      "Epoch 243/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9012 - acc: 0.6959 - val_loss: 0.6039 - val_acc: 0.7719\n",
      "Epoch 244/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9046 - acc: 0.6681 - val_loss: 0.5972 - val_acc: 0.7807\n",
      "Epoch 245/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.9055 - acc: 0.6681 - val_loss: 0.5925 - val_acc: 0.7865\n",
      "Epoch 246/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.8889 - acc: 0.6696 - val_loss: 0.5849 - val_acc: 0.7895\n",
      "Epoch 247/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9143 - acc: 0.6784 - val_loss: 0.5957 - val_acc: 0.7836\n",
      "Epoch 248/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8997 - acc: 0.6842 - val_loss: 0.5966 - val_acc: 0.7836\n",
      "Epoch 249/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9168 - acc: 0.6608 - val_loss: 0.5904 - val_acc: 0.7836\n",
      "Epoch 250/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8819 - acc: 0.6798 - val_loss: 0.5917 - val_acc: 0.7836\n",
      "Epoch 251/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9207 - acc: 0.6740 - val_loss: 0.5912 - val_acc: 0.7836\n",
      "Epoch 252/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8945 - acc: 0.6813 - val_loss: 0.6011 - val_acc: 0.7778\n",
      "Epoch 253/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9070 - acc: 0.6594 - val_loss: 0.5916 - val_acc: 0.7778\n",
      "Epoch 254/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8993 - acc: 0.6711 - val_loss: 0.5815 - val_acc: 0.7807\n",
      "Epoch 255/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8281 - acc: 0.7018 - val_loss: 0.5856 - val_acc: 0.7953\n",
      "Epoch 256/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8749 - acc: 0.6754 - val_loss: 0.6043 - val_acc: 0.7895\n",
      "Epoch 257/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9705 - acc: 0.6608 - val_loss: 0.6171 - val_acc: 0.7661\n",
      "Epoch 258/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8468 - acc: 0.6784 - val_loss: 0.6036 - val_acc: 0.7836\n",
      "Epoch 259/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9231 - acc: 0.6813 - val_loss: 0.5984 - val_acc: 0.8041\n",
      "Epoch 260/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9381 - acc: 0.6637 - val_loss: 0.6118 - val_acc: 0.7749\n",
      "Epoch 261/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9086 - acc: 0.6740 - val_loss: 0.6020 - val_acc: 0.7895\n",
      "Epoch 262/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8850 - acc: 0.6944 - val_loss: 0.6179 - val_acc: 0.7865\n",
      "Epoch 263/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8937 - acc: 0.6681 - val_loss: 0.5842 - val_acc: 0.7982\n",
      "Epoch 264/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8340 - acc: 0.6871 - val_loss: 0.5928 - val_acc: 0.8129\n",
      "Epoch 265/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9025 - acc: 0.6623 - val_loss: 0.5719 - val_acc: 0.8099\n",
      "Epoch 266/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9171 - acc: 0.6725 - val_loss: 0.5755 - val_acc: 0.7865\n",
      "Epoch 267/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9060 - acc: 0.6681 - val_loss: 0.5762 - val_acc: 0.7924\n",
      "Epoch 268/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7967 - acc: 0.7178 - val_loss: 0.5686 - val_acc: 0.7924\n",
      "Epoch 269/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8784 - acc: 0.6711 - val_loss: 0.5742 - val_acc: 0.8012\n",
      "Epoch 270/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8911 - acc: 0.6842 - val_loss: 0.5646 - val_acc: 0.7895\n",
      "Epoch 271/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8528 - acc: 0.6901 - val_loss: 0.5924 - val_acc: 0.7778\n",
      "Epoch 272/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8431 - acc: 0.6915 - val_loss: 0.5576 - val_acc: 0.7953\n",
      "Epoch 273/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9632 - acc: 0.6769 - val_loss: 0.5708 - val_acc: 0.7895\n",
      "Epoch 274/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8753 - acc: 0.7091 - val_loss: 0.5585 - val_acc: 0.8099\n",
      "Epoch 275/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8733 - acc: 0.6754 - val_loss: 0.5673 - val_acc: 0.8099\n",
      "Epoch 276/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.8278 - acc: 0.7047 - val_loss: 0.5631 - val_acc: 0.8041\n",
      "Epoch 277/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7967 - acc: 0.7105 - val_loss: 0.5474 - val_acc: 0.8041\n",
      "Epoch 278/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7692 - acc: 0.7149 - val_loss: 0.5367 - val_acc: 0.8187\n",
      "Epoch 279/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8605 - acc: 0.7135 - val_loss: 0.5419 - val_acc: 0.8216\n",
      "Epoch 280/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.8885 - acc: 0.6798 - val_loss: 0.5544 - val_acc: 0.7865\n",
      "Epoch 281/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9311 - acc: 0.6813 - val_loss: 0.5525 - val_acc: 0.8099\n",
      "Epoch 282/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8583 - acc: 0.6681 - val_loss: 0.5593 - val_acc: 0.8041\n",
      "Epoch 283/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8680 - acc: 0.6623 - val_loss: 0.5660 - val_acc: 0.7865\n",
      "Epoch 284/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8972 - acc: 0.6857 - val_loss: 0.5714 - val_acc: 0.7953\n",
      "Epoch 285/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.0002 - acc: 0.6637 - val_loss: 0.5751 - val_acc: 0.7865\n",
      "Epoch 286/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9010 - acc: 0.6901 - val_loss: 0.5863 - val_acc: 0.7661\n",
      "Epoch 287/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9219 - acc: 0.6681 - val_loss: 0.5665 - val_acc: 0.7924\n",
      "Epoch 288/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7764 - acc: 0.7251 - val_loss: 0.5596 - val_acc: 0.8099\n",
      "Epoch 289/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8659 - acc: 0.7164 - val_loss: 0.5576 - val_acc: 0.8129\n",
      "Epoch 290/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8901 - acc: 0.6827 - val_loss: 0.5588 - val_acc: 0.8070\n",
      "Epoch 291/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8701 - acc: 0.6974 - val_loss: 0.5498 - val_acc: 0.8012\n",
      "Epoch 292/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8362 - acc: 0.6974 - val_loss: 0.5615 - val_acc: 0.8041\n",
      "Epoch 293/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8300 - acc: 0.6901 - val_loss: 0.5625 - val_acc: 0.8070\n",
      "Epoch 294/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7910 - acc: 0.7149 - val_loss: 0.5625 - val_acc: 0.8070\n",
      "Epoch 295/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8493 - acc: 0.6725 - val_loss: 0.5767 - val_acc: 0.7836\n",
      "Epoch 296/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8821 - acc: 0.6769 - val_loss: 0.5439 - val_acc: 0.8041\n",
      "Epoch 297/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8425 - acc: 0.6813 - val_loss: 0.5420 - val_acc: 0.8158\n",
      "Epoch 298/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8777 - acc: 0.6901 - val_loss: 0.5592 - val_acc: 0.8041\n",
      "Epoch 299/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8604 - acc: 0.6944 - val_loss: 0.5464 - val_acc: 0.8158\n",
      "Epoch 300/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8465 - acc: 0.6974 - val_loss: 0.5624 - val_acc: 0.7982\n",
      "Epoch 301/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8405 - acc: 0.6842 - val_loss: 0.5528 - val_acc: 0.8012\n",
      "Epoch 302/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9184 - acc: 0.6827 - val_loss: 0.5575 - val_acc: 0.8012\n",
      "Epoch 303/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8515 - acc: 0.6974 - val_loss: 0.5474 - val_acc: 0.8099\n",
      "Epoch 304/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7926 - acc: 0.7120 - val_loss: 0.5514 - val_acc: 0.8012\n",
      "Epoch 305/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8249 - acc: 0.7047 - val_loss: 0.5595 - val_acc: 0.8158\n",
      "Epoch 306/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8515 - acc: 0.6915 - val_loss: 0.5541 - val_acc: 0.7982\n",
      "Epoch 307/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8513 - acc: 0.7120 - val_loss: 0.5476 - val_acc: 0.8129\n",
      "Epoch 308/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8520 - acc: 0.6930 - val_loss: 0.5406 - val_acc: 0.8070\n",
      "Epoch 309/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8288 - acc: 0.7061 - val_loss: 0.5349 - val_acc: 0.8216\n",
      "Epoch 310/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8344 - acc: 0.6842 - val_loss: 0.5397 - val_acc: 0.8099\n",
      "Epoch 311/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8631 - acc: 0.6974 - val_loss: 0.5464 - val_acc: 0.7953\n",
      "Epoch 312/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7788 - acc: 0.7076 - val_loss: 0.5395 - val_acc: 0.8012\n",
      "Epoch 313/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8451 - acc: 0.6988 - val_loss: 0.5406 - val_acc: 0.8012\n",
      "Epoch 314/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8686 - acc: 0.6740 - val_loss: 0.5384 - val_acc: 0.8012\n",
      "Epoch 315/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8217 - acc: 0.7018 - val_loss: 0.5299 - val_acc: 0.8099\n",
      "Epoch 316/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8109 - acc: 0.7135 - val_loss: 0.5370 - val_acc: 0.7982\n",
      "Epoch 317/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8147 - acc: 0.7061 - val_loss: 0.5341 - val_acc: 0.8158\n",
      "Epoch 318/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9128 - acc: 0.7091 - val_loss: 0.5396 - val_acc: 0.8041\n",
      "Epoch 319/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9248 - acc: 0.6901 - val_loss: 0.5500 - val_acc: 0.8012\n",
      "Epoch 320/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8767 - acc: 0.6813 - val_loss: 0.5627 - val_acc: 0.7807\n",
      "Epoch 321/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7977 - acc: 0.6974 - val_loss: 0.5344 - val_acc: 0.8012\n",
      "Epoch 322/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.8454 - acc: 0.6886 - val_loss: 0.5312 - val_acc: 0.8158\n",
      "Epoch 323/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.8523 - acc: 0.7032 - val_loss: 0.5425 - val_acc: 0.8099\n",
      "Epoch 324/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8225 - acc: 0.7061 - val_loss: 0.5396 - val_acc: 0.8012\n",
      "Epoch 325/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8073 - acc: 0.7076 - val_loss: 0.5282 - val_acc: 0.7982\n",
      "Epoch 326/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7943 - acc: 0.7120 - val_loss: 0.5312 - val_acc: 0.8041\n",
      "Epoch 327/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7827 - acc: 0.7076 - val_loss: 0.5207 - val_acc: 0.8070\n",
      "Epoch 328/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8298 - acc: 0.6959 - val_loss: 0.5332 - val_acc: 0.8012\n",
      "Epoch 329/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8529 - acc: 0.7018 - val_loss: 0.5365 - val_acc: 0.7953\n",
      "Epoch 330/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8302 - acc: 0.7032 - val_loss: 0.5101 - val_acc: 0.8187\n",
      "Epoch 331/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8427 - acc: 0.7120 - val_loss: 0.5263 - val_acc: 0.8012\n",
      "Epoch 332/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7879 - acc: 0.7237 - val_loss: 0.5248 - val_acc: 0.7953\n",
      "Epoch 333/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7922 - acc: 0.7266 - val_loss: 0.5353 - val_acc: 0.7982\n",
      "Epoch 334/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7730 - acc: 0.7295 - val_loss: 0.5528 - val_acc: 0.7953\n",
      "Epoch 335/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8246 - acc: 0.7266 - val_loss: 0.5327 - val_acc: 0.8012\n",
      "Epoch 336/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8553 - acc: 0.7047 - val_loss: 0.5255 - val_acc: 0.8070\n",
      "Epoch 337/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7899 - acc: 0.7003 - val_loss: 0.5193 - val_acc: 0.8070\n",
      "Epoch 338/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7623 - acc: 0.7412 - val_loss: 0.5228 - val_acc: 0.7982\n",
      "Epoch 339/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8626 - acc: 0.7003 - val_loss: 0.5229 - val_acc: 0.8012\n",
      "Epoch 340/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7753 - acc: 0.7208 - val_loss: 0.5068 - val_acc: 0.8129\n",
      "Epoch 341/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8056 - acc: 0.7032 - val_loss: 0.4980 - val_acc: 0.8158\n",
      "Epoch 342/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8342 - acc: 0.7047 - val_loss: 0.5156 - val_acc: 0.8129\n",
      "Epoch 343/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7938 - acc: 0.7164 - val_loss: 0.5279 - val_acc: 0.7982\n",
      "Epoch 344/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8102 - acc: 0.7164 - val_loss: 0.5226 - val_acc: 0.8129\n",
      "Epoch 345/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7762 - acc: 0.7339 - val_loss: 0.5230 - val_acc: 0.8158\n",
      "Epoch 346/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8201 - acc: 0.7222 - val_loss: 0.5188 - val_acc: 0.8070\n",
      "Epoch 347/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7647 - acc: 0.7266 - val_loss: 0.4952 - val_acc: 0.8216\n",
      "Epoch 348/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7694 - acc: 0.7120 - val_loss: 0.5176 - val_acc: 0.8041\n",
      "Epoch 349/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7044 - acc: 0.7515 - val_loss: 0.5016 - val_acc: 0.8158\n",
      "Epoch 350/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8092 - acc: 0.7368 - val_loss: 0.4998 - val_acc: 0.8099\n",
      "Epoch 351/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7339 - acc: 0.7295 - val_loss: 0.5036 - val_acc: 0.8070\n",
      "Epoch 352/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8473 - acc: 0.7061 - val_loss: 0.4943 - val_acc: 0.8129\n",
      "Epoch 353/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7927 - acc: 0.7222 - val_loss: 0.5091 - val_acc: 0.7982\n",
      "Epoch 354/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.7000 - acc: 0.7558 - val_loss: 0.4867 - val_acc: 0.8129\n",
      "Epoch 355/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7873 - acc: 0.7281 - val_loss: 0.4897 - val_acc: 0.8099\n",
      "Epoch 356/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7788 - acc: 0.7339 - val_loss: 0.4895 - val_acc: 0.8099\n",
      "Epoch 357/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8045 - acc: 0.7295 - val_loss: 0.4870 - val_acc: 0.8158\n",
      "Epoch 358/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.7432 - acc: 0.7339 - val_loss: 0.4854 - val_acc: 0.8216\n",
      "Epoch 359/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7736 - acc: 0.7339 - val_loss: 0.5026 - val_acc: 0.8041\n",
      "Epoch 360/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7529 - acc: 0.7208 - val_loss: 0.4895 - val_acc: 0.8099\n",
      "Epoch 361/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8105 - acc: 0.7193 - val_loss: 0.4943 - val_acc: 0.8099\n",
      "Epoch 362/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8302 - acc: 0.7193 - val_loss: 0.4846 - val_acc: 0.8333\n",
      "Epoch 363/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7856 - acc: 0.7266 - val_loss: 0.4802 - val_acc: 0.8216\n",
      "Epoch 364/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7561 - acc: 0.7222 - val_loss: 0.4813 - val_acc: 0.8187\n",
      "Epoch 365/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8216 - acc: 0.7266 - val_loss: 0.4790 - val_acc: 0.8158\n",
      "Epoch 366/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7748 - acc: 0.7237 - val_loss: 0.4885 - val_acc: 0.8099\n",
      "Epoch 367/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7894 - acc: 0.7281 - val_loss: 0.4701 - val_acc: 0.8304\n",
      "Epoch 368/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7803 - acc: 0.7061 - val_loss: 0.4801 - val_acc: 0.8304\n",
      "Epoch 369/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7784 - acc: 0.7339 - val_loss: 0.4919 - val_acc: 0.8187\n",
      "Epoch 370/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7815 - acc: 0.7237 - val_loss: 0.5039 - val_acc: 0.8012\n",
      "Epoch 371/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7623 - acc: 0.7383 - val_loss: 0.4784 - val_acc: 0.8363\n",
      "Epoch 372/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8119 - acc: 0.7222 - val_loss: 0.4821 - val_acc: 0.8246\n",
      "Epoch 373/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7867 - acc: 0.7398 - val_loss: 0.4739 - val_acc: 0.8246\n",
      "Epoch 374/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7959 - acc: 0.7266 - val_loss: 0.4750 - val_acc: 0.8129\n",
      "Epoch 375/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7669 - acc: 0.7310 - val_loss: 0.4754 - val_acc: 0.8246\n",
      "Epoch 376/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7809 - acc: 0.7251 - val_loss: 0.4642 - val_acc: 0.8333\n",
      "Epoch 377/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7920 - acc: 0.7222 - val_loss: 0.4847 - val_acc: 0.8129\n",
      "Epoch 378/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7800 - acc: 0.7120 - val_loss: 0.4740 - val_acc: 0.8246\n",
      "Epoch 379/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8975 - acc: 0.7032 - val_loss: 0.4947 - val_acc: 0.8275\n",
      "Epoch 380/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7518 - acc: 0.7485 - val_loss: 0.4884 - val_acc: 0.8246\n",
      "Epoch 381/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7521 - acc: 0.7266 - val_loss: 0.4798 - val_acc: 0.8363\n",
      "Epoch 382/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7818 - acc: 0.7398 - val_loss: 0.4802 - val_acc: 0.8216\n",
      "Epoch 383/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8422 - acc: 0.6886 - val_loss: 0.4860 - val_acc: 0.8187\n",
      "Epoch 384/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7337 - acc: 0.7368 - val_loss: 0.4813 - val_acc: 0.8158\n",
      "Epoch 385/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8086 - acc: 0.7208 - val_loss: 0.4845 - val_acc: 0.8129\n",
      "Epoch 386/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7596 - acc: 0.7208 - val_loss: 0.4671 - val_acc: 0.8333\n",
      "Epoch 387/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7657 - acc: 0.7266 - val_loss: 0.4811 - val_acc: 0.8275\n",
      "Epoch 388/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7653 - acc: 0.7061 - val_loss: 0.4769 - val_acc: 0.8129\n",
      "Epoch 389/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7581 - acc: 0.7310 - val_loss: 0.4847 - val_acc: 0.8070\n",
      "Epoch 390/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7433 - acc: 0.7558 - val_loss: 0.4731 - val_acc: 0.8275\n",
      "Epoch 391/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7553 - acc: 0.7383 - val_loss: 0.4737 - val_acc: 0.8187\n",
      "Epoch 392/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7728 - acc: 0.7310 - val_loss: 0.4861 - val_acc: 0.8158\n",
      "Epoch 393/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7433 - acc: 0.7383 - val_loss: 0.4684 - val_acc: 0.8129\n",
      "Epoch 394/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7592 - acc: 0.7208 - val_loss: 0.4883 - val_acc: 0.8158\n",
      "Epoch 395/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7401 - acc: 0.7354 - val_loss: 0.4892 - val_acc: 0.8158\n",
      "Epoch 396/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7884 - acc: 0.7237 - val_loss: 0.5009 - val_acc: 0.7865\n",
      "Epoch 397/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6965 - acc: 0.7427 - val_loss: 0.4815 - val_acc: 0.8099\n",
      "Epoch 398/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7412 - acc: 0.7412 - val_loss: 0.4722 - val_acc: 0.8187\n",
      "Epoch 399/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7888 - acc: 0.7485 - val_loss: 0.4763 - val_acc: 0.8187\n",
      "Epoch 400/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8105 - acc: 0.7222 - val_loss: 0.4849 - val_acc: 0.8012\n",
      "Epoch 401/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8382 - acc: 0.7135 - val_loss: 0.4955 - val_acc: 0.7982\n",
      "Epoch 402/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7145 - acc: 0.7544 - val_loss: 0.4826 - val_acc: 0.8041\n",
      "Epoch 403/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7828 - acc: 0.7310 - val_loss: 0.4683 - val_acc: 0.8187\n",
      "Epoch 404/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7669 - acc: 0.7325 - val_loss: 0.4819 - val_acc: 0.8070\n",
      "Epoch 405/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7149 - acc: 0.7544 - val_loss: 0.4724 - val_acc: 0.8012\n",
      "Epoch 406/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7333 - acc: 0.7442 - val_loss: 0.4861 - val_acc: 0.8012\n",
      "Epoch 407/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7871 - acc: 0.7237 - val_loss: 0.4780 - val_acc: 0.8041\n",
      "Epoch 408/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7466 - acc: 0.7237 - val_loss: 0.4950 - val_acc: 0.8041\n",
      "Epoch 409/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8099 - acc: 0.7295 - val_loss: 0.4862 - val_acc: 0.8041\n",
      "Epoch 410/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7518 - acc: 0.7442 - val_loss: 0.4781 - val_acc: 0.8070\n",
      "Epoch 411/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7164 - acc: 0.7500 - val_loss: 0.4730 - val_acc: 0.8070\n",
      "Epoch 412/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7495 - acc: 0.7398 - val_loss: 0.4623 - val_acc: 0.8216\n",
      "Epoch 413/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7619 - acc: 0.7222 - val_loss: 0.4641 - val_acc: 0.8304\n",
      "Epoch 414/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7200 - acc: 0.7617 - val_loss: 0.4593 - val_acc: 0.8333\n",
      "Epoch 415/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7556 - acc: 0.7339 - val_loss: 0.4473 - val_acc: 0.8304\n",
      "Epoch 416/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7496 - acc: 0.7222 - val_loss: 0.4449 - val_acc: 0.8450\n",
      "Epoch 417/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7129 - acc: 0.7529 - val_loss: 0.4467 - val_acc: 0.8421\n",
      "Epoch 418/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7572 - acc: 0.7281 - val_loss: 0.4505 - val_acc: 0.8304\n",
      "Epoch 419/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7357 - acc: 0.7208 - val_loss: 0.4589 - val_acc: 0.8158\n",
      "Epoch 420/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7798 - acc: 0.7164 - val_loss: 0.4552 - val_acc: 0.8275\n",
      "Epoch 421/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7587 - acc: 0.7310 - val_loss: 0.4625 - val_acc: 0.8129\n",
      "Epoch 422/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7262 - acc: 0.7339 - val_loss: 0.4571 - val_acc: 0.8187\n",
      "Epoch 423/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6677 - acc: 0.7456 - val_loss: 0.4516 - val_acc: 0.8187\n",
      "Epoch 424/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7817 - acc: 0.7251 - val_loss: 0.4798 - val_acc: 0.7982\n",
      "Epoch 425/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6652 - acc: 0.7412 - val_loss: 0.4502 - val_acc: 0.8216\n",
      "Epoch 426/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7912 - acc: 0.7237 - val_loss: 0.4588 - val_acc: 0.8187\n",
      "Epoch 427/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7666 - acc: 0.7295 - val_loss: 0.4600 - val_acc: 0.8129\n",
      "Epoch 428/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7514 - acc: 0.7193 - val_loss: 0.4562 - val_acc: 0.8246\n",
      "Epoch 429/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7046 - acc: 0.7544 - val_loss: 0.4601 - val_acc: 0.8216\n",
      "Epoch 430/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7392 - acc: 0.7442 - val_loss: 0.4573 - val_acc: 0.8187\n",
      "Epoch 431/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7068 - acc: 0.7515 - val_loss: 0.4469 - val_acc: 0.8246\n",
      "Epoch 432/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7319 - acc: 0.7354 - val_loss: 0.4687 - val_acc: 0.8129\n",
      "Epoch 433/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7484 - acc: 0.7588 - val_loss: 0.4645 - val_acc: 0.8099\n",
      "Epoch 434/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7454 - acc: 0.7295 - val_loss: 0.4473 - val_acc: 0.8421\n",
      "Epoch 435/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7952 - acc: 0.7208 - val_loss: 0.4538 - val_acc: 0.8304\n",
      "Epoch 436/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7400 - acc: 0.7222 - val_loss: 0.4537 - val_acc: 0.8187\n",
      "Epoch 437/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7203 - acc: 0.7515 - val_loss: 0.4535 - val_acc: 0.8246\n",
      "Epoch 438/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6581 - acc: 0.7529 - val_loss: 0.4545 - val_acc: 0.8392\n",
      "Epoch 439/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7204 - acc: 0.7544 - val_loss: 0.4574 - val_acc: 0.8304\n",
      "Epoch 440/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.7394 - acc: 0.7573 - val_loss: 0.4386 - val_acc: 0.8363\n",
      "Epoch 441/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.7210 - acc: 0.7529 - val_loss: 0.4543 - val_acc: 0.8304\n",
      "Epoch 442/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7132 - acc: 0.7325 - val_loss: 0.4705 - val_acc: 0.8099\n",
      "Epoch 443/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.6987 - acc: 0.7471 - val_loss: 0.4590 - val_acc: 0.8246\n",
      "Epoch 444/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6617 - acc: 0.7515 - val_loss: 0.4534 - val_acc: 0.8275\n",
      "Epoch 445/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7208 - acc: 0.7456 - val_loss: 0.4516 - val_acc: 0.8246\n",
      "Epoch 446/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7501 - acc: 0.7471 - val_loss: 0.4455 - val_acc: 0.8246\n",
      "Epoch 447/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.6892 - acc: 0.7529 - val_loss: 0.4469 - val_acc: 0.8129\n",
      "Epoch 448/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.7421 - acc: 0.7427 - val_loss: 0.4503 - val_acc: 0.8187\n",
      "Epoch 449/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.6800 - acc: 0.7558 - val_loss: 0.4490 - val_acc: 0.8216\n",
      "Epoch 450/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7034 - acc: 0.7471 - val_loss: 0.4354 - val_acc: 0.8333\n",
      "Epoch 451/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7322 - acc: 0.7471 - val_loss: 0.4505 - val_acc: 0.8304\n",
      "Epoch 452/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6703 - acc: 0.7617 - val_loss: 0.4450 - val_acc: 0.8216\n",
      "Epoch 453/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7546 - acc: 0.7354 - val_loss: 0.4460 - val_acc: 0.8216\n",
      "Epoch 454/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.6869 - acc: 0.7485 - val_loss: 0.4399 - val_acc: 0.8158\n",
      "Epoch 455/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7154 - acc: 0.7500 - val_loss: 0.4336 - val_acc: 0.8304\n",
      "Epoch 456/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6540 - acc: 0.7705 - val_loss: 0.4405 - val_acc: 0.8363\n",
      "Epoch 457/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6483 - acc: 0.7734 - val_loss: 0.4236 - val_acc: 0.8363\n",
      "Epoch 458/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6894 - acc: 0.7675 - val_loss: 0.4185 - val_acc: 0.8275\n",
      "Epoch 459/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7942 - acc: 0.7383 - val_loss: 0.4303 - val_acc: 0.8275\n",
      "Epoch 460/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7043 - acc: 0.7632 - val_loss: 0.4186 - val_acc: 0.8392\n",
      "Epoch 461/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.7052 - acc: 0.7471 - val_loss: 0.4298 - val_acc: 0.8450\n",
      "Epoch 462/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7701 - acc: 0.7339 - val_loss: 0.4345 - val_acc: 0.8246\n",
      "Epoch 463/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7071 - acc: 0.7325 - val_loss: 0.4284 - val_acc: 0.8333\n",
      "Epoch 464/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7169 - acc: 0.7325 - val_loss: 0.4266 - val_acc: 0.8275\n",
      "Epoch 465/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6747 - acc: 0.7588 - val_loss: 0.4266 - val_acc: 0.8304\n",
      "Epoch 466/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6528 - acc: 0.7734 - val_loss: 0.4159 - val_acc: 0.8392\n",
      "Epoch 467/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7033 - acc: 0.7632 - val_loss: 0.4188 - val_acc: 0.8304\n",
      "Epoch 468/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.7137 - acc: 0.7719 - val_loss: 0.4218 - val_acc: 0.8246\n",
      "Epoch 469/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7303 - acc: 0.7456 - val_loss: 0.4348 - val_acc: 0.8304\n",
      "Epoch 470/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6832 - acc: 0.7529 - val_loss: 0.4325 - val_acc: 0.8275\n",
      "Epoch 471/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7110 - acc: 0.7602 - val_loss: 0.4416 - val_acc: 0.8333\n",
      "Epoch 472/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7400 - acc: 0.7705 - val_loss: 0.4261 - val_acc: 0.8304\n",
      "Epoch 473/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7269 - acc: 0.7281 - val_loss: 0.4295 - val_acc: 0.8304\n",
      "Epoch 474/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6991 - acc: 0.7632 - val_loss: 0.4285 - val_acc: 0.8275\n",
      "Epoch 475/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.6604 - acc: 0.7675 - val_loss: 0.4184 - val_acc: 0.8363\n",
      "Epoch 476/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6285 - acc: 0.7880 - val_loss: 0.4016 - val_acc: 0.8480\n",
      "Epoch 477/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6954 - acc: 0.7880 - val_loss: 0.4102 - val_acc: 0.8450\n",
      "Epoch 478/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7200 - acc: 0.7383 - val_loss: 0.4142 - val_acc: 0.8304\n",
      "Epoch 479/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7262 - acc: 0.7705 - val_loss: 0.4333 - val_acc: 0.8158\n",
      "Epoch 480/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7058 - acc: 0.7251 - val_loss: 0.4248 - val_acc: 0.8216\n",
      "Epoch 481/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7581 - acc: 0.7442 - val_loss: 0.4110 - val_acc: 0.8333\n",
      "Epoch 482/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7119 - acc: 0.7383 - val_loss: 0.4209 - val_acc: 0.8304\n",
      "Epoch 483/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7494 - acc: 0.7456 - val_loss: 0.4092 - val_acc: 0.8392\n",
      "Epoch 484/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6756 - acc: 0.7690 - val_loss: 0.4099 - val_acc: 0.8538\n",
      "Epoch 485/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7060 - acc: 0.7573 - val_loss: 0.4321 - val_acc: 0.8333\n",
      "Epoch 486/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7684 - acc: 0.7602 - val_loss: 0.4095 - val_acc: 0.8333\n",
      "Epoch 487/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6858 - acc: 0.7617 - val_loss: 0.4059 - val_acc: 0.8392\n",
      "Epoch 488/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7256 - acc: 0.7705 - val_loss: 0.4100 - val_acc: 0.8333\n",
      "Epoch 489/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7302 - acc: 0.7515 - val_loss: 0.4230 - val_acc: 0.8392\n",
      "Epoch 490/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.6670 - acc: 0.7544 - val_loss: 0.4218 - val_acc: 0.8392\n",
      "Epoch 491/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.6422 - acc: 0.7675 - val_loss: 0.4121 - val_acc: 0.8450\n",
      "Epoch 492/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7013 - acc: 0.7558 - val_loss: 0.4081 - val_acc: 0.8567\n",
      "Epoch 493/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.6841 - acc: 0.7529 - val_loss: 0.4070 - val_acc: 0.8480\n",
      "Epoch 494/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.6786 - acc: 0.7763 - val_loss: 0.4157 - val_acc: 0.8333\n",
      "Epoch 495/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.6323 - acc: 0.7953 - val_loss: 0.4112 - val_acc: 0.8392\n",
      "Epoch 496/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6333 - acc: 0.7807 - val_loss: 0.4194 - val_acc: 0.8392\n",
      "Epoch 497/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6913 - acc: 0.7573 - val_loss: 0.4057 - val_acc: 0.8392\n",
      "Epoch 498/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6993 - acc: 0.7573 - val_loss: 0.4213 - val_acc: 0.8421\n",
      "Epoch 499/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6961 - acc: 0.7763 - val_loss: 0.4157 - val_acc: 0.8509\n",
      "Epoch 500/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6851 - acc: 0.7632 - val_loss: 0.4113 - val_acc: 0.8480\n",
      "Epoch 501/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7691 - acc: 0.7515 - val_loss: 0.4262 - val_acc: 0.8392\n",
      "Epoch 502/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.6932 - acc: 0.7646 - val_loss: 0.4174 - val_acc: 0.8509\n",
      "Epoch 503/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.6805 - acc: 0.7515 - val_loss: 0.4191 - val_acc: 0.8363\n",
      "Epoch 504/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.6375 - acc: 0.7763 - val_loss: 0.4253 - val_acc: 0.8363\n",
      "Epoch 505/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6740 - acc: 0.7646 - val_loss: 0.4163 - val_acc: 0.8450\n",
      "Epoch 506/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6658 - acc: 0.7822 - val_loss: 0.4032 - val_acc: 0.8421\n",
      "Epoch 507/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6743 - acc: 0.7778 - val_loss: 0.4106 - val_acc: 0.8538\n",
      "Epoch 508/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.6974 - acc: 0.7617 - val_loss: 0.4126 - val_acc: 0.8363\n",
      "Epoch 509/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7221 - acc: 0.7661 - val_loss: 0.4324 - val_acc: 0.8129\n",
      "Epoch 510/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7574 - acc: 0.7383 - val_loss: 0.4038 - val_acc: 0.8363\n",
      "Epoch 511/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7075 - acc: 0.7515 - val_loss: 0.4034 - val_acc: 0.8363\n",
      "Epoch 512/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6823 - acc: 0.7456 - val_loss: 0.4098 - val_acc: 0.8392\n",
      "Epoch 513/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6197 - acc: 0.7880 - val_loss: 0.3985 - val_acc: 0.8421\n",
      "Epoch 514/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6833 - acc: 0.7617 - val_loss: 0.3933 - val_acc: 0.8450\n",
      "Epoch 515/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.6434 - acc: 0.7851 - val_loss: 0.4003 - val_acc: 0.8333\n",
      "Epoch 516/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.6502 - acc: 0.7749 - val_loss: 0.4118 - val_acc: 0.8304\n",
      "Epoch 517/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5965 - acc: 0.7807 - val_loss: 0.3994 - val_acc: 0.8304\n",
      "Epoch 518/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.6448 - acc: 0.7661 - val_loss: 0.3905 - val_acc: 0.8450\n",
      "Epoch 519/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6697 - acc: 0.7734 - val_loss: 0.4033 - val_acc: 0.8363\n",
      "Epoch 520/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6425 - acc: 0.7646 - val_loss: 0.4030 - val_acc: 0.8333\n",
      "Epoch 521/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7191 - acc: 0.7383 - val_loss: 0.4122 - val_acc: 0.8275\n",
      "Epoch 522/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.6327 - acc: 0.7661 - val_loss: 0.3892 - val_acc: 0.8392\n",
      "Epoch 523/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.6511 - acc: 0.7632 - val_loss: 0.3940 - val_acc: 0.8421\n",
      "Epoch 524/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6858 - acc: 0.7822 - val_loss: 0.3940 - val_acc: 0.8392\n",
      "Epoch 525/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6762 - acc: 0.7646 - val_loss: 0.3937 - val_acc: 0.8333\n",
      "Epoch 526/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.6519 - acc: 0.7544 - val_loss: 0.3927 - val_acc: 0.8421\n",
      "Epoch 527/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6630 - acc: 0.7734 - val_loss: 0.4020 - val_acc: 0.8363\n",
      "Epoch 528/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.6750 - acc: 0.7719 - val_loss: 0.3944 - val_acc: 0.8363\n",
      "Epoch 529/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.6913 - acc: 0.7763 - val_loss: 0.4044 - val_acc: 0.8304\n",
      "Epoch 530/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6467 - acc: 0.7792 - val_loss: 0.3983 - val_acc: 0.8450\n",
      "Epoch 531/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6574 - acc: 0.7763 - val_loss: 0.3901 - val_acc: 0.8596\n",
      "Epoch 532/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6992 - acc: 0.7632 - val_loss: 0.3903 - val_acc: 0.8450\n",
      "Epoch 533/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7563 - acc: 0.7310 - val_loss: 0.3933 - val_acc: 0.8480\n",
      "Epoch 534/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6381 - acc: 0.7836 - val_loss: 0.4026 - val_acc: 0.8480\n",
      "Epoch 535/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.6483 - acc: 0.7792 - val_loss: 0.3984 - val_acc: 0.8509\n",
      "Epoch 536/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6544 - acc: 0.7924 - val_loss: 0.4014 - val_acc: 0.8509\n",
      "Epoch 537/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6757 - acc: 0.7836 - val_loss: 0.3894 - val_acc: 0.8567\n",
      "Epoch 538/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.7617 - acc: 0.7456 - val_loss: 0.4011 - val_acc: 0.8392\n",
      "Epoch 539/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6288 - acc: 0.7734 - val_loss: 0.3985 - val_acc: 0.8421\n",
      "Epoch 540/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6473 - acc: 0.7880 - val_loss: 0.4118 - val_acc: 0.8246\n",
      "Epoch 541/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6408 - acc: 0.7617 - val_loss: 0.4013 - val_acc: 0.8392\n",
      "Epoch 542/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.7241 - acc: 0.7807 - val_loss: 0.3956 - val_acc: 0.8480\n",
      "Epoch 543/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6098 - acc: 0.7924 - val_loss: 0.3900 - val_acc: 0.8450\n",
      "Epoch 544/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6499 - acc: 0.7865 - val_loss: 0.3927 - val_acc: 0.8509\n",
      "Epoch 545/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7250 - acc: 0.7456 - val_loss: 0.4018 - val_acc: 0.8333\n",
      "Epoch 546/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6466 - acc: 0.7880 - val_loss: 0.3893 - val_acc: 0.8421\n",
      "Epoch 547/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6740 - acc: 0.7544 - val_loss: 0.3868 - val_acc: 0.8509\n",
      "Epoch 548/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6736 - acc: 0.7734 - val_loss: 0.3897 - val_acc: 0.8567\n",
      "Epoch 549/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.6488 - acc: 0.7807 - val_loss: 0.3929 - val_acc: 0.8450\n",
      "Epoch 550/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7021 - acc: 0.7558 - val_loss: 0.3954 - val_acc: 0.8450\n",
      "Epoch 551/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6356 - acc: 0.7749 - val_loss: 0.3953 - val_acc: 0.8450\n",
      "Epoch 552/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6615 - acc: 0.7763 - val_loss: 0.3910 - val_acc: 0.8509\n",
      "Epoch 553/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6531 - acc: 0.7544 - val_loss: 0.3949 - val_acc: 0.8450\n",
      "Epoch 554/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7195 - acc: 0.7690 - val_loss: 0.3939 - val_acc: 0.8480\n",
      "Epoch 555/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6225 - acc: 0.7865 - val_loss: 0.3831 - val_acc: 0.8567\n",
      "Epoch 556/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6363 - acc: 0.7895 - val_loss: 0.3798 - val_acc: 0.8450\n",
      "Epoch 557/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6880 - acc: 0.7339 - val_loss: 0.3930 - val_acc: 0.8450\n",
      "Epoch 558/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6407 - acc: 0.7865 - val_loss: 0.3941 - val_acc: 0.8480\n",
      "Epoch 559/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6576 - acc: 0.7851 - val_loss: 0.4031 - val_acc: 0.8392\n",
      "Epoch 560/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6659 - acc: 0.7602 - val_loss: 0.4009 - val_acc: 0.8363\n",
      "Epoch 561/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6638 - acc: 0.7690 - val_loss: 0.3856 - val_acc: 0.8596\n",
      "Epoch 562/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7071 - acc: 0.7690 - val_loss: 0.3869 - val_acc: 0.8567\n",
      "Epoch 563/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6136 - acc: 0.7807 - val_loss: 0.3867 - val_acc: 0.8421\n",
      "Epoch 564/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6012 - acc: 0.7924 - val_loss: 0.3836 - val_acc: 0.8480\n",
      "Epoch 565/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6394 - acc: 0.7675 - val_loss: 0.3883 - val_acc: 0.8421\n",
      "Epoch 566/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6858 - acc: 0.7675 - val_loss: 0.3922 - val_acc: 0.8421\n",
      "Epoch 567/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6744 - acc: 0.7690 - val_loss: 0.3942 - val_acc: 0.8450\n",
      "Epoch 568/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6267 - acc: 0.7719 - val_loss: 0.3835 - val_acc: 0.8626\n",
      "Epoch 569/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6275 - acc: 0.7822 - val_loss: 0.3799 - val_acc: 0.8538\n",
      "Epoch 570/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6396 - acc: 0.7865 - val_loss: 0.3798 - val_acc: 0.8538\n",
      "Epoch 571/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6777 - acc: 0.7500 - val_loss: 0.3951 - val_acc: 0.8509\n",
      "Epoch 572/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6204 - acc: 0.7953 - val_loss: 0.3829 - val_acc: 0.8567\n",
      "Epoch 573/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7046 - acc: 0.7661 - val_loss: 0.3985 - val_acc: 0.8246\n",
      "Epoch 574/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6342 - acc: 0.7851 - val_loss: 0.3999 - val_acc: 0.8363\n",
      "Epoch 575/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6890 - acc: 0.7690 - val_loss: 0.3909 - val_acc: 0.8421\n",
      "Epoch 576/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6770 - acc: 0.7544 - val_loss: 0.3828 - val_acc: 0.8480\n",
      "Epoch 577/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.6422 - acc: 0.7807 - val_loss: 0.3945 - val_acc: 0.8480\n",
      "Epoch 578/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6811 - acc: 0.7792 - val_loss: 0.3875 - val_acc: 0.8538\n",
      "Epoch 579/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7013 - acc: 0.7690 - val_loss: 0.3989 - val_acc: 0.8392\n",
      "Epoch 580/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6035 - acc: 0.7909 - val_loss: 0.3889 - val_acc: 0.8392\n",
      "Epoch 581/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5772 - acc: 0.7997 - val_loss: 0.3920 - val_acc: 0.8363\n",
      "Epoch 582/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6289 - acc: 0.7909 - val_loss: 0.3902 - val_acc: 0.8421\n",
      "Epoch 583/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6047 - acc: 0.7895 - val_loss: 0.3811 - val_acc: 0.8684\n",
      "Epoch 584/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6558 - acc: 0.7822 - val_loss: 0.3672 - val_acc: 0.8538\n",
      "Epoch 585/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7413 - acc: 0.7515 - val_loss: 0.3817 - val_acc: 0.8480\n",
      "Epoch 586/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7279 - acc: 0.7675 - val_loss: 0.3843 - val_acc: 0.8450\n",
      "Epoch 587/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6590 - acc: 0.7471 - val_loss: 0.3803 - val_acc: 0.8567\n",
      "Epoch 588/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6401 - acc: 0.7792 - val_loss: 0.3772 - val_acc: 0.8567\n",
      "Epoch 589/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.6411 - acc: 0.7880 - val_loss: 0.3910 - val_acc: 0.8333\n",
      "Epoch 590/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.6266 - acc: 0.7675 - val_loss: 0.3900 - val_acc: 0.8304\n",
      "Epoch 591/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.6387 - acc: 0.7895 - val_loss: 0.3656 - val_acc: 0.8626\n",
      "Epoch 592/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.6188 - acc: 0.7880 - val_loss: 0.3719 - val_acc: 0.8538\n",
      "Epoch 593/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.6025 - acc: 0.7968 - val_loss: 0.3811 - val_acc: 0.8509\n",
      "Epoch 594/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6441 - acc: 0.7661 - val_loss: 0.3855 - val_acc: 0.8684\n",
      "Epoch 595/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.6281 - acc: 0.7880 - val_loss: 0.3835 - val_acc: 0.8509\n",
      "Epoch 596/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.6493 - acc: 0.7749 - val_loss: 0.3833 - val_acc: 0.8392\n",
      "Epoch 597/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.6840 - acc: 0.7529 - val_loss: 0.3867 - val_acc: 0.8421\n",
      "Epoch 598/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.5933 - acc: 0.7953 - val_loss: 0.3793 - val_acc: 0.8626\n",
      "Epoch 599/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6638 - acc: 0.7617 - val_loss: 0.3801 - val_acc: 0.8450\n",
      "Epoch 600/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6479 - acc: 0.7690 - val_loss: 0.3809 - val_acc: 0.8538\n",
      "Epoch 601/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6697 - acc: 0.7705 - val_loss: 0.3760 - val_acc: 0.8480\n",
      "Epoch 602/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6159 - acc: 0.7953 - val_loss: 0.3638 - val_acc: 0.8567\n",
      "Epoch 603/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7341 - acc: 0.7690 - val_loss: 0.3677 - val_acc: 0.8684\n",
      "Epoch 604/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.6285 - acc: 0.7968 - val_loss: 0.3794 - val_acc: 0.8421\n",
      "Epoch 605/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.7309 - acc: 0.7661 - val_loss: 0.3730 - val_acc: 0.8596\n",
      "Epoch 606/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6428 - acc: 0.7792 - val_loss: 0.3702 - val_acc: 0.8596\n",
      "Epoch 607/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6324 - acc: 0.7865 - val_loss: 0.3690 - val_acc: 0.8655\n",
      "Epoch 608/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6991 - acc: 0.7880 - val_loss: 0.3657 - val_acc: 0.8684\n",
      "Epoch 609/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6191 - acc: 0.7822 - val_loss: 0.3659 - val_acc: 0.8684\n",
      "Epoch 610/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6173 - acc: 0.7690 - val_loss: 0.3704 - val_acc: 0.8509\n",
      "Epoch 611/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.6472 - acc: 0.7749 - val_loss: 0.3660 - val_acc: 0.8567\n",
      "Epoch 612/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5422 - acc: 0.8041 - val_loss: 0.3577 - val_acc: 0.8655\n",
      "Epoch 613/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6336 - acc: 0.7749 - val_loss: 0.3595 - val_acc: 0.8567\n",
      "Epoch 614/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6017 - acc: 0.7953 - val_loss: 0.3634 - val_acc: 0.8596\n",
      "Epoch 615/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6108 - acc: 0.8070 - val_loss: 0.3655 - val_acc: 0.8538\n",
      "Epoch 616/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6079 - acc: 0.8026 - val_loss: 0.3591 - val_acc: 0.8655\n",
      "Epoch 617/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6289 - acc: 0.7836 - val_loss: 0.3617 - val_acc: 0.8567\n",
      "Epoch 618/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6138 - acc: 0.7909 - val_loss: 0.3606 - val_acc: 0.8480\n",
      "Epoch 619/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6154 - acc: 0.7953 - val_loss: 0.3684 - val_acc: 0.8392\n",
      "Epoch 620/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6388 - acc: 0.7632 - val_loss: 0.3629 - val_acc: 0.8567\n",
      "Epoch 621/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5643 - acc: 0.8085 - val_loss: 0.3623 - val_acc: 0.8596\n",
      "Epoch 622/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.6398 - acc: 0.7895 - val_loss: 0.3600 - val_acc: 0.8596\n",
      "Epoch 623/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.5722 - acc: 0.7895 - val_loss: 0.3583 - val_acc: 0.8567\n",
      "Epoch 624/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.5904 - acc: 0.7909 - val_loss: 0.3579 - val_acc: 0.8655\n",
      "Epoch 625/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.6428 - acc: 0.7807 - val_loss: 0.3578 - val_acc: 0.8655\n",
      "Epoch 626/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6136 - acc: 0.7953 - val_loss: 0.3555 - val_acc: 0.8596\n",
      "Epoch 627/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6150 - acc: 0.7807 - val_loss: 0.3600 - val_acc: 0.8509\n",
      "Epoch 628/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6457 - acc: 0.7851 - val_loss: 0.3526 - val_acc: 0.8713\n",
      "Epoch 629/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6400 - acc: 0.7690 - val_loss: 0.3513 - val_acc: 0.8538\n",
      "Epoch 630/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5858 - acc: 0.7807 - val_loss: 0.3491 - val_acc: 0.8655\n",
      "Epoch 631/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6658 - acc: 0.7661 - val_loss: 0.3733 - val_acc: 0.8480\n",
      "Epoch 632/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.6607 - acc: 0.7690 - val_loss: 0.3661 - val_acc: 0.8684\n",
      "Epoch 633/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6235 - acc: 0.7880 - val_loss: 0.3565 - val_acc: 0.8655\n",
      "Epoch 634/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5914 - acc: 0.7749 - val_loss: 0.3518 - val_acc: 0.8538\n",
      "Epoch 635/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6059 - acc: 0.8026 - val_loss: 0.3463 - val_acc: 0.8772\n",
      "Epoch 636/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6621 - acc: 0.7588 - val_loss: 0.3552 - val_acc: 0.8509\n",
      "Epoch 637/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6481 - acc: 0.7836 - val_loss: 0.3636 - val_acc: 0.8626\n",
      "Epoch 638/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6266 - acc: 0.7836 - val_loss: 0.3604 - val_acc: 0.8684\n",
      "Epoch 639/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.6180 - acc: 0.7851 - val_loss: 0.3534 - val_acc: 0.8596\n",
      "Epoch 640/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5999 - acc: 0.8056 - val_loss: 0.3541 - val_acc: 0.8626\n",
      "Epoch 641/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5651 - acc: 0.7982 - val_loss: 0.3491 - val_acc: 0.8684\n",
      "Epoch 642/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6385 - acc: 0.7895 - val_loss: 0.3656 - val_acc: 0.8509\n",
      "Epoch 643/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6265 - acc: 0.7792 - val_loss: 0.3569 - val_acc: 0.8509\n",
      "Epoch 644/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7300 - acc: 0.7588 - val_loss: 0.3480 - val_acc: 0.8655\n",
      "Epoch 645/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6329 - acc: 0.7997 - val_loss: 0.3364 - val_acc: 0.8772\n",
      "Epoch 646/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.6396 - acc: 0.7865 - val_loss: 0.3612 - val_acc: 0.8480\n",
      "Epoch 647/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5831 - acc: 0.7880 - val_loss: 0.3603 - val_acc: 0.8538\n",
      "Epoch 648/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5599 - acc: 0.7968 - val_loss: 0.3564 - val_acc: 0.8538\n",
      "Epoch 649/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6196 - acc: 0.7851 - val_loss: 0.3620 - val_acc: 0.8567\n",
      "Epoch 650/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5907 - acc: 0.7895 - val_loss: 0.3441 - val_acc: 0.8743\n",
      "Epoch 651/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6050 - acc: 0.8012 - val_loss: 0.3542 - val_acc: 0.8567\n",
      "Epoch 652/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6756 - acc: 0.7836 - val_loss: 0.3591 - val_acc: 0.8596\n",
      "Epoch 653/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.6444 - acc: 0.8026 - val_loss: 0.3424 - val_acc: 0.8655\n",
      "Epoch 654/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6300 - acc: 0.7909 - val_loss: 0.3478 - val_acc: 0.8801\n",
      "Epoch 655/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5983 - acc: 0.7968 - val_loss: 0.3448 - val_acc: 0.8713\n",
      "Epoch 656/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6083 - acc: 0.7865 - val_loss: 0.3575 - val_acc: 0.8567\n",
      "Epoch 657/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5597 - acc: 0.7924 - val_loss: 0.3509 - val_acc: 0.8626\n",
      "Epoch 658/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6646 - acc: 0.7558 - val_loss: 0.3476 - val_acc: 0.8655\n",
      "Epoch 659/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5844 - acc: 0.7880 - val_loss: 0.3626 - val_acc: 0.8480\n",
      "Epoch 660/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.5768 - acc: 0.7982 - val_loss: 0.3530 - val_acc: 0.8538\n",
      "Epoch 661/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6720 - acc: 0.8012 - val_loss: 0.3417 - val_acc: 0.8713\n",
      "Epoch 662/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6238 - acc: 0.7953 - val_loss: 0.3541 - val_acc: 0.8655\n",
      "Epoch 663/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6153 - acc: 0.8099 - val_loss: 0.3602 - val_acc: 0.8596\n",
      "Epoch 664/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6734 - acc: 0.7661 - val_loss: 0.3505 - val_acc: 0.8596\n",
      "Epoch 665/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6102 - acc: 0.7865 - val_loss: 0.3538 - val_acc: 0.8567\n",
      "Epoch 666/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6166 - acc: 0.7865 - val_loss: 0.3543 - val_acc: 0.8538\n",
      "Epoch 667/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6326 - acc: 0.7763 - val_loss: 0.3451 - val_acc: 0.8567\n",
      "Epoch 668/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6468 - acc: 0.7924 - val_loss: 0.3445 - val_acc: 0.8655\n",
      "Epoch 669/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6339 - acc: 0.7909 - val_loss: 0.3588 - val_acc: 0.8509\n",
      "Epoch 670/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6154 - acc: 0.7822 - val_loss: 0.3498 - val_acc: 0.8655\n",
      "Epoch 671/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6072 - acc: 0.7939 - val_loss: 0.3473 - val_acc: 0.8626\n",
      "Epoch 672/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.6887 - acc: 0.7851 - val_loss: 0.3557 - val_acc: 0.8538\n",
      "Epoch 673/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6516 - acc: 0.7675 - val_loss: 0.3438 - val_acc: 0.8713\n",
      "Epoch 674/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.5919 - acc: 0.7865 - val_loss: 0.3517 - val_acc: 0.8743\n",
      "Epoch 675/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6383 - acc: 0.7749 - val_loss: 0.3553 - val_acc: 0.8567\n",
      "Epoch 676/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6219 - acc: 0.7675 - val_loss: 0.3499 - val_acc: 0.8655\n",
      "Epoch 677/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5527 - acc: 0.8041 - val_loss: 0.3418 - val_acc: 0.8743\n",
      "Epoch 678/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6686 - acc: 0.7880 - val_loss: 0.3564 - val_acc: 0.8684\n",
      "Epoch 679/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6632 - acc: 0.7778 - val_loss: 0.3482 - val_acc: 0.8684\n",
      "Epoch 680/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5982 - acc: 0.7865 - val_loss: 0.3464 - val_acc: 0.8743\n",
      "Epoch 681/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.6061 - acc: 0.7939 - val_loss: 0.3433 - val_acc: 0.8684\n",
      "Epoch 682/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5277 - acc: 0.8158 - val_loss: 0.3414 - val_acc: 0.8713\n",
      "Epoch 683/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6406 - acc: 0.8012 - val_loss: 0.3376 - val_acc: 0.8713\n",
      "Epoch 684/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5980 - acc: 0.7968 - val_loss: 0.3358 - val_acc: 0.8743\n",
      "Epoch 685/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6275 - acc: 0.7997 - val_loss: 0.3345 - val_acc: 0.8743\n",
      "Epoch 686/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6016 - acc: 0.8056 - val_loss: 0.3458 - val_acc: 0.8626\n",
      "Epoch 687/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.6292 - acc: 0.7939 - val_loss: 0.3423 - val_acc: 0.8626\n",
      "Epoch 688/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.5697 - acc: 0.8012 - val_loss: 0.3394 - val_acc: 0.8684\n",
      "Epoch 689/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.6397 - acc: 0.7807 - val_loss: 0.3546 - val_acc: 0.8626\n",
      "Epoch 690/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.5994 - acc: 0.7924 - val_loss: 0.3402 - val_acc: 0.8626\n",
      "Epoch 691/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.6520 - acc: 0.7778 - val_loss: 0.3496 - val_acc: 0.8538\n",
      "Epoch 692/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5669 - acc: 0.7880 - val_loss: 0.3561 - val_acc: 0.8538\n",
      "Epoch 693/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6376 - acc: 0.7939 - val_loss: 0.3643 - val_acc: 0.8509\n",
      "Epoch 694/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.5790 - acc: 0.7851 - val_loss: 0.3506 - val_acc: 0.8509\n",
      "Epoch 695/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6225 - acc: 0.7909 - val_loss: 0.3582 - val_acc: 0.8713\n",
      "Epoch 696/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5760 - acc: 0.8070 - val_loss: 0.3559 - val_acc: 0.8596\n",
      "Epoch 697/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6100 - acc: 0.7939 - val_loss: 0.3546 - val_acc: 0.8626\n",
      "Epoch 698/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6364 - acc: 0.7880 - val_loss: 0.3577 - val_acc: 0.8538\n",
      "Epoch 699/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5641 - acc: 0.8143 - val_loss: 0.3460 - val_acc: 0.8626\n",
      "Epoch 700/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5859 - acc: 0.7851 - val_loss: 0.3394 - val_acc: 0.8713\n",
      "Epoch 701/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.5732 - acc: 0.7968 - val_loss: 0.3458 - val_acc: 0.8743\n",
      "Epoch 702/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5935 - acc: 0.7895 - val_loss: 0.3385 - val_acc: 0.8772\n",
      "Epoch 703/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6256 - acc: 0.7939 - val_loss: 0.3526 - val_acc: 0.8655\n",
      "Epoch 704/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6270 - acc: 0.7851 - val_loss: 0.3563 - val_acc: 0.8626\n",
      "Epoch 705/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6921 - acc: 0.7778 - val_loss: 0.3432 - val_acc: 0.8684\n",
      "Epoch 706/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6231 - acc: 0.7924 - val_loss: 0.3406 - val_acc: 0.8830\n",
      "Epoch 707/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.5747 - acc: 0.8070 - val_loss: 0.3348 - val_acc: 0.8801\n",
      "Epoch 708/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.6691 - acc: 0.7705 - val_loss: 0.3444 - val_acc: 0.8713\n",
      "Epoch 709/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6248 - acc: 0.7690 - val_loss: 0.3481 - val_acc: 0.8596\n",
      "Epoch 710/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6245 - acc: 0.7997 - val_loss: 0.3541 - val_acc: 0.8596\n",
      "Epoch 711/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6202 - acc: 0.7939 - val_loss: 0.3511 - val_acc: 0.8655\n",
      "Epoch 712/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.5754 - acc: 0.7953 - val_loss: 0.3413 - val_acc: 0.8713\n",
      "Epoch 713/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.5677 - acc: 0.8114 - val_loss: 0.3473 - val_acc: 0.8626\n",
      "Epoch 714/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.6452 - acc: 0.7939 - val_loss: 0.3405 - val_acc: 0.8801\n",
      "Epoch 715/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.6313 - acc: 0.7807 - val_loss: 0.3578 - val_acc: 0.8596\n",
      "Epoch 716/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6533 - acc: 0.7675 - val_loss: 0.3402 - val_acc: 0.8743\n",
      "Epoch 717/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5970 - acc: 0.7968 - val_loss: 0.3409 - val_acc: 0.8713\n",
      "Epoch 718/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5787 - acc: 0.7953 - val_loss: 0.3447 - val_acc: 0.8743\n",
      "Epoch 719/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6011 - acc: 0.8041 - val_loss: 0.3540 - val_acc: 0.8596\n",
      "Epoch 720/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6256 - acc: 0.7807 - val_loss: 0.3406 - val_acc: 0.8596\n",
      "Epoch 721/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6607 - acc: 0.7939 - val_loss: 0.3506 - val_acc: 0.8655\n",
      "Epoch 722/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6129 - acc: 0.7822 - val_loss: 0.3549 - val_acc: 0.8626\n",
      "Epoch 723/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6090 - acc: 0.7865 - val_loss: 0.3545 - val_acc: 0.8509\n",
      "Epoch 724/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5865 - acc: 0.7895 - val_loss: 0.3482 - val_acc: 0.8655\n",
      "Epoch 725/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6311 - acc: 0.7807 - val_loss: 0.3537 - val_acc: 0.8596\n",
      "Epoch 726/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5948 - acc: 0.7982 - val_loss: 0.3521 - val_acc: 0.8655\n",
      "Epoch 727/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6072 - acc: 0.8026 - val_loss: 0.3504 - val_acc: 0.8684\n",
      "Epoch 728/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6432 - acc: 0.7865 - val_loss: 0.3404 - val_acc: 0.8743\n",
      "Epoch 729/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6514 - acc: 0.7646 - val_loss: 0.3422 - val_acc: 0.8743\n",
      "Epoch 730/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5731 - acc: 0.7807 - val_loss: 0.3425 - val_acc: 0.8713\n",
      "Epoch 731/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6280 - acc: 0.7865 - val_loss: 0.3502 - val_acc: 0.8626\n",
      "Epoch 732/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5513 - acc: 0.7939 - val_loss: 0.3477 - val_acc: 0.8626\n",
      "Epoch 733/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5568 - acc: 0.8202 - val_loss: 0.3423 - val_acc: 0.8713\n",
      "Epoch 734/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5927 - acc: 0.8099 - val_loss: 0.3388 - val_acc: 0.8743\n",
      "Epoch 735/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5718 - acc: 0.7997 - val_loss: 0.3418 - val_acc: 0.8684\n",
      "Epoch 736/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.5901 - acc: 0.7953 - val_loss: 0.3363 - val_acc: 0.8772\n",
      "Epoch 737/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5524 - acc: 0.7997 - val_loss: 0.3378 - val_acc: 0.8655\n",
      "Epoch 738/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5466 - acc: 0.8187 - val_loss: 0.3434 - val_acc: 0.8596\n",
      "Epoch 739/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.5896 - acc: 0.7909 - val_loss: 0.3400 - val_acc: 0.8655\n",
      "Epoch 740/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.6227 - acc: 0.7749 - val_loss: 0.3305 - val_acc: 0.8684\n",
      "Epoch 741/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.5693 - acc: 0.7953 - val_loss: 0.3427 - val_acc: 0.8772\n",
      "Epoch 742/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.5559 - acc: 0.7997 - val_loss: 0.3442 - val_acc: 0.8713\n",
      "Epoch 743/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.6148 - acc: 0.7865 - val_loss: 0.3376 - val_acc: 0.8772\n",
      "Epoch 744/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.5523 - acc: 0.8070 - val_loss: 0.3307 - val_acc: 0.8743\n",
      "Epoch 745/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6250 - acc: 0.7997 - val_loss: 0.3344 - val_acc: 0.8743\n",
      "Epoch 746/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5905 - acc: 0.8202 - val_loss: 0.3374 - val_acc: 0.8684\n",
      "Epoch 747/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5636 - acc: 0.8085 - val_loss: 0.3357 - val_acc: 0.8713\n",
      "Epoch 748/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.6609 - acc: 0.7865 - val_loss: 0.3371 - val_acc: 0.8655\n",
      "Epoch 749/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.5770 - acc: 0.7924 - val_loss: 0.3281 - val_acc: 0.8684\n",
      "Epoch 750/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.5966 - acc: 0.7968 - val_loss: 0.3280 - val_acc: 0.8772\n",
      "Epoch 751/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5749 - acc: 0.7982 - val_loss: 0.3296 - val_acc: 0.8713\n",
      "Epoch 752/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.6349 - acc: 0.7734 - val_loss: 0.3412 - val_acc: 0.8626\n",
      "Epoch 753/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.6108 - acc: 0.7880 - val_loss: 0.3345 - val_acc: 0.8713\n",
      "Epoch 754/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.5850 - acc: 0.7939 - val_loss: 0.3372 - val_acc: 0.8743\n",
      "Epoch 755/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.6386 - acc: 0.8026 - val_loss: 0.3425 - val_acc: 0.8713\n",
      "Epoch 756/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.5691 - acc: 0.8056 - val_loss: 0.3250 - val_acc: 0.8772\n",
      "Epoch 757/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.5601 - acc: 0.7939 - val_loss: 0.3238 - val_acc: 0.8830\n",
      "Epoch 758/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.5160 - acc: 0.8143 - val_loss: 0.3282 - val_acc: 0.8743\n",
      "Epoch 759/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.5926 - acc: 0.7997 - val_loss: 0.3315 - val_acc: 0.8772\n",
      "Epoch 760/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.6069 - acc: 0.7865 - val_loss: 0.3363 - val_acc: 0.8743\n",
      "Epoch 761/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5766 - acc: 0.8070 - val_loss: 0.3238 - val_acc: 0.8772\n",
      "Epoch 762/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6315 - acc: 0.8041 - val_loss: 0.3288 - val_acc: 0.8743\n",
      "Epoch 763/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5679 - acc: 0.7953 - val_loss: 0.3279 - val_acc: 0.8801\n",
      "Epoch 764/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5833 - acc: 0.7909 - val_loss: 0.3312 - val_acc: 0.8801\n",
      "Epoch 765/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5604 - acc: 0.8026 - val_loss: 0.3305 - val_acc: 0.8743\n",
      "Epoch 766/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5470 - acc: 0.8202 - val_loss: 0.3339 - val_acc: 0.8684\n",
      "Epoch 767/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5897 - acc: 0.7778 - val_loss: 0.3273 - val_acc: 0.8655\n",
      "Epoch 768/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6126 - acc: 0.7924 - val_loss: 0.3369 - val_acc: 0.8772\n",
      "Epoch 769/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5762 - acc: 0.8056 - val_loss: 0.3363 - val_acc: 0.8772\n",
      "Epoch 770/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.6131 - acc: 0.7997 - val_loss: 0.3389 - val_acc: 0.8713\n",
      "Epoch 771/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.6132 - acc: 0.7982 - val_loss: 0.3324 - val_acc: 0.8801\n",
      "Epoch 772/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.5955 - acc: 0.8070 - val_loss: 0.3284 - val_acc: 0.8801\n",
      "Epoch 773/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5760 - acc: 0.7924 - val_loss: 0.3359 - val_acc: 0.8655\n",
      "Epoch 774/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.5110 - acc: 0.8289 - val_loss: 0.3401 - val_acc: 0.8655\n",
      "Epoch 775/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5764 - acc: 0.8026 - val_loss: 0.3224 - val_acc: 0.8772\n",
      "Epoch 776/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5550 - acc: 0.8173 - val_loss: 0.3249 - val_acc: 0.8889\n",
      "Epoch 777/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5535 - acc: 0.7997 - val_loss: 0.3329 - val_acc: 0.8713\n",
      "Epoch 778/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6167 - acc: 0.7953 - val_loss: 0.3439 - val_acc: 0.8626\n",
      "Epoch 779/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5429 - acc: 0.8129 - val_loss: 0.3350 - val_acc: 0.8743\n",
      "Epoch 780/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6046 - acc: 0.7982 - val_loss: 0.3355 - val_acc: 0.8713\n",
      "Epoch 781/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5885 - acc: 0.7924 - val_loss: 0.3346 - val_acc: 0.8596\n",
      "Epoch 782/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5812 - acc: 0.8085 - val_loss: 0.3315 - val_acc: 0.8684\n",
      "Epoch 783/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5847 - acc: 0.8026 - val_loss: 0.3314 - val_acc: 0.8713\n",
      "Epoch 784/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5138 - acc: 0.8304 - val_loss: 0.3380 - val_acc: 0.8655\n",
      "Epoch 785/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5669 - acc: 0.8056 - val_loss: 0.3259 - val_acc: 0.8801\n",
      "Epoch 786/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5719 - acc: 0.7968 - val_loss: 0.3251 - val_acc: 0.8743\n",
      "Epoch 787/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5994 - acc: 0.8026 - val_loss: 0.3152 - val_acc: 0.8889TA: 1s - loss: 0.6\n",
      "Epoch 788/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5179 - acc: 0.8275 - val_loss: 0.3172 - val_acc: 0.8801\n",
      "Epoch 789/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6014 - acc: 0.8070 - val_loss: 0.3255 - val_acc: 0.8801\n",
      "Epoch 790/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5712 - acc: 0.8099 - val_loss: 0.3330 - val_acc: 0.8801\n",
      "Epoch 791/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6028 - acc: 0.7982 - val_loss: 0.3231 - val_acc: 0.8801\n",
      "Epoch 792/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.5698 - acc: 0.7997 - val_loss: 0.3188 - val_acc: 0.8830\n",
      "Epoch 793/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5510 - acc: 0.8070 - val_loss: 0.3279 - val_acc: 0.8743\n",
      "Epoch 794/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5560 - acc: 0.8289 - val_loss: 0.3373 - val_acc: 0.8713\n",
      "Epoch 795/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5526 - acc: 0.7924 - val_loss: 0.3203 - val_acc: 0.8860\n",
      "Epoch 796/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.6227 - acc: 0.8085 - val_loss: 0.3306 - val_acc: 0.8684\n",
      "Epoch 797/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.5695 - acc: 0.8173 - val_loss: 0.3371 - val_acc: 0.8655\n",
      "Epoch 798/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.5742 - acc: 0.7968 - val_loss: 0.3325 - val_acc: 0.8684\n",
      "Epoch 799/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.5630 - acc: 0.8114 - val_loss: 0.3179 - val_acc: 0.8772\n",
      "Epoch 800/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5823 - acc: 0.8114 - val_loss: 0.3205 - val_acc: 0.8684\n",
      "Epoch 801/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.5584 - acc: 0.7982 - val_loss: 0.3224 - val_acc: 0.8772\n",
      "Epoch 802/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.5333 - acc: 0.8085 - val_loss: 0.3224 - val_acc: 0.8743\n",
      "Epoch 803/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.5643 - acc: 0.8012 - val_loss: 0.3288 - val_acc: 0.8684\n",
      "Epoch 804/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5027 - acc: 0.8246 - val_loss: 0.3186 - val_acc: 0.8713\n",
      "Epoch 805/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.5580 - acc: 0.8085 - val_loss: 0.3216 - val_acc: 0.8801\n",
      "Epoch 806/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.5698 - acc: 0.8173 - val_loss: 0.3292 - val_acc: 0.8655\n",
      "Epoch 807/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6020 - acc: 0.8056 - val_loss: 0.3145 - val_acc: 0.8772\n",
      "Epoch 808/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6633 - acc: 0.7865 - val_loss: 0.3150 - val_acc: 0.8830\n",
      "Epoch 809/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.5783 - acc: 0.8158 - val_loss: 0.3078 - val_acc: 0.8801\n",
      "Epoch 810/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.5690 - acc: 0.8173 - val_loss: 0.3133 - val_acc: 0.8830\n",
      "Epoch 811/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.5199 - acc: 0.8319 - val_loss: 0.3133 - val_acc: 0.8830\n",
      "Epoch 812/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.5387 - acc: 0.8202 - val_loss: 0.3105 - val_acc: 0.8830\n",
      "Epoch 813/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.5095 - acc: 0.8202 - val_loss: 0.3124 - val_acc: 0.8860\n",
      "Epoch 814/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6088 - acc: 0.7749 - val_loss: 0.3216 - val_acc: 0.8743\n",
      "Epoch 815/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6056 - acc: 0.7909 - val_loss: 0.3217 - val_acc: 0.8772\n",
      "Epoch 816/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.4869 - acc: 0.8275 - val_loss: 0.3131 - val_acc: 0.8830\n",
      "Epoch 817/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.5489 - acc: 0.8202 - val_loss: 0.3128 - val_acc: 0.8772\n",
      "Epoch 818/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.6178 - acc: 0.7982 - val_loss: 0.3078 - val_acc: 0.8889\n",
      "Epoch 819/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.6028 - acc: 0.7968 - val_loss: 0.3178 - val_acc: 0.8713\n",
      "Epoch 820/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5056 - acc: 0.8070 - val_loss: 0.3137 - val_acc: 0.8801\n",
      "Epoch 821/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5700 - acc: 0.8041 - val_loss: 0.3178 - val_acc: 0.8801\n",
      "Epoch 822/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.5667 - acc: 0.8099 - val_loss: 0.3183 - val_acc: 0.8772\n",
      "Epoch 823/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5951 - acc: 0.7982 - val_loss: 0.3146 - val_acc: 0.8713\n",
      "Epoch 824/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5240 - acc: 0.8099 - val_loss: 0.3107 - val_acc: 0.8801\n",
      "Epoch 825/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5877 - acc: 0.7997 - val_loss: 0.3148 - val_acc: 0.8801\n",
      "Epoch 826/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5438 - acc: 0.8041 - val_loss: 0.3155 - val_acc: 0.8830\n",
      "Epoch 827/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5723 - acc: 0.7924 - val_loss: 0.3231 - val_acc: 0.8743\n",
      "Epoch 828/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5857 - acc: 0.7865 - val_loss: 0.3251 - val_acc: 0.8626\n",
      "Epoch 829/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5300 - acc: 0.8246 - val_loss: 0.3054 - val_acc: 0.8889\n",
      "Epoch 830/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5245 - acc: 0.8158 - val_loss: 0.3007 - val_acc: 0.8830\n",
      "Epoch 831/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6254 - acc: 0.8026 - val_loss: 0.3130 - val_acc: 0.8830\n",
      "Epoch 832/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5931 - acc: 0.7807 - val_loss: 0.3066 - val_acc: 0.8801\n",
      "Epoch 833/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5392 - acc: 0.8070 - val_loss: 0.3090 - val_acc: 0.8860\n",
      "Epoch 834/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6160 - acc: 0.8129 - val_loss: 0.3100 - val_acc: 0.8860\n",
      "Epoch 835/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.5568 - acc: 0.8012 - val_loss: 0.3046 - val_acc: 0.8947\n",
      "Epoch 836/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.5627 - acc: 0.8231 - val_loss: 0.3077 - val_acc: 0.8860\n",
      "Epoch 837/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5574 - acc: 0.8158 - val_loss: 0.3124 - val_acc: 0.8860\n",
      "Epoch 838/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5693 - acc: 0.7982 - val_loss: 0.3159 - val_acc: 0.8918\n",
      "Epoch 839/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5286 - acc: 0.8143 - val_loss: 0.3059 - val_acc: 0.8977\n",
      "Epoch 840/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5269 - acc: 0.8056 - val_loss: 0.3041 - val_acc: 0.8860\n",
      "Epoch 841/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6332 - acc: 0.7895 - val_loss: 0.3078 - val_acc: 0.8801\n",
      "Epoch 842/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5388 - acc: 0.8216 - val_loss: 0.3062 - val_acc: 0.8830\n",
      "Epoch 843/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6026 - acc: 0.7997 - val_loss: 0.3088 - val_acc: 0.8860\n",
      "Epoch 844/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5394 - acc: 0.8026 - val_loss: 0.3169 - val_acc: 0.8860\n",
      "Epoch 845/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5094 - acc: 0.8231 - val_loss: 0.3102 - val_acc: 0.8860\n",
      "Epoch 846/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5270 - acc: 0.8129 - val_loss: 0.3170 - val_acc: 0.8830\n",
      "Epoch 847/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5351 - acc: 0.8114 - val_loss: 0.3036 - val_acc: 0.8713\n",
      "Epoch 848/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6291 - acc: 0.7939 - val_loss: 0.3075 - val_acc: 0.8655\n",
      "Epoch 849/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5576 - acc: 0.8143 - val_loss: 0.3016 - val_acc: 0.8713\n",
      "Epoch 850/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5234 - acc: 0.8202 - val_loss: 0.3023 - val_acc: 0.8684\n",
      "Epoch 851/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5271 - acc: 0.8085 - val_loss: 0.3141 - val_acc: 0.8713\n",
      "Epoch 852/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5354 - acc: 0.8099 - val_loss: 0.3119 - val_acc: 0.8860\n",
      "Epoch 853/1000\n",
      "684/684 [==============================] - ETA: 0s - loss: 0.6079 - acc: 0.814 - 2s 3ms/step - loss: 0.6055 - acc: 0.8158 - val_loss: 0.3281 - val_acc: 0.8801\n",
      "Epoch 854/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6099 - acc: 0.7807 - val_loss: 0.3220 - val_acc: 0.8830\n",
      "Epoch 855/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5407 - acc: 0.8158 - val_loss: 0.3162 - val_acc: 0.8889\n",
      "Epoch 856/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5994 - acc: 0.7895 - val_loss: 0.3125 - val_acc: 0.8743\n",
      "Epoch 857/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5983 - acc: 0.8026 - val_loss: 0.3128 - val_acc: 0.8743\n",
      "Epoch 858/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5555 - acc: 0.8143 - val_loss: 0.3120 - val_acc: 0.8918\n",
      "Epoch 859/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5421 - acc: 0.7968 - val_loss: 0.3025 - val_acc: 0.8918\n",
      "Epoch 860/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5422 - acc: 0.8202 - val_loss: 0.2990 - val_acc: 0.8889\n",
      "Epoch 861/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5563 - acc: 0.8187 - val_loss: 0.2950 - val_acc: 0.8860\n",
      "Epoch 862/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5960 - acc: 0.7763 - val_loss: 0.3104 - val_acc: 0.8743\n",
      "Epoch 863/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5701 - acc: 0.8026 - val_loss: 0.3081 - val_acc: 0.8830\n",
      "Epoch 864/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5053 - acc: 0.8304 - val_loss: 0.3128 - val_acc: 0.8860\n",
      "Epoch 865/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5577 - acc: 0.8129 - val_loss: 0.3129 - val_acc: 0.8889\n",
      "Epoch 866/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5807 - acc: 0.7939 - val_loss: 0.3171 - val_acc: 0.8860\n",
      "Epoch 867/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5645 - acc: 0.8099 - val_loss: 0.3089 - val_acc: 0.8918\n",
      "Epoch 868/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5371 - acc: 0.8363 - val_loss: 0.3187 - val_acc: 0.8830\n",
      "Epoch 869/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6630 - acc: 0.7924 - val_loss: 0.3183 - val_acc: 0.8830\n",
      "Epoch 870/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6199 - acc: 0.7895 - val_loss: 0.3130 - val_acc: 0.8830\n",
      "Epoch 871/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5667 - acc: 0.8202 - val_loss: 0.3099 - val_acc: 0.8860\n",
      "Epoch 872/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.4982 - acc: 0.8289 - val_loss: 0.3167 - val_acc: 0.8801\n",
      "Epoch 873/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5401 - acc: 0.8216 - val_loss: 0.3128 - val_acc: 0.8743\n",
      "Epoch 874/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5500 - acc: 0.8143 - val_loss: 0.3065 - val_acc: 0.8713\n",
      "Epoch 875/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5616 - acc: 0.8114 - val_loss: 0.3009 - val_acc: 0.8743\n",
      "Epoch 876/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5088 - acc: 0.8216 - val_loss: 0.3022 - val_acc: 0.8743\n",
      "Epoch 877/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5263 - acc: 0.8114 - val_loss: 0.3073 - val_acc: 0.8772\n",
      "Epoch 878/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5599 - acc: 0.7924 - val_loss: 0.2996 - val_acc: 0.8918\n",
      "Epoch 879/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6060 - acc: 0.7909 - val_loss: 0.3028 - val_acc: 0.8947\n",
      "Epoch 880/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6067 - acc: 0.7953 - val_loss: 0.3089 - val_acc: 0.8860\n",
      "Epoch 881/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5618 - acc: 0.8085 - val_loss: 0.3033 - val_acc: 0.8918\n",
      "Epoch 882/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5837 - acc: 0.8056 - val_loss: 0.3108 - val_acc: 0.8860\n",
      "Epoch 883/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5565 - acc: 0.8187 - val_loss: 0.3101 - val_acc: 0.8830\n",
      "Epoch 884/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5242 - acc: 0.7997 - val_loss: 0.3065 - val_acc: 0.8830\n",
      "Epoch 885/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.4952 - acc: 0.8304 - val_loss: 0.3057 - val_acc: 0.8801\n",
      "Epoch 886/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5131 - acc: 0.8333 - val_loss: 0.3004 - val_acc: 0.8860\n",
      "Epoch 887/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5641 - acc: 0.8143 - val_loss: 0.3019 - val_acc: 0.8918\n",
      "Epoch 888/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5787 - acc: 0.8070 - val_loss: 0.2974 - val_acc: 0.8889\n",
      "Epoch 889/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5152 - acc: 0.8173 - val_loss: 0.3025 - val_acc: 0.8918\n",
      "Epoch 890/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5091 - acc: 0.8319 - val_loss: 0.2955 - val_acc: 0.8977\n",
      "Epoch 891/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5641 - acc: 0.8056 - val_loss: 0.2908 - val_acc: 0.9006\n",
      "Epoch 892/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5423 - acc: 0.8099 - val_loss: 0.2934 - val_acc: 0.8977\n",
      "Epoch 893/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6125 - acc: 0.8070 - val_loss: 0.2997 - val_acc: 0.8977\n",
      "Epoch 894/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5652 - acc: 0.7953 - val_loss: 0.2939 - val_acc: 0.8918\n",
      "Epoch 895/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6229 - acc: 0.8143 - val_loss: 0.2944 - val_acc: 0.8860\n",
      "Epoch 896/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5128 - acc: 0.8129 - val_loss: 0.2926 - val_acc: 0.8889\n",
      "Epoch 897/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5184 - acc: 0.8231 - val_loss: 0.2931 - val_acc: 0.8889\n",
      "Epoch 898/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6060 - acc: 0.8099 - val_loss: 0.2917 - val_acc: 0.8860\n",
      "Epoch 899/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5611 - acc: 0.8114 - val_loss: 0.3026 - val_acc: 0.8801\n",
      "Epoch 900/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5972 - acc: 0.7924 - val_loss: 0.3039 - val_acc: 0.8830\n",
      "Epoch 901/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5333 - acc: 0.8363 - val_loss: 0.2952 - val_acc: 0.8977\n",
      "Epoch 902/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.4951 - acc: 0.8231 - val_loss: 0.3019 - val_acc: 0.8889\n",
      "Epoch 903/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5629 - acc: 0.8304 - val_loss: 0.2962 - val_acc: 0.8889\n",
      "Epoch 904/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5114 - acc: 0.8114 - val_loss: 0.3016 - val_acc: 0.8947\n",
      "Epoch 905/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5471 - acc: 0.8246 - val_loss: 0.2874 - val_acc: 0.8977\n",
      "Epoch 906/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5440 - acc: 0.8246 - val_loss: 0.2886 - val_acc: 0.8918\n",
      "Epoch 907/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6097 - acc: 0.7939 - val_loss: 0.2884 - val_acc: 0.8889\n",
      "Epoch 908/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6657 - acc: 0.8099 - val_loss: 0.2859 - val_acc: 0.8977\n",
      "Epoch 909/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5169 - acc: 0.8114 - val_loss: 0.2975 - val_acc: 0.8860\n",
      "Epoch 910/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5366 - acc: 0.8012 - val_loss: 0.3027 - val_acc: 0.8889\n",
      "Epoch 911/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5039 - acc: 0.8070 - val_loss: 0.3004 - val_acc: 0.8947\n",
      "Epoch 912/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5553 - acc: 0.7968 - val_loss: 0.3025 - val_acc: 0.8801\n",
      "Epoch 913/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5320 - acc: 0.8129 - val_loss: 0.3054 - val_acc: 0.8889\n",
      "Epoch 914/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5313 - acc: 0.8026 - val_loss: 0.2921 - val_acc: 0.8977\n",
      "Epoch 915/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5790 - acc: 0.8070 - val_loss: 0.2855 - val_acc: 0.9094\n",
      "Epoch 916/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5547 - acc: 0.8099 - val_loss: 0.2875 - val_acc: 0.9006\n",
      "Epoch 917/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5472 - acc: 0.8056 - val_loss: 0.2915 - val_acc: 0.8947\n",
      "Epoch 918/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5321 - acc: 0.8085 - val_loss: 0.2964 - val_acc: 0.8918\n",
      "Epoch 919/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5463 - acc: 0.7997 - val_loss: 0.3008 - val_acc: 0.8918\n",
      "Epoch 920/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5467 - acc: 0.8275 - val_loss: 0.2967 - val_acc: 0.8947\n",
      "Epoch 921/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.4903 - acc: 0.8304 - val_loss: 0.2921 - val_acc: 0.9006\n",
      "Epoch 922/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5637 - acc: 0.8187 - val_loss: 0.2897 - val_acc: 0.8947\n",
      "Epoch 923/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5101 - acc: 0.8289 - val_loss: 0.2910 - val_acc: 0.8947\n",
      "Epoch 924/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5560 - acc: 0.8099 - val_loss: 0.2961 - val_acc: 0.8947\n",
      "Epoch 925/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5515 - acc: 0.8099 - val_loss: 0.2948 - val_acc: 0.8947\n",
      "Epoch 926/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5213 - acc: 0.8187 - val_loss: 0.2890 - val_acc: 0.8947\n",
      "Epoch 927/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5638 - acc: 0.8041 - val_loss: 0.2949 - val_acc: 0.8918\n",
      "Epoch 928/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5341 - acc: 0.8231 - val_loss: 0.2968 - val_acc: 0.8860\n",
      "Epoch 929/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5965 - acc: 0.7982 - val_loss: 0.2973 - val_acc: 0.8889\n",
      "Epoch 930/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5043 - acc: 0.8231 - val_loss: 0.2995 - val_acc: 0.8947\n",
      "Epoch 931/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5509 - acc: 0.8187 - val_loss: 0.3035 - val_acc: 0.8947\n",
      "Epoch 932/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5898 - acc: 0.8187 - val_loss: 0.3029 - val_acc: 0.8918\n",
      "Epoch 933/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6104 - acc: 0.8012 - val_loss: 0.2991 - val_acc: 0.8830\n",
      "Epoch 934/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5118 - acc: 0.8260 - val_loss: 0.2970 - val_acc: 0.8889\n",
      "Epoch 935/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5211 - acc: 0.8304 - val_loss: 0.2862 - val_acc: 0.9006\n",
      "Epoch 936/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5692 - acc: 0.8143 - val_loss: 0.2910 - val_acc: 0.9006\n",
      "Epoch 937/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6066 - acc: 0.7939 - val_loss: 0.2997 - val_acc: 0.8947\n",
      "Epoch 938/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5227 - acc: 0.8202 - val_loss: 0.2985 - val_acc: 0.8977\n",
      "Epoch 939/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5454 - acc: 0.8319 - val_loss: 0.3030 - val_acc: 0.8918\n",
      "Epoch 940/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.5118 - acc: 0.8333 - val_loss: 0.3083 - val_acc: 0.8860\n",
      "Epoch 941/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5507 - acc: 0.8085 - val_loss: 0.3085 - val_acc: 0.8801\n",
      "Epoch 942/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.4837 - acc: 0.8421 - val_loss: 0.2999 - val_acc: 0.8889\n",
      "Epoch 943/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5224 - acc: 0.8246 - val_loss: 0.3074 - val_acc: 0.8947\n",
      "Epoch 944/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5471 - acc: 0.8173 - val_loss: 0.3062 - val_acc: 0.8860\n",
      "Epoch 945/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5356 - acc: 0.8289 - val_loss: 0.2966 - val_acc: 0.8977\n",
      "Epoch 946/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.5339 - acc: 0.8246 - val_loss: 0.2949 - val_acc: 0.8918\n",
      "Epoch 947/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5523 - acc: 0.8187 - val_loss: 0.2938 - val_acc: 0.8889\n",
      "Epoch 948/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6152 - acc: 0.8129 - val_loss: 0.2905 - val_acc: 0.8860\n",
      "Epoch 949/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5139 - acc: 0.8319 - val_loss: 0.2946 - val_acc: 0.8889\n",
      "Epoch 950/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.4948 - acc: 0.8319 - val_loss: 0.2879 - val_acc: 0.8918\n",
      "Epoch 951/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5422 - acc: 0.8246 - val_loss: 0.2927 - val_acc: 0.8977\n",
      "Epoch 952/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6091 - acc: 0.7880 - val_loss: 0.2902 - val_acc: 0.8947\n",
      "Epoch 953/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5239 - acc: 0.8275 - val_loss: 0.3023 - val_acc: 0.8918\n",
      "Epoch 954/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5539 - acc: 0.8070 - val_loss: 0.3049 - val_acc: 0.8889\n",
      "Epoch 955/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5349 - acc: 0.8216 - val_loss: 0.2976 - val_acc: 0.8947\n",
      "Epoch 956/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.4850 - acc: 0.8363 - val_loss: 0.2875 - val_acc: 0.8977\n",
      "Epoch 957/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.4830 - acc: 0.8319 - val_loss: 0.2921 - val_acc: 0.8889\n",
      "Epoch 958/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5639 - acc: 0.7968 - val_loss: 0.2928 - val_acc: 0.8860\n",
      "Epoch 959/1000\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.5373 - acc: 0.8260 - val_loss: 0.2935 - val_acc: 0.8830\n",
      "Epoch 960/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.4904 - acc: 0.8406 - val_loss: 0.2846 - val_acc: 0.9006\n",
      "Epoch 961/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5745 - acc: 0.8231 - val_loss: 0.2845 - val_acc: 0.9006\n",
      "Epoch 962/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5345 - acc: 0.8173 - val_loss: 0.2861 - val_acc: 0.9035\n",
      "Epoch 963/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5413 - acc: 0.8202 - val_loss: 0.2929 - val_acc: 0.8918\n",
      "Epoch 964/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.5200 - acc: 0.8260 - val_loss: 0.2893 - val_acc: 0.8889\n",
      "Epoch 965/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5457 - acc: 0.8319 - val_loss: 0.2871 - val_acc: 0.8977\n",
      "Epoch 966/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5704 - acc: 0.8231 - val_loss: 0.2866 - val_acc: 0.8947\n",
      "Epoch 967/1000\n",
      "684/684 [==============================] - 5s 7ms/step - loss: 0.5626 - acc: 0.8026 - val_loss: 0.2880 - val_acc: 0.8889\n",
      "Epoch 968/1000\n",
      "684/684 [==============================] - 7s 11ms/step - loss: 0.5356 - acc: 0.8275 - val_loss: 0.2871 - val_acc: 0.8918\n",
      "Epoch 969/1000\n",
      "684/684 [==============================] - 7s 11ms/step - loss: 0.5937 - acc: 0.8129 - val_loss: 0.2894 - val_acc: 0.8889\n",
      "Epoch 970/1000\n",
      "684/684 [==============================] - 6s 9ms/step - loss: 0.5237 - acc: 0.8289 - val_loss: 0.2905 - val_acc: 0.8947\n",
      "Epoch 971/1000\n",
      "684/684 [==============================] - 6s 9ms/step - loss: 0.5014 - acc: 0.8143 - val_loss: 0.2884 - val_acc: 0.8977\n",
      "Epoch 972/1000\n",
      "684/684 [==============================] - 7s 10ms/step - loss: 0.5160 - acc: 0.8275 - val_loss: 0.2909 - val_acc: 0.8947\n",
      "Epoch 973/1000\n",
      "684/684 [==============================] - 6s 9ms/step - loss: 0.4973 - acc: 0.8348 - val_loss: 0.2928 - val_acc: 0.8860\n",
      "Epoch 974/1000\n",
      "684/684 [==============================] - 6s 9ms/step - loss: 0.5521 - acc: 0.8202 - val_loss: 0.2901 - val_acc: 0.8918\n",
      "Epoch 975/1000\n",
      "684/684 [==============================] - 4s 6ms/step - loss: 0.5885 - acc: 0.8216 - val_loss: 0.2946 - val_acc: 0.8889\n",
      "Epoch 976/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5659 - acc: 0.8129 - val_loss: 0.2938 - val_acc: 0.8947\n",
      "Epoch 977/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5667 - acc: 0.8173 - val_loss: 0.2854 - val_acc: 0.8918\n",
      "Epoch 978/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5817 - acc: 0.8026 - val_loss: 0.2836 - val_acc: 0.8947\n",
      "Epoch 979/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.5009 - acc: 0.8304 - val_loss: 0.2869 - val_acc: 0.9006\n",
      "Epoch 980/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.6046 - acc: 0.8114 - val_loss: 0.2962 - val_acc: 0.8889\n",
      "Epoch 981/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.5104 - acc: 0.8289 - val_loss: 0.2974 - val_acc: 0.8860\n",
      "Epoch 982/1000\n",
      "684/684 [==============================] - 7s 11ms/step - loss: 0.5647 - acc: 0.8260 - val_loss: 0.2886 - val_acc: 0.8947\n",
      "Epoch 983/1000\n",
      "684/684 [==============================] - 8s 12ms/step - loss: 0.6351 - acc: 0.7968 - val_loss: 0.2938 - val_acc: 0.8918\n",
      "Epoch 984/1000\n",
      "684/684 [==============================] - 8s 11ms/step - loss: 0.5125 - acc: 0.8304 - val_loss: 0.2949 - val_acc: 0.8889\n",
      "Epoch 985/1000\n",
      "684/684 [==============================] - 8s 12ms/step - loss: 0.4919 - acc: 0.8392 - val_loss: 0.2977 - val_acc: 0.8830\n",
      "Epoch 986/1000\n",
      "684/684 [==============================] - 9s 13ms/step - loss: 0.5119 - acc: 0.8319 - val_loss: 0.2880 - val_acc: 0.8860\n",
      "Epoch 987/1000\n",
      "684/684 [==============================] - 9s 13ms/step - loss: 0.5131 - acc: 0.8187 - val_loss: 0.2802 - val_acc: 0.9064\n",
      "Epoch 988/1000\n",
      "684/684 [==============================] - 9s 13ms/step - loss: 0.4635 - acc: 0.8494 - val_loss: 0.2854 - val_acc: 0.8947\n",
      "Epoch 989/1000\n",
      "684/684 [==============================] - 9s 13ms/step - loss: 0.5685 - acc: 0.8289 - val_loss: 0.2959 - val_acc: 0.8772\n",
      "Epoch 990/1000\n",
      "684/684 [==============================] - 8s 12ms/step - loss: 0.4896 - acc: 0.8406 - val_loss: 0.2909 - val_acc: 0.8860\n",
      "Epoch 991/1000\n",
      "684/684 [==============================] - 9s 13ms/step - loss: 0.5258 - acc: 0.8129 - val_loss: 0.2947 - val_acc: 0.8830\n",
      "Epoch 992/1000\n",
      "684/684 [==============================] - 8s 12ms/step - loss: 0.5183 - acc: 0.8289 - val_loss: 0.2848 - val_acc: 0.8860\n",
      "Epoch 993/1000\n",
      "684/684 [==============================] - 10s 14ms/step - loss: 0.5474 - acc: 0.8202 - val_loss: 0.2794 - val_acc: 0.9064loss: \n",
      "Epoch 994/1000\n",
      "684/684 [==============================] - 9s 13ms/step - loss: 0.4598 - acc: 0.8289 - val_loss: 0.2818 - val_acc: 0.9064\n",
      "Epoch 995/1000\n",
      "684/684 [==============================] - 9s 13ms/step - loss: 0.5360 - acc: 0.8289 - val_loss: 0.2796 - val_acc: 0.9064\n",
      "Epoch 996/1000\n",
      "684/684 [==============================] - 9s 13ms/step - loss: 0.5015 - acc: 0.8275 - val_loss: 0.2790 - val_acc: 0.9006\n",
      "Epoch 997/1000\n",
      "684/684 [==============================] - 8s 12ms/step - loss: 0.4761 - acc: 0.8377 - val_loss: 0.2843 - val_acc: 0.8977\n",
      "Epoch 998/1000\n",
      "684/684 [==============================] - 9s 13ms/step - loss: 0.5786 - acc: 0.7968 - val_loss: 0.2911 - val_acc: 0.8889\n",
      "Epoch 999/1000\n",
      "684/684 [==============================] - 8s 12ms/step - loss: 0.5363 - acc: 0.8202 - val_loss: 0.2847 - val_acc: 0.8977\n",
      "Epoch 1000/1000\n",
      "684/684 [==============================] - 9s 12ms/step - loss: 0.5380 - acc: 0.8202 - val_loss: 0.2841 - val_acc: 0.9006\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train_shuffle, Y_train_shuffle,validation_data=(x_test, Y_test), epochs=1000, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "342/342 [==============================] - 0s 831us/step\n",
      "Test score: 0.284073118316\n",
      "Test accuracy: 0.900584795322\n"
     ]
    }
   ],
   "source": [
    "score, acc = model.evaluate(x_test, Y_test)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# list all data in history\n",
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nq/wL3SrmZgwCfjwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c9aa819828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c9aa82ed30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
