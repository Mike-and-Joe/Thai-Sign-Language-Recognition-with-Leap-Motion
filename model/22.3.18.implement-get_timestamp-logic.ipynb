{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import GRU, Dense, Dropout, Input, concatenate\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import Adam\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# variable\n",
    "words = [\n",
    "    'come quickly', 'emergency', 'father', 'fever', 'good luck',\n",
    "    'headache', 'hello', 'help', 'hi', 'hungry',\n",
    "    'like', 'mother', 'mother_father', 'mother_mother', 'not ok',\n",
    "    'quickly', 'sorry', 'tomorrow', 'yogurt'\n",
    "]\n",
    "data_per_word = 27\n",
    "data_length = 2 * data_per_word * len(words)\n",
    "timesteps = 50\n",
    "dimensions = 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_feature(frame):\n",
    "    finger_name = ['thumb', 'index', 'middle', 'ring', 'pinky']\n",
    "#     coordinate = ['x', 'y', 'z']\n",
    "    fingertip_pos = np.zeros([2, 5, 3]) # [cooridinates x fingers]\n",
    "    feature = np.zeros([22])\n",
    "    hand_pos = np.zeros([12])\n",
    "#     finger_tip = {}\n",
    "    if 'right' in frame['hands']:\n",
    "        hand_pos[0:6] = np.array([frame['hands']['right']['hand_palm_position'][0],\n",
    "                                  frame['hands']['right']['hand_palm_position'][1],\n",
    "                                  frame['hands']['right']['hand_palm_position'][2],\n",
    "                                  frame['hands']['right']['yaw'], \n",
    "                                  frame['hands']['right']['roll'], \n",
    "                                  frame['hands']['right']['pitch']])\n",
    "        for idx, finger in enumerate(finger_name):\n",
    "#             fingertip_pos[2 + idx, :] = np.array(frame['hands']['right']['fingers'][finger]['bones']['distal']['next_joint'])\n",
    "            fingertip_pos[0, idx, :] = np.array(frame['hands']['right']['fingers'][finger]['bones']['distal']['next_joint'])\n",
    "    if 'left' in frame['hands']:\n",
    "        hand_pos[6:12] = np.array([frame['hands']['left']['hand_palm_position'][0],\n",
    "                                   frame['hands']['left']['hand_palm_position'][1],\n",
    "                                   frame['hands']['left']['hand_palm_position'][2],\n",
    "                                   frame['hands']['left']['yaw'], \n",
    "                                   frame['hands']['left']['roll'], \n",
    "                                   frame['hands']['left']['pitch']])\n",
    "#         fingertip_pos[8, :] = np.array(frame['hands']['left']['hand_palm_position'])\n",
    "        for idx, finger in enumerate(finger_name):\n",
    "#             fingertip_pos[4 + 5 + idx, :] = np.array(frame['hands']['left']['fingers'][finger]['bones']['distal']['next_joint'])\n",
    "            fingertip_pos[1, idx, :] = np.array(frame['hands']['left']['fingers'][finger]['bones']['distal']['next_joint'])\n",
    "    fingertip_pos_shift = np.roll(fingertip_pos, 1, axis=1)\n",
    "    feature[0:10] = np.linalg.norm(fingertip_pos - fingertip_pos_shift, axis=2).reshape(10)\n",
    "    feature[10:22] = hand_pos\n",
    "\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_timestep_from_data(json_data, pick_frame_every_no):\n",
    "    timestep = np.zeros([0, dimensions])\n",
    "    curr_idx = 0\n",
    "    \n",
    "    for frame_no, frame in enumerate(json_data):\n",
    "        if frame_no % pick_frame_every_no != 0 or not frame['hands']: #check if frame[hands] is null\n",
    "            continue\n",
    "        feature = get_feature(frame)\n",
    "#             for idx, fingertip_pos in enumerate(fingertips_pos):\n",
    "        timestep = np.vstack((timestep, feature))\n",
    "        curr_idx += 1\n",
    "        \n",
    "    return timestep\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_timesteps(json_data, pick_frame_every_no): \n",
    "    timesteps = np.zeros([0, dimensions])\n",
    "    for frame_no, frame in enumerate(json_data):\n",
    "        if frame_no % pick_frame_every_no != 0 or not frame['hands']:\n",
    "            continue\n",
    "        feature = get_feature(frame)\n",
    "        timesteps = np.vstack((timesteps, feature))\n",
    "    return timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_fake_speedup_timesteps_1(percent, json_data, pick_frame_every_no):\n",
    "    return get_timesteps(json_data, pick_frame_every_no*(100 - percent)//100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_fake_speedup_timesteps_2(percent, old_timesteps, old_pick_frame_every_no):\n",
    "    timesteps = np.zeros([0, dimensions])\n",
    "    pick_frame_every_number = old_pick_frame_every_no*(percent - 100)//100\n",
    "    timesteps_length = old_timesteps.shape[0] // pick_frame_every_no\n",
    "    \n",
    "    for new_index in range(timesteps_length):\n",
    "        start_old_index = (new_index * _pick_frame_every_number) // old_pick_frame_every_no\n",
    "        x1 = pick_frame_every_number*start_old_index\n",
    "        x2 = pick_frame_every_number*(start_old_index + 1)\n",
    "        h1, h2 = old_timesteps[start_old_index : start_old_index + 2]\n",
    "        _x = (new_index * pick_frame_every_number)\n",
    "        \n",
    "        feature = ((_x-x1)/(x2-x1))*(h2-h1) + h1\n",
    "        \n",
    "        timesteps = np.vstack((timesteps, feature))\n",
    "        \n",
    "    return timesteps\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_frame = 0\n",
    "for word_no, word in enumerate(words):\n",
    "    for data_no in range(data_per_word):\n",
    "        try:\n",
    "            with open(\"./record/{}/json_{}.txt\".format(word, data_no)) as json_data:\n",
    "                json_data = json.load(json_data)\n",
    "        except Exception as s:\n",
    "            print ('error log:', s)\n",
    "        \n",
    "        if max_frame < len(json_data):\n",
    "            max_frame = len(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pick_frame_every_no = max_frame // 50 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.zeros([0, timesteps, dimensions])\n",
    "y = np.zeros([0])\n",
    "for word_no, word in enumerate(words):\n",
    "    for data_no in range(data_per_word):\n",
    "        try:\n",
    "            with open(\"./record/{}/json_{}.txt\".format(word, data_no)) as json_data:\n",
    "                json_data = json.load(json_data)\n",
    "        except Exception as s:\n",
    "            print ('error log:', s)\n",
    "        \n",
    "        _timesteps = get_timesteps(json_data, pick_frame_every_no)\n",
    "        __timesteps = np.vstack((_timesteps, np.zeros([timesteps - _timesteps.shape[0], dimensions])))\n",
    "        x = np.vstack((x, [__timesteps]))\n",
    "        y = np.append(y, word_no)\n",
    "        \n",
    "        \n",
    "        _timesteps = get_fake_speedup_timesteps_1(+10, json_data, pick_frame_every_no)\n",
    "        __timesteps = np.vstack((_timesteps, np.zeros([timesteps - _timesteps.shape[0], dimensions])))\n",
    "        x = np.vstack((x, [__timesteps]))\n",
    "        y = np.append(y, word_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 16.,  16.,  16.,  16.,  16.,  16.,  16.,  16.,  16.,  16.,  16.,\n",
       "        16.,  16.,  16.,  16.,  16.,  16.,  16.,  17.,  17.,  17.,  17.,\n",
       "        17.,  17.,  17.,  17.,  17.,  17.,  17.,  17.,  17.,  17.,  17.,\n",
       "        17.,  17.,  17.,  17.,  17.,  17.,  17.,  17.,  17.,  17.,  17.,\n",
       "        17.,  17.,  17.,  17.,  17.,  17.,  17.,  17.,  17.,  17.,  17.,\n",
       "        17.,  17.,  17.,  17.,  17.,  17.,  17.,  17.,  17.,  17.,  17.,\n",
       "        17.,  17.,  17.,  17.,  17.,  17.,  18.,  18.,  18.,  18.,  18.,\n",
       "        18.,  18.,  18.,  18.,  18.,  18.,  18.,  18.,  18.,  18.,  18.,\n",
       "        18.,  18.,  18.,  18.,  18.,  18.,  18.,  18.,  18.,  18.,  18.,\n",
       "        18.,  18.,  18.,  18.,  18.,  18.,  18.,  18.,  18.,  18.,  18.,\n",
       "        18.,  18.,  18.,  18.,  18.,  18.,  18.,  18.,  18.,  18.,  18.,\n",
       "        18.,  18.,  18.,  18.,  18.])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_std = x.std(axis=(0,1), keepdims=True)\n",
    "x_mean = x.mean(axis=(0,1), keepdims=True)\n",
    "x_norm = (x-x_mean)/x_std\n",
    "# x_norm = (x-x_min)/(x_max-x_min)\n",
    "# x_norm = 2*(x-(x_max+x_min)/2)/(x_max-x_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = np.zeros([data_length * 2 // 3, timesteps, dimensions])\n",
    "y_train = np.zeros([data_length * 2 // 3])\n",
    "x_test = np.zeros([data_length // 3, timesteps, dimensions])\n",
    "y_test = np.zeros([data_length // 3])\n",
    "for idx in range(data_length):\n",
    "    if idx % 3 == 2:\n",
    "        x_test[idx // 3] = x_norm[idx]\n",
    "        y_test[idx // 3] = y[idx]\n",
    "    else:\n",
    "        x_train[idx - idx // 3] = x_norm[idx]\n",
    "        y_train[idx - idx // 3] = y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shuffle_train = np.arange(len(x_train))\n",
    "np.random.shuffle(shuffle_train)\n",
    "x_train_shuffle = np.zeros([data_length * 2 // 3, timesteps, dimensions])\n",
    "y_train_shuffle = np.zeros([data_length * 2 // 3])\n",
    "for idx, item in enumerate(shuffle_train):\n",
    "    x_train_shuffle[idx] = x_train[item]\n",
    "    y_train_shuffle[idx] = y_train[item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# encoding label\n",
    "Y_train_shuffle = np_utils.to_categorical(y_train_shuffle, len(words))\n",
    "Y_test = np_utils.to_categorical(y_test, len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fingers = Input(shape=(timesteps, dimensions), name='fingers')\n",
    "fingers_layers = GRU(64, activation='tanh', recurrent_activation='hard_sigmoid', dropout=0.2, recurrent_dropout=0.2)(fingers)\n",
    "fingers_layers = Dense(64, activation='relu')(fingers_layers)\n",
    "fingers_layers = Dropout(0.2)(fingers_layers)\n",
    "fingers_layers = Dense(64, activation='relu')(fingers_layers)\n",
    "fingers_layers = Dropout(0.2)(fingers_layers)\n",
    "fingers_layers = Dense(64, activation='relu')(fingers_layers)\n",
    "fingers_layers = Dropout(0.2)(fingers_layers)\n",
    "output_layer = Dense(len(words), activation='softmax')(fingers_layers)\n",
    "model = Model(inputs=fingers, outputs=output_layer)\n",
    "adam = Adam(lr=0.01, decay=0.0005)\n",
    "model.compile(optimizer=adam,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 684 samples, validate on 342 samples\n",
      "Epoch 1/1000\n",
      "684/684 [==============================] - 4s 6ms/step - loss: 2.9724 - acc: 0.0468 - val_loss: 2.9447 - val_acc: 0.0468\n",
      "Epoch 2/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.9649 - acc: 0.0512 - val_loss: 2.9464 - val_acc: 0.0643\n",
      "Epoch 3/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.9713 - acc: 0.0643 - val_loss: 2.9370 - val_acc: 0.0702\n",
      "Epoch 4/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.9605 - acc: 0.0526 - val_loss: 2.9449 - val_acc: 0.0526\n",
      "Epoch 5/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.9647 - acc: 0.0599 - val_loss: 2.9418 - val_acc: 0.0760\n",
      "Epoch 6/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.9583 - acc: 0.0585 - val_loss: 2.8518 - val_acc: 0.0994\n",
      "Epoch 7/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.8980 - acc: 0.0702 - val_loss: 2.7660 - val_acc: 0.0906\n",
      "Epoch 8/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.8444 - acc: 0.0848 - val_loss: 2.7268 - val_acc: 0.1316\n",
      "Epoch 9/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.7883 - acc: 0.0921 - val_loss: 2.7299 - val_acc: 0.1316\n",
      "Epoch 10/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.7664 - acc: 0.0994 - val_loss: 2.6732 - val_acc: 0.1404\n",
      "Epoch 11/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.7091 - acc: 0.1067 - val_loss: 2.5045 - val_acc: 0.1345\n",
      "Epoch 12/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.6615 - acc: 0.1316 - val_loss: 2.4812 - val_acc: 0.1667\n",
      "Epoch 13/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.6288 - acc: 0.1140 - val_loss: 2.4770 - val_acc: 0.1491\n",
      "Epoch 14/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 2.6545 - acc: 0.1096 - val_loss: 2.4894 - val_acc: 0.1111\n",
      "Epoch 15/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 2.6774 - acc: 0.1009 - val_loss: 2.4497 - val_acc: 0.1404\n",
      "Epoch 16/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 2.6031 - acc: 0.1199 - val_loss: 2.4353 - val_acc: 0.1550\n",
      "Epoch 17/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.5981 - acc: 0.1126 - val_loss: 2.4586 - val_acc: 0.1520\n",
      "Epoch 18/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.6107 - acc: 0.1213 - val_loss: 2.4446 - val_acc: 0.1374\n",
      "Epoch 19/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.5700 - acc: 0.1228 - val_loss: 2.4992 - val_acc: 0.1199\n",
      "Epoch 20/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.6200 - acc: 0.1023 - val_loss: 2.3873 - val_acc: 0.1433\n",
      "Epoch 21/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.5691 - acc: 0.1082 - val_loss: 2.3869 - val_acc: 0.1520\n",
      "Epoch 22/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.5050 - acc: 0.1535 - val_loss: 2.3932 - val_acc: 0.1754\n",
      "Epoch 23/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.5672 - acc: 0.1199 - val_loss: 2.3849 - val_acc: 0.1871\n",
      "Epoch 24/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.5313 - acc: 0.1462 - val_loss: 2.4101 - val_acc: 0.1608\n",
      "Epoch 25/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.4883 - acc: 0.1213 - val_loss: 2.3584 - val_acc: 0.1930\n",
      "Epoch 26/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.4627 - acc: 0.1477 - val_loss: 2.2869 - val_acc: 0.1901\n",
      "Epoch 27/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.4635 - acc: 0.1564 - val_loss: 2.2922 - val_acc: 0.1667\n",
      "Epoch 28/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.4362 - acc: 0.1520 - val_loss: 2.2452 - val_acc: 0.1813\n",
      "Epoch 29/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.4451 - acc: 0.1608 - val_loss: 2.2159 - val_acc: 0.1959\n",
      "Epoch 30/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.3952 - acc: 0.1652 - val_loss: 2.2043 - val_acc: 0.2164\n",
      "Epoch 31/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.3893 - acc: 0.1564 - val_loss: 2.2518 - val_acc: 0.1930\n",
      "Epoch 32/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.4257 - acc: 0.1711 - val_loss: 2.2489 - val_acc: 0.1930\n",
      "Epoch 33/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.4242 - acc: 0.1594 - val_loss: 2.1687 - val_acc: 0.1901\n",
      "Epoch 34/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.4135 - acc: 0.1564 - val_loss: 2.1936 - val_acc: 0.2018\n",
      "Epoch 35/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.4402 - acc: 0.1506 - val_loss: 2.1788 - val_acc: 0.1901\n",
      "Epoch 36/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.3552 - acc: 0.1637 - val_loss: 2.1428 - val_acc: 0.2105\n",
      "Epoch 37/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.3311 - acc: 0.1711 - val_loss: 2.1555 - val_acc: 0.2193\n",
      "Epoch 38/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.2888 - acc: 0.1652 - val_loss: 2.1697 - val_acc: 0.1901\n",
      "Epoch 39/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.3123 - acc: 0.1842 - val_loss: 2.1201 - val_acc: 0.1901\n",
      "Epoch 40/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.3389 - acc: 0.1652 - val_loss: 2.1838 - val_acc: 0.2281\n",
      "Epoch 41/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 2.3588 - acc: 0.1871 - val_loss: 2.2005 - val_acc: 0.1930\n",
      "Epoch 42/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.4052 - acc: 0.1535 - val_loss: 2.2055 - val_acc: 0.2135\n",
      "Epoch 43/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.3181 - acc: 0.1696 - val_loss: 2.1586 - val_acc: 0.1813\n",
      "Epoch 44/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.2466 - acc: 0.2018 - val_loss: 2.1611 - val_acc: 0.2193\n",
      "Epoch 45/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.3642 - acc: 0.1535 - val_loss: 2.1036 - val_acc: 0.2018\n",
      "Epoch 46/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.2969 - acc: 0.1652 - val_loss: 2.0661 - val_acc: 0.2105\n",
      "Epoch 47/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.2892 - acc: 0.1754 - val_loss: 2.1136 - val_acc: 0.2193\n",
      "Epoch 48/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.2396 - acc: 0.1944 - val_loss: 2.0914 - val_acc: 0.2164\n",
      "Epoch 49/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.2772 - acc: 0.1769 - val_loss: 2.0709 - val_acc: 0.2281\n",
      "Epoch 50/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.2266 - acc: 0.1711 - val_loss: 2.0164 - val_acc: 0.2310\n",
      "Epoch 51/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.2518 - acc: 0.1784 - val_loss: 2.0305 - val_acc: 0.2456\n",
      "Epoch 52/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.2527 - acc: 0.1901 - val_loss: 2.0191 - val_acc: 0.3041\n",
      "Epoch 53/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.2427 - acc: 0.1930 - val_loss: 2.0182 - val_acc: 0.2281\n",
      "Epoch 54/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.2170 - acc: 0.1988 - val_loss: 1.9734 - val_acc: 0.2836\n",
      "Epoch 55/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.2220 - acc: 0.1930 - val_loss: 1.9967 - val_acc: 0.2515\n",
      "Epoch 56/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.2331 - acc: 0.1974 - val_loss: 1.9907 - val_acc: 0.2807\n",
      "Epoch 57/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.1930 - acc: 0.2076 - val_loss: 1.9711 - val_acc: 0.2895\n",
      "Epoch 58/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.2362 - acc: 0.1857 - val_loss: 1.9805 - val_acc: 0.2515\n",
      "Epoch 59/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.2407 - acc: 0.1769 - val_loss: 1.9736 - val_acc: 0.2836\n",
      "Epoch 60/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.1823 - acc: 0.2178 - val_loss: 1.9381 - val_acc: 0.3070\n",
      "Epoch 61/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.2069 - acc: 0.2003 - val_loss: 1.9545 - val_acc: 0.2602\n",
      "Epoch 62/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.1512 - acc: 0.2398 - val_loss: 1.9173 - val_acc: 0.3099\n",
      "Epoch 63/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.1145 - acc: 0.2237 - val_loss: 1.8958 - val_acc: 0.3158\n",
      "Epoch 64/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.1562 - acc: 0.2398 - val_loss: 1.9019 - val_acc: 0.3450\n",
      "Epoch 65/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.1348 - acc: 0.2047 - val_loss: 1.8601 - val_acc: 0.2895\n",
      "Epoch 66/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.0992 - acc: 0.2193 - val_loss: 1.8342 - val_acc: 0.3187\n",
      "Epoch 67/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.0711 - acc: 0.2529 - val_loss: 1.7690 - val_acc: 0.3129\n",
      "Epoch 68/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.0454 - acc: 0.2310 - val_loss: 1.8086 - val_acc: 0.3363\n",
      "Epoch 69/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.0778 - acc: 0.2456 - val_loss: 1.7888 - val_acc: 0.3567\n",
      "Epoch 70/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.1148 - acc: 0.2558 - val_loss: 1.8288 - val_acc: 0.3333\n",
      "Epoch 71/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.0791 - acc: 0.2719 - val_loss: 1.7967 - val_acc: 0.3947\n",
      "Epoch 72/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.1131 - acc: 0.2763 - val_loss: 1.7748 - val_acc: 0.3977\n",
      "Epoch 73/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.0540 - acc: 0.2588 - val_loss: 1.7592 - val_acc: 0.3918\n",
      "Epoch 74/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.0443 - acc: 0.2661 - val_loss: 1.7075 - val_acc: 0.3977\n",
      "Epoch 75/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.0752 - acc: 0.2515 - val_loss: 1.6681 - val_acc: 0.3918\n",
      "Epoch 76/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.0324 - acc: 0.2807 - val_loss: 1.6623 - val_acc: 0.4561\n",
      "Epoch 77/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.9888 - acc: 0.2778 - val_loss: 1.6439 - val_acc: 0.4123\n",
      "Epoch 78/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.9550 - acc: 0.2895 - val_loss: 1.6354 - val_acc: 0.3830\n",
      "Epoch 79/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 2.0106 - acc: 0.2836 - val_loss: 1.6096 - val_acc: 0.4386\n",
      "Epoch 80/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 2.0076 - acc: 0.2778 - val_loss: 1.6442 - val_acc: 0.3801\n",
      "Epoch 81/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.9663 - acc: 0.2997 - val_loss: 1.6615 - val_acc: 0.4152\n",
      "Epoch 82/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.9758 - acc: 0.2822 - val_loss: 1.6385 - val_acc: 0.4298\n",
      "Epoch 83/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.9769 - acc: 0.2909 - val_loss: 1.5871 - val_acc: 0.4269\n",
      "Epoch 84/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.9526 - acc: 0.3056 - val_loss: 1.6275 - val_acc: 0.4123\n",
      "Epoch 85/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.9367 - acc: 0.3026 - val_loss: 1.5802 - val_acc: 0.4298\n",
      "Epoch 86/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8829 - acc: 0.3231 - val_loss: 1.5792 - val_acc: 0.4269\n",
      "Epoch 87/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.9867 - acc: 0.3012 - val_loss: 1.5984 - val_acc: 0.4503\n",
      "Epoch 88/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8999 - acc: 0.3114 - val_loss: 1.5782 - val_acc: 0.4269\n",
      "Epoch 89/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8890 - acc: 0.3012 - val_loss: 1.5719 - val_acc: 0.4532\n",
      "Epoch 90/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.9859 - acc: 0.2939 - val_loss: 1.5617 - val_acc: 0.4444\n",
      "Epoch 91/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.9404 - acc: 0.3143 - val_loss: 1.5562 - val_acc: 0.4678\n",
      "Epoch 92/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8552 - acc: 0.3348 - val_loss: 1.5548 - val_acc: 0.4211\n",
      "Epoch 93/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 1.8588 - acc: 0.3392 - val_loss: 1.5225 - val_acc: 0.4561\n",
      "Epoch 94/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.8188 - acc: 0.3202 - val_loss: 1.5076 - val_acc: 0.4591\n",
      "Epoch 95/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.9264 - acc: 0.3143 - val_loss: 1.5272 - val_acc: 0.4444\n",
      "Epoch 96/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8722 - acc: 0.3582 - val_loss: 1.5163 - val_acc: 0.4532\n",
      "Epoch 97/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.9011 - acc: 0.3129 - val_loss: 1.5089 - val_acc: 0.4327\n",
      "Epoch 98/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8280 - acc: 0.3363 - val_loss: 1.5086 - val_acc: 0.4357\n",
      "Epoch 99/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8885 - acc: 0.3143 - val_loss: 1.4868 - val_acc: 0.4474\n",
      "Epoch 100/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7928 - acc: 0.3494 - val_loss: 1.4399 - val_acc: 0.4444\n",
      "Epoch 101/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8949 - acc: 0.3158 - val_loss: 1.4605 - val_acc: 0.4532\n",
      "Epoch 102/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8554 - acc: 0.3333 - val_loss: 1.4642 - val_acc: 0.4415\n",
      "Epoch 103/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7835 - acc: 0.3260 - val_loss: 1.4759 - val_acc: 0.4766\n",
      "Epoch 104/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8278 - acc: 0.3421 - val_loss: 1.4514 - val_acc: 0.4708\n",
      "Epoch 105/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8428 - acc: 0.3421 - val_loss: 1.4973 - val_acc: 0.4444\n",
      "Epoch 106/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8940 - acc: 0.3187 - val_loss: 1.4754 - val_acc: 0.4532\n",
      "Epoch 107/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8575 - acc: 0.3436 - val_loss: 1.4769 - val_acc: 0.4444\n",
      "Epoch 108/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8321 - acc: 0.3173 - val_loss: 1.4882 - val_acc: 0.4620\n",
      "Epoch 109/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8102 - acc: 0.3173 - val_loss: 1.4578 - val_acc: 0.4415\n",
      "Epoch 110/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8325 - acc: 0.3363 - val_loss: 1.4557 - val_acc: 0.4386\n",
      "Epoch 111/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7828 - acc: 0.3450 - val_loss: 1.4396 - val_acc: 0.4795\n",
      "Epoch 112/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7965 - acc: 0.3363 - val_loss: 1.4182 - val_acc: 0.4795\n",
      "Epoch 113/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7155 - acc: 0.3728 - val_loss: 1.4011 - val_acc: 0.4474\n",
      "Epoch 114/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8369 - acc: 0.3392 - val_loss: 1.4232 - val_acc: 0.4444\n",
      "Epoch 115/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7479 - acc: 0.3465 - val_loss: 1.4030 - val_acc: 0.4444\n",
      "Epoch 116/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7723 - acc: 0.3582 - val_loss: 1.3814 - val_acc: 0.5029\n",
      "Epoch 117/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7439 - acc: 0.3626 - val_loss: 1.4094 - val_acc: 0.4737\n",
      "Epoch 118/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7466 - acc: 0.3626 - val_loss: 1.4377 - val_acc: 0.4620\n",
      "Epoch 119/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7885 - acc: 0.3596 - val_loss: 1.4058 - val_acc: 0.4532\n",
      "Epoch 120/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7861 - acc: 0.3728 - val_loss: 1.3745 - val_acc: 0.5029\n",
      "Epoch 121/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7483 - acc: 0.3787 - val_loss: 1.3835 - val_acc: 0.4912\n",
      "Epoch 122/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.8248 - acc: 0.3421 - val_loss: 1.4089 - val_acc: 0.4766\n",
      "Epoch 123/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7808 - acc: 0.3567 - val_loss: 1.3906 - val_acc: 0.4795\n",
      "Epoch 124/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7617 - acc: 0.3582 - val_loss: 1.3908 - val_acc: 0.4649\n",
      "Epoch 125/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7094 - acc: 0.3816 - val_loss: 1.3686 - val_acc: 0.5058\n",
      "Epoch 126/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6942 - acc: 0.3816 - val_loss: 1.3679 - val_acc: 0.5058\n",
      "Epoch 127/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7241 - acc: 0.3860 - val_loss: 1.3546 - val_acc: 0.4942\n",
      "Epoch 128/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6497 - acc: 0.4020 - val_loss: 1.3381 - val_acc: 0.4795\n",
      "Epoch 129/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6645 - acc: 0.3933 - val_loss: 1.3370 - val_acc: 0.4825\n",
      "Epoch 130/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6766 - acc: 0.3757 - val_loss: 1.3082 - val_acc: 0.5292\n",
      "Epoch 131/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6233 - acc: 0.4108 - val_loss: 1.2990 - val_acc: 0.5351\n",
      "Epoch 132/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6325 - acc: 0.4137 - val_loss: 1.3137 - val_acc: 0.5234\n",
      "Epoch 133/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6697 - acc: 0.3640 - val_loss: 1.3075 - val_acc: 0.5000\n",
      "Epoch 134/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7052 - acc: 0.3772 - val_loss: 1.3226 - val_acc: 0.5000\n",
      "Epoch 135/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6475 - acc: 0.3713 - val_loss: 1.3232 - val_acc: 0.4971\n",
      "Epoch 136/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.7173 - acc: 0.3363 - val_loss: 1.3146 - val_acc: 0.5234\n",
      "Epoch 137/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6978 - acc: 0.4020 - val_loss: 1.3234 - val_acc: 0.5029\n",
      "Epoch 138/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.7643 - acc: 0.3611 - val_loss: 1.3451 - val_acc: 0.5088\n",
      "Epoch 139/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6194 - acc: 0.3845 - val_loss: 1.2778 - val_acc: 0.5175\n",
      "Epoch 140/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6502 - acc: 0.3918 - val_loss: 1.2945 - val_acc: 0.4971\n",
      "Epoch 141/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6709 - acc: 0.4167 - val_loss: 1.3093 - val_acc: 0.5088\n",
      "Epoch 142/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6670 - acc: 0.3962 - val_loss: 1.2693 - val_acc: 0.5234\n",
      "Epoch 143/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6110 - acc: 0.4079 - val_loss: 1.2963 - val_acc: 0.5058\n",
      "Epoch 144/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6251 - acc: 0.3962 - val_loss: 1.2364 - val_acc: 0.5526\n",
      "Epoch 145/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6248 - acc: 0.4108 - val_loss: 1.2586 - val_acc: 0.5117\n",
      "Epoch 146/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6162 - acc: 0.4225 - val_loss: 1.2648 - val_acc: 0.5117\n",
      "Epoch 147/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6606 - acc: 0.4167 - val_loss: 1.2692 - val_acc: 0.5409\n",
      "Epoch 148/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6299 - acc: 0.4240 - val_loss: 1.2593 - val_acc: 0.5585\n",
      "Epoch 149/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.5373 - acc: 0.4181 - val_loss: 1.2391 - val_acc: 0.5205\n",
      "Epoch 150/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6423 - acc: 0.4079 - val_loss: 1.2810 - val_acc: 0.5351\n",
      "Epoch 151/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.5845 - acc: 0.4108 - val_loss: 1.2627 - val_acc: 0.5234\n",
      "Epoch 152/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.5886 - acc: 0.4342 - val_loss: 1.2524 - val_acc: 0.5234\n",
      "Epoch 153/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.5598 - acc: 0.4020 - val_loss: 1.2344 - val_acc: 0.5351\n",
      "Epoch 154/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.6814 - acc: 0.3904 - val_loss: 1.2300 - val_acc: 0.5439\n",
      "Epoch 155/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.5931 - acc: 0.4269 - val_loss: 1.2070 - val_acc: 0.5497\n",
      "Epoch 156/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.5283 - acc: 0.4298 - val_loss: 1.2242 - val_acc: 0.5409\n",
      "Epoch 157/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.5822 - acc: 0.4064 - val_loss: 1.2247 - val_acc: 0.5731\n",
      "Epoch 158/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.5415 - acc: 0.4357 - val_loss: 1.2046 - val_acc: 0.5468\n",
      "Epoch 159/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.5709 - acc: 0.4079 - val_loss: 1.1888 - val_acc: 0.5702\n",
      "Epoch 160/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.5918 - acc: 0.4152 - val_loss: 1.1983 - val_acc: 0.5585\n",
      "Epoch 161/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6052 - acc: 0.4298 - val_loss: 1.2024 - val_acc: 0.5409\n",
      "Epoch 162/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.5361 - acc: 0.4547 - val_loss: 1.1934 - val_acc: 0.5643\n",
      "Epoch 163/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.5541 - acc: 0.4444 - val_loss: 1.1521 - val_acc: 0.5789\n",
      "Epoch 164/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.6291 - acc: 0.4167 - val_loss: 1.1667 - val_acc: 0.5848\n",
      "Epoch 165/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.5968 - acc: 0.4167 - val_loss: 1.2020 - val_acc: 0.5848\n",
      "Epoch 166/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.5394 - acc: 0.4240 - val_loss: 1.1761 - val_acc: 0.5789\n",
      "Epoch 167/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.5821 - acc: 0.4123 - val_loss: 1.1941 - val_acc: 0.5702\n",
      "Epoch 168/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.5249 - acc: 0.4605 - val_loss: 1.1586 - val_acc: 0.5702\n",
      "Epoch 169/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.4669 - acc: 0.4547 - val_loss: 1.1356 - val_acc: 0.5994\n",
      "Epoch 170/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.5330 - acc: 0.4547 - val_loss: 1.1457 - val_acc: 0.5906\n",
      "Epoch 171/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.5877 - acc: 0.4620 - val_loss: 1.1622 - val_acc: 0.6053\n",
      "Epoch 172/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.5261 - acc: 0.4401 - val_loss: 1.1577 - val_acc: 0.5877\n",
      "Epoch 173/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.5146 - acc: 0.4474 - val_loss: 1.1617 - val_acc: 0.5994\n",
      "Epoch 174/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.5456 - acc: 0.4591 - val_loss: 1.1888 - val_acc: 0.5585\n",
      "Epoch 175/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.5983 - acc: 0.4459 - val_loss: 1.1597 - val_acc: 0.5848\n",
      "Epoch 176/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.5130 - acc: 0.4430 - val_loss: 1.1381 - val_acc: 0.5819\n",
      "Epoch 177/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.5837 - acc: 0.4518 - val_loss: 1.1644 - val_acc: 0.5731\n",
      "Epoch 178/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.5636 - acc: 0.4620 - val_loss: 1.1132 - val_acc: 0.5702\n",
      "Epoch 179/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.5094 - acc: 0.4430 - val_loss: 1.1126 - val_acc: 0.5760\n",
      "Epoch 180/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.5237 - acc: 0.4401 - val_loss: 1.1164 - val_acc: 0.5906\n",
      "Epoch 181/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.5012 - acc: 0.4781 - val_loss: 1.0929 - val_acc: 0.5848\n",
      "Epoch 182/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.4548 - acc: 0.4751 - val_loss: 1.0941 - val_acc: 0.5877\n",
      "Epoch 183/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.4810 - acc: 0.4678 - val_loss: 1.0730 - val_acc: 0.6053\n",
      "Epoch 184/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.4494 - acc: 0.4605 - val_loss: 1.0767 - val_acc: 0.5906\n",
      "Epoch 185/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.4957 - acc: 0.4678 - val_loss: 1.0970 - val_acc: 0.6082\n",
      "Epoch 186/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.4783 - acc: 0.4795 - val_loss: 1.0882 - val_acc: 0.5819\n",
      "Epoch 187/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.4625 - acc: 0.4766 - val_loss: 1.0901 - val_acc: 0.5848\n",
      "Epoch 188/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.4428 - acc: 0.5073 - val_loss: 1.1006 - val_acc: 0.6082\n",
      "Epoch 189/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.4588 - acc: 0.4664 - val_loss: 1.1013 - val_acc: 0.6023\n",
      "Epoch 190/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.4607 - acc: 0.4444 - val_loss: 1.1037 - val_acc: 0.6023\n",
      "Epoch 191/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.4530 - acc: 0.4766 - val_loss: 1.0820 - val_acc: 0.5877\n",
      "Epoch 192/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.4379 - acc: 0.4810 - val_loss: 1.0862 - val_acc: 0.5877\n",
      "Epoch 193/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.3986 - acc: 0.4854 - val_loss: 1.0631 - val_acc: 0.6111\n",
      "Epoch 194/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.4042 - acc: 0.4985 - val_loss: 1.0867 - val_acc: 0.5848\n",
      "Epoch 195/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.4352 - acc: 0.4795 - val_loss: 1.0530 - val_acc: 0.6111\n",
      "Epoch 196/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.4523 - acc: 0.4664 - val_loss: 1.0443 - val_acc: 0.6374\n",
      "Epoch 197/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.4857 - acc: 0.4708 - val_loss: 1.0741 - val_acc: 0.6082\n",
      "Epoch 198/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.4426 - acc: 0.4810 - val_loss: 1.0636 - val_acc: 0.5848\n",
      "Epoch 199/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.4538 - acc: 0.4854 - val_loss: 1.0470 - val_acc: 0.6140\n",
      "Epoch 200/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.4188 - acc: 0.4854 - val_loss: 1.0814 - val_acc: 0.5936\n",
      "Epoch 201/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.4470 - acc: 0.5015 - val_loss: 1.0578 - val_acc: 0.6023\n",
      "Epoch 202/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.4727 - acc: 0.4649 - val_loss: 1.0566 - val_acc: 0.6053\n",
      "Epoch 203/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.4689 - acc: 0.4576 - val_loss: 1.0500 - val_acc: 0.6082\n",
      "Epoch 204/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.4227 - acc: 0.4971 - val_loss: 1.0560 - val_acc: 0.5994\n",
      "Epoch 205/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.3724 - acc: 0.4912 - val_loss: 1.0591 - val_acc: 0.6199\n",
      "Epoch 206/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.4240 - acc: 0.4825 - val_loss: 1.0459 - val_acc: 0.6111\n",
      "Epoch 207/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.3369 - acc: 0.5015 - val_loss: 1.0348 - val_acc: 0.6228\n",
      "Epoch 208/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.4177 - acc: 0.5029 - val_loss: 1.0445 - val_acc: 0.6111\n",
      "Epoch 209/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.3704 - acc: 0.4956 - val_loss: 1.0229 - val_acc: 0.6228\n",
      "Epoch 210/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.4360 - acc: 0.4942 - val_loss: 1.0369 - val_acc: 0.6228\n",
      "Epoch 211/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.4943 - acc: 0.4751 - val_loss: 1.0298 - val_acc: 0.6257\n",
      "Epoch 212/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.3919 - acc: 0.4898 - val_loss: 1.0135 - val_acc: 0.6199\n",
      "Epoch 213/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.4228 - acc: 0.4883 - val_loss: 0.9971 - val_acc: 0.6520\n",
      "Epoch 214/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.3574 - acc: 0.5073 - val_loss: 0.9951 - val_acc: 0.6374\n",
      "Epoch 215/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.3180 - acc: 0.5117 - val_loss: 1.0100 - val_acc: 0.6316\n",
      "Epoch 216/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.4526 - acc: 0.4781 - val_loss: 1.0106 - val_acc: 0.6111\n",
      "Epoch 217/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.3546 - acc: 0.4883 - val_loss: 1.0458 - val_acc: 0.6374\n",
      "Epoch 218/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.4599 - acc: 0.4605 - val_loss: 1.0399 - val_acc: 0.6111\n",
      "Epoch 219/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.3691 - acc: 0.5102 - val_loss: 1.0298 - val_acc: 0.6170\n",
      "Epoch 220/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.3226 - acc: 0.5044 - val_loss: 1.0209 - val_acc: 0.6287\n",
      "Epoch 221/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.4071 - acc: 0.5088 - val_loss: 1.0133 - val_acc: 0.6228\n",
      "Epoch 222/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.4027 - acc: 0.4927 - val_loss: 1.0139 - val_acc: 0.6257\n",
      "Epoch 223/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.4216 - acc: 0.4693 - val_loss: 0.9899 - val_acc: 0.6579\n",
      "Epoch 224/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.3965 - acc: 0.4810 - val_loss: 0.9951 - val_acc: 0.6374\n",
      "Epoch 225/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.3314 - acc: 0.5190 - val_loss: 0.9989 - val_acc: 0.6316\n",
      "Epoch 226/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.3901 - acc: 0.4927 - val_loss: 0.9847 - val_acc: 0.6404\n",
      "Epoch 227/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.3924 - acc: 0.4985 - val_loss: 0.9929 - val_acc: 0.6257\n",
      "Epoch 228/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 1.3719 - acc: 0.4825 - val_loss: 0.9783 - val_acc: 0.6345\n",
      "Epoch 229/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.3391 - acc: 0.5088 - val_loss: 1.0149 - val_acc: 0.6140\n",
      "Epoch 230/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.3178 - acc: 0.5365 - val_loss: 0.9596 - val_acc: 0.6784\n",
      "Epoch 231/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.3799 - acc: 0.5000 - val_loss: 0.9942 - val_acc: 0.6316\n",
      "Epoch 232/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.3800 - acc: 0.5205 - val_loss: 0.9701 - val_acc: 0.6491\n",
      "Epoch 233/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.3124 - acc: 0.5161 - val_loss: 0.9596 - val_acc: 0.6667\n",
      "Epoch 234/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.3273 - acc: 0.5102 - val_loss: 0.9814 - val_acc: 0.6170\n",
      "Epoch 235/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.3750 - acc: 0.5132 - val_loss: 0.9781 - val_acc: 0.6345\n",
      "Epoch 236/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 1.3403 - acc: 0.5219 - val_loss: 0.9617 - val_acc: 0.6374\n",
      "Epoch 237/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.4007 - acc: 0.5000 - val_loss: 0.9868 - val_acc: 0.6579\n",
      "Epoch 238/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.3734 - acc: 0.4854 - val_loss: 0.9890 - val_acc: 0.6462\n",
      "Epoch 239/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.3147 - acc: 0.5292 - val_loss: 0.9652 - val_acc: 0.6520\n",
      "Epoch 240/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.2853 - acc: 0.5132 - val_loss: 0.9676 - val_acc: 0.6462\n",
      "Epoch 241/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 2s 3ms/step - loss: 1.3171 - acc: 0.5263 - val_loss: 0.9717 - val_acc: 0.6228\n",
      "Epoch 242/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.3605 - acc: 0.5307 - val_loss: 0.9418 - val_acc: 0.6550\n",
      "Epoch 243/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.3144 - acc: 0.5249 - val_loss: 0.9602 - val_acc: 0.6579\n",
      "Epoch 244/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.3937 - acc: 0.4898 - val_loss: 0.9324 - val_acc: 0.6637\n",
      "Epoch 245/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.3365 - acc: 0.5307 - val_loss: 0.9289 - val_acc: 0.6696\n",
      "Epoch 246/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.2844 - acc: 0.5205 - val_loss: 0.9375 - val_acc: 0.6667\n",
      "Epoch 247/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.3663 - acc: 0.5234 - val_loss: 0.9543 - val_acc: 0.6842\n",
      "Epoch 248/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.3345 - acc: 0.5292 - val_loss: 0.9295 - val_acc: 0.6754\n",
      "Epoch 249/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.3926 - acc: 0.5044 - val_loss: 0.9557 - val_acc: 0.6433\n",
      "Epoch 250/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.3169 - acc: 0.5146 - val_loss: 0.9345 - val_acc: 0.6520\n",
      "Epoch 251/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.2930 - acc: 0.5512 - val_loss: 0.9367 - val_acc: 0.6667\n",
      "Epoch 252/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.3785 - acc: 0.5117 - val_loss: 0.9256 - val_acc: 0.6784\n",
      "Epoch 253/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.3474 - acc: 0.5146 - val_loss: 0.9051 - val_acc: 0.6813\n",
      "Epoch 254/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.2742 - acc: 0.5249 - val_loss: 0.9156 - val_acc: 0.6754\n",
      "Epoch 255/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.3517 - acc: 0.4956 - val_loss: 0.9261 - val_acc: 0.6404\n",
      "Epoch 256/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.3273 - acc: 0.5058 - val_loss: 0.9091 - val_acc: 0.6550\n",
      "Epoch 257/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.3254 - acc: 0.5219 - val_loss: 0.9275 - val_acc: 0.6520\n",
      "Epoch 258/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.3328 - acc: 0.5132 - val_loss: 0.9199 - val_acc: 0.6725\n",
      "Epoch 259/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.2992 - acc: 0.5351 - val_loss: 0.9058 - val_acc: 0.6901\n",
      "Epoch 260/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.2913 - acc: 0.5409 - val_loss: 0.9059 - val_acc: 0.6520\n",
      "Epoch 261/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.3854 - acc: 0.4912 - val_loss: 0.8966 - val_acc: 0.6491\n",
      "Epoch 262/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.3245 - acc: 0.5380 - val_loss: 0.9293 - val_acc: 0.6462\n",
      "Epoch 263/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.2997 - acc: 0.5175 - val_loss: 0.9168 - val_acc: 0.6520\n",
      "Epoch 264/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.3209 - acc: 0.5380 - val_loss: 0.9057 - val_acc: 0.6930\n",
      "Epoch 265/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.2477 - acc: 0.5424 - val_loss: 0.8991 - val_acc: 0.6784\n",
      "Epoch 266/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.3204 - acc: 0.5175 - val_loss: 0.8992 - val_acc: 0.6959\n",
      "Epoch 267/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.2387 - acc: 0.5424 - val_loss: 0.9173 - val_acc: 0.6725\n",
      "Epoch 268/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.2681 - acc: 0.5263 - val_loss: 0.8846 - val_acc: 0.6608\n",
      "Epoch 269/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.3200 - acc: 0.5234 - val_loss: 0.8909 - val_acc: 0.6901\n",
      "Epoch 270/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.2820 - acc: 0.5278 - val_loss: 0.8878 - val_acc: 0.6784\n",
      "Epoch 271/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.2480 - acc: 0.5673 - val_loss: 0.8868 - val_acc: 0.6784\n",
      "Epoch 272/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.2500 - acc: 0.5468 - val_loss: 0.8858 - val_acc: 0.7164\n",
      "Epoch 273/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.2318 - acc: 0.5468 - val_loss: 0.8903 - val_acc: 0.6754\n",
      "Epoch 274/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.2620 - acc: 0.5541 - val_loss: 0.8577 - val_acc: 0.6988\n",
      "Epoch 275/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.2885 - acc: 0.5380 - val_loss: 0.8613 - val_acc: 0.7018\n",
      "Epoch 276/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.2601 - acc: 0.5263 - val_loss: 0.8783 - val_acc: 0.6842\n",
      "Epoch 277/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.2637 - acc: 0.5409 - val_loss: 0.9024 - val_acc: 0.6637\n",
      "Epoch 278/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.2945 - acc: 0.5219 - val_loss: 0.9040 - val_acc: 0.6550\n",
      "Epoch 279/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.4062 - acc: 0.5000 - val_loss: 0.9163 - val_acc: 0.6754\n",
      "Epoch 280/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1816 - acc: 0.5585 - val_loss: 0.8773 - val_acc: 0.7164\n",
      "Epoch 281/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.3512 - acc: 0.5029 - val_loss: 0.8735 - val_acc: 0.6696\n",
      "Epoch 282/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.2770 - acc: 0.5322 - val_loss: 0.8561 - val_acc: 0.6842\n",
      "Epoch 283/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.3013 - acc: 0.5336 - val_loss: 0.8648 - val_acc: 0.6637\n",
      "Epoch 284/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.2842 - acc: 0.5263 - val_loss: 0.8695 - val_acc: 0.6813\n",
      "Epoch 285/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.2158 - acc: 0.5424 - val_loss: 0.8511 - val_acc: 0.7018\n",
      "Epoch 286/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.2404 - acc: 0.5556 - val_loss: 0.8692 - val_acc: 0.6901\n",
      "Epoch 287/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.2795 - acc: 0.5468 - val_loss: 0.8424 - val_acc: 0.6930\n",
      "Epoch 288/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.2088 - acc: 0.5570 - val_loss: 0.8534 - val_acc: 0.6784\n",
      "Epoch 289/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.2282 - acc: 0.5292 - val_loss: 0.8424 - val_acc: 0.6959\n",
      "Epoch 290/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.2652 - acc: 0.5190 - val_loss: 0.8416 - val_acc: 0.6930\n",
      "Epoch 291/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.2736 - acc: 0.5599 - val_loss: 0.8477 - val_acc: 0.7105\n",
      "Epoch 292/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.2096 - acc: 0.5643 - val_loss: 0.8398 - val_acc: 0.7076\n",
      "Epoch 293/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.2845 - acc: 0.5307 - val_loss: 0.8623 - val_acc: 0.6813\n",
      "Epoch 294/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1807 - acc: 0.5614 - val_loss: 0.8439 - val_acc: 0.7047\n",
      "Epoch 295/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.2429 - acc: 0.5512 - val_loss: 0.8514 - val_acc: 0.7135\n",
      "Epoch 296/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.2305 - acc: 0.5658 - val_loss: 0.8579 - val_acc: 0.7193\n",
      "Epoch 297/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.2266 - acc: 0.5570 - val_loss: 0.8575 - val_acc: 0.6930\n",
      "Epoch 298/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1744 - acc: 0.5775 - val_loss: 0.8489 - val_acc: 0.6959\n",
      "Epoch 299/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.2971 - acc: 0.5190 - val_loss: 0.8466 - val_acc: 0.7456\n",
      "Epoch 300/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 1.2428 - acc: 0.5599 - val_loss: 0.8297 - val_acc: 0.7135\n",
      "Epoch 301/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.2374 - acc: 0.5322 - val_loss: 0.8418 - val_acc: 0.7076\n",
      "Epoch 302/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.2105 - acc: 0.5673 - val_loss: 0.8680 - val_acc: 0.6988\n",
      "Epoch 303/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1793 - acc: 0.5819 - val_loss: 0.8335 - val_acc: 0.7222\n",
      "Epoch 304/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.2171 - acc: 0.5541 - val_loss: 0.8369 - val_acc: 0.7076\n",
      "Epoch 305/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.2050 - acc: 0.5585 - val_loss: 0.8398 - val_acc: 0.7222\n",
      "Epoch 306/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.2248 - acc: 0.5599 - val_loss: 0.8317 - val_acc: 0.7135\n",
      "Epoch 307/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1918 - acc: 0.5643 - val_loss: 0.8200 - val_acc: 0.7164\n",
      "Epoch 308/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.2464 - acc: 0.5570 - val_loss: 0.8244 - val_acc: 0.7047\n",
      "Epoch 309/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1989 - acc: 0.5643 - val_loss: 0.8131 - val_acc: 0.7135\n",
      "Epoch 310/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.2544 - acc: 0.5482 - val_loss: 0.8180 - val_acc: 0.7281\n",
      "Epoch 311/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.2279 - acc: 0.5702 - val_loss: 0.8193 - val_acc: 0.6930\n",
      "Epoch 312/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1310 - acc: 0.6023 - val_loss: 0.8098 - val_acc: 0.6959\n",
      "Epoch 313/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1745 - acc: 0.5775 - val_loss: 0.8090 - val_acc: 0.7105\n",
      "Epoch 314/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.2070 - acc: 0.5804 - val_loss: 0.7857 - val_acc: 0.7164\n",
      "Epoch 315/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.2147 - acc: 0.5424 - val_loss: 0.8236 - val_acc: 0.7135\n",
      "Epoch 316/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1829 - acc: 0.5526 - val_loss: 0.8167 - val_acc: 0.7105\n",
      "Epoch 317/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.2226 - acc: 0.5585 - val_loss: 0.8068 - val_acc: 0.7076\n",
      "Epoch 318/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.2466 - acc: 0.5482 - val_loss: 0.8306 - val_acc: 0.7076\n",
      "Epoch 319/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.2502 - acc: 0.5570 - val_loss: 0.8242 - val_acc: 0.7164\n",
      "Epoch 320/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.2389 - acc: 0.5526 - val_loss: 0.8129 - val_acc: 0.7368\n",
      "Epoch 321/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1900 - acc: 0.5673 - val_loss: 0.8016 - val_acc: 0.7368\n",
      "Epoch 322/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.2072 - acc: 0.5512 - val_loss: 0.8172 - val_acc: 0.7193\n",
      "Epoch 323/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.2058 - acc: 0.5629 - val_loss: 0.8092 - val_acc: 0.7135\n",
      "Epoch 324/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1967 - acc: 0.5833 - val_loss: 0.8279 - val_acc: 0.7047\n",
      "Epoch 325/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.2437 - acc: 0.5526 - val_loss: 0.7931 - val_acc: 0.6959\n",
      "Epoch 326/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1833 - acc: 0.5746 - val_loss: 0.7797 - val_acc: 0.7193\n",
      "Epoch 327/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1882 - acc: 0.5863 - val_loss: 0.8112 - val_acc: 0.7018\n",
      "Epoch 328/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.2426 - acc: 0.5556 - val_loss: 0.7924 - val_acc: 0.7251\n",
      "Epoch 329/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1914 - acc: 0.5526 - val_loss: 0.7766 - val_acc: 0.7339\n",
      "Epoch 330/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1253 - acc: 0.5950 - val_loss: 0.7846 - val_acc: 0.7164\n",
      "Epoch 331/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.2092 - acc: 0.5892 - val_loss: 0.7974 - val_acc: 0.7485\n",
      "Epoch 332/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1196 - acc: 0.5760 - val_loss: 0.7669 - val_acc: 0.7456\n",
      "Epoch 333/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1722 - acc: 0.5906 - val_loss: 0.7548 - val_acc: 0.7281\n",
      "Epoch 334/1000\n",
      "684/684 [==============================] - ETA: 0s - loss: 1.1744 - acc: 0.561 - 2s 3ms/step - loss: 1.1796 - acc: 0.5599 - val_loss: 0.7947 - val_acc: 0.7310\n",
      "Epoch 335/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1531 - acc: 0.5789 - val_loss: 0.7713 - val_acc: 0.7222\n",
      "Epoch 336/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1684 - acc: 0.5585 - val_loss: 0.7877 - val_acc: 0.7193\n",
      "Epoch 337/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1733 - acc: 0.5819 - val_loss: 0.7635 - val_acc: 0.7398\n",
      "Epoch 338/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1133 - acc: 0.5950 - val_loss: 0.7591 - val_acc: 0.7398\n",
      "Epoch 339/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1747 - acc: 0.5643 - val_loss: 0.7608 - val_acc: 0.7573\n",
      "Epoch 340/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1676 - acc: 0.5819 - val_loss: 0.7563 - val_acc: 0.7339\n",
      "Epoch 341/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1661 - acc: 0.5599 - val_loss: 0.7574 - val_acc: 0.7368\n",
      "Epoch 342/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1456 - acc: 0.5804 - val_loss: 0.7634 - val_acc: 0.7339\n",
      "Epoch 343/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.2284 - acc: 0.5614 - val_loss: 0.7605 - val_acc: 0.7368\n",
      "Epoch 344/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1711 - acc: 0.5585 - val_loss: 0.7477 - val_acc: 0.7427\n",
      "Epoch 345/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1218 - acc: 0.6009 - val_loss: 0.7301 - val_acc: 0.7515\n",
      "Epoch 346/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1171 - acc: 0.5716 - val_loss: 0.7323 - val_acc: 0.7544\n",
      "Epoch 347/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1103 - acc: 0.5936 - val_loss: 0.7521 - val_acc: 0.7018\n",
      "Epoch 348/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1429 - acc: 0.5599 - val_loss: 0.7575 - val_acc: 0.7310\n",
      "Epoch 349/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1801 - acc: 0.5848 - val_loss: 0.7364 - val_acc: 0.7456\n",
      "Epoch 350/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1628 - acc: 0.5731 - val_loss: 0.7405 - val_acc: 0.7456\n",
      "Epoch 351/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1685 - acc: 0.5804 - val_loss: 0.7347 - val_acc: 0.7456\n",
      "Epoch 352/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1418 - acc: 0.5804 - val_loss: 0.7455 - val_acc: 0.7485\n",
      "Epoch 353/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1416 - acc: 0.5906 - val_loss: 0.7514 - val_acc: 0.7398\n",
      "Epoch 354/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1517 - acc: 0.5980 - val_loss: 0.7578 - val_acc: 0.7544\n",
      "Epoch 355/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1749 - acc: 0.5833 - val_loss: 0.7480 - val_acc: 0.7398\n",
      "Epoch 356/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1261 - acc: 0.6228 - val_loss: 0.7567 - val_acc: 0.7310\n",
      "Epoch 357/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 1.1273 - acc: 0.6067 - val_loss: 0.7571 - val_acc: 0.7339\n",
      "Epoch 358/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1368 - acc: 0.5746 - val_loss: 0.7521 - val_acc: 0.7339\n",
      "Epoch 359/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1171 - acc: 0.5950 - val_loss: 0.7734 - val_acc: 0.7339\n",
      "Epoch 360/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1655 - acc: 0.5585 - val_loss: 0.7453 - val_acc: 0.7515\n",
      "Epoch 361/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1194 - acc: 0.5950 - val_loss: 0.7627 - val_acc: 0.7339\n",
      "Epoch 362/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1519 - acc: 0.5789 - val_loss: 0.7631 - val_acc: 0.7368\n",
      "Epoch 363/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 1.1118 - acc: 0.6170 - val_loss: 0.7271 - val_acc: 0.7573\n",
      "Epoch 364/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.0809 - acc: 0.6038 - val_loss: 0.7396 - val_acc: 0.7515\n",
      "Epoch 365/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1332 - acc: 0.5702 - val_loss: 0.7216 - val_acc: 0.7602\n",
      "Epoch 366/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1377 - acc: 0.5980 - val_loss: 0.7468 - val_acc: 0.7398\n",
      "Epoch 367/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1481 - acc: 0.5980 - val_loss: 0.7436 - val_acc: 0.7485\n",
      "Epoch 368/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1850 - acc: 0.5541 - val_loss: 0.7548 - val_acc: 0.7310\n",
      "Epoch 369/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1457 - acc: 0.5863 - val_loss: 0.7214 - val_acc: 0.7573\n",
      "Epoch 370/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1985 - acc: 0.5804 - val_loss: 0.7478 - val_acc: 0.7398\n",
      "Epoch 371/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1688 - acc: 0.5921 - val_loss: 0.7518 - val_acc: 0.7427\n",
      "Epoch 372/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.0782 - acc: 0.5936 - val_loss: 0.7341 - val_acc: 0.7339\n",
      "Epoch 373/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.0301 - acc: 0.6184 - val_loss: 0.7266 - val_acc: 0.7485\n",
      "Epoch 374/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.0843 - acc: 0.6111 - val_loss: 0.7342 - val_acc: 0.7427\n",
      "Epoch 375/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1393 - acc: 0.5877 - val_loss: 0.7344 - val_acc: 0.7398\n",
      "Epoch 376/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1384 - acc: 0.5936 - val_loss: 0.7324 - val_acc: 0.7485\n",
      "Epoch 377/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.0930 - acc: 0.6213 - val_loss: 0.7358 - val_acc: 0.7602\n",
      "Epoch 378/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1516 - acc: 0.5848 - val_loss: 0.7329 - val_acc: 0.7485\n",
      "Epoch 379/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1667 - acc: 0.5994 - val_loss: 0.7071 - val_acc: 0.7602\n",
      "Epoch 380/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1047 - acc: 0.6140 - val_loss: 0.7264 - val_acc: 0.7602\n",
      "Epoch 381/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1027 - acc: 0.5965 - val_loss: 0.7444 - val_acc: 0.7544\n",
      "Epoch 382/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1691 - acc: 0.5789 - val_loss: 0.7362 - val_acc: 0.7427\n",
      "Epoch 383/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1174 - acc: 0.6140 - val_loss: 0.7238 - val_acc: 0.7515\n",
      "Epoch 384/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1208 - acc: 0.5936 - val_loss: 0.7084 - val_acc: 0.7515\n",
      "Epoch 385/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.0624 - acc: 0.6228 - val_loss: 0.7085 - val_acc: 0.7602\n",
      "Epoch 386/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1868 - acc: 0.5687 - val_loss: 0.7206 - val_acc: 0.7544\n",
      "Epoch 387/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1062 - acc: 0.5994 - val_loss: 0.7290 - val_acc: 0.7485\n",
      "Epoch 388/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1312 - acc: 0.6009 - val_loss: 0.7057 - val_acc: 0.7427\n",
      "Epoch 389/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1025 - acc: 0.6126 - val_loss: 0.7069 - val_acc: 0.7602\n",
      "Epoch 390/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.0809 - acc: 0.6140 - val_loss: 0.7238 - val_acc: 0.7485\n",
      "Epoch 391/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.0866 - acc: 0.6009 - val_loss: 0.7250 - val_acc: 0.7515\n",
      "Epoch 392/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1471 - acc: 0.5994 - val_loss: 0.7140 - val_acc: 0.7544\n",
      "Epoch 393/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.0927 - acc: 0.6184 - val_loss: 0.7053 - val_acc: 0.7456\n",
      "Epoch 394/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1802 - acc: 0.5760 - val_loss: 0.7140 - val_acc: 0.7573\n",
      "Epoch 395/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.0766 - acc: 0.6330 - val_loss: 0.7067 - val_acc: 0.7719\n",
      "Epoch 396/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1361 - acc: 0.6199 - val_loss: 0.7265 - val_acc: 0.7544\n",
      "Epoch 397/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1224 - acc: 0.5921 - val_loss: 0.6990 - val_acc: 0.7544\n",
      "Epoch 398/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.0416 - acc: 0.6345 - val_loss: 0.7161 - val_acc: 0.7573\n",
      "Epoch 399/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1143 - acc: 0.6067 - val_loss: 0.6890 - val_acc: 0.7602\n",
      "Epoch 400/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 1.1311 - acc: 0.6228 - val_loss: 0.6954 - val_acc: 0.7544\n",
      "Epoch 401/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.0900 - acc: 0.6213 - val_loss: 0.7039 - val_acc: 0.7573\n",
      "Epoch 402/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.0877 - acc: 0.6053 - val_loss: 0.7034 - val_acc: 0.7661\n",
      "Epoch 403/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9835 - acc: 0.6374 - val_loss: 0.6842 - val_acc: 0.7632\n",
      "Epoch 404/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.0904 - acc: 0.6199 - val_loss: 0.6729 - val_acc: 0.7661\n",
      "Epoch 405/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.0625 - acc: 0.6082 - val_loss: 0.6833 - val_acc: 0.7778\n",
      "Epoch 406/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.0825 - acc: 0.5994 - val_loss: 0.6886 - val_acc: 0.7778\n",
      "Epoch 407/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1031 - acc: 0.6228 - val_loss: 0.7036 - val_acc: 0.7807\n",
      "Epoch 408/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.0357 - acc: 0.6374 - val_loss: 0.6791 - val_acc: 0.7719\n",
      "Epoch 409/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.0566 - acc: 0.6228 - val_loss: 0.6876 - val_acc: 0.7690\n",
      "Epoch 410/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.0421 - acc: 0.6228 - val_loss: 0.6918 - val_acc: 0.7690\n",
      "Epoch 411/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.0418 - acc: 0.6330 - val_loss: 0.6763 - val_acc: 0.7749\n",
      "Epoch 412/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9992 - acc: 0.6564 - val_loss: 0.6603 - val_acc: 0.7807\n",
      "Epoch 413/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.0688 - acc: 0.6170 - val_loss: 0.6660 - val_acc: 0.7807\n",
      "Epoch 414/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1321 - acc: 0.6023 - val_loss: 0.6620 - val_acc: 0.7778\n",
      "Epoch 415/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.0953 - acc: 0.6287 - val_loss: 0.6877 - val_acc: 0.7661\n",
      "Epoch 416/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1258 - acc: 0.6009 - val_loss: 0.6710 - val_acc: 0.7778\n",
      "Epoch 417/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1004 - acc: 0.5921 - val_loss: 0.6757 - val_acc: 0.7573\n",
      "Epoch 418/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1165 - acc: 0.6053 - val_loss: 0.6792 - val_acc: 0.7661\n",
      "Epoch 419/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1224 - acc: 0.5965 - val_loss: 0.6939 - val_acc: 0.7573\n",
      "Epoch 420/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.0842 - acc: 0.6140 - val_loss: 0.6857 - val_acc: 0.7749\n",
      "Epoch 421/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.0440 - acc: 0.6170 - val_loss: 0.6647 - val_acc: 0.7749\n",
      "Epoch 422/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.0875 - acc: 0.6053 - val_loss: 0.6754 - val_acc: 0.7778\n",
      "Epoch 423/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1453 - acc: 0.6287 - val_loss: 0.6770 - val_acc: 0.7602\n",
      "Epoch 424/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1365 - acc: 0.6126 - val_loss: 0.7042 - val_acc: 0.7632\n",
      "Epoch 425/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1498 - acc: 0.5980 - val_loss: 0.6883 - val_acc: 0.7778\n",
      "Epoch 426/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1468 - acc: 0.6140 - val_loss: 0.6994 - val_acc: 0.7632\n",
      "Epoch 427/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.0560 - acc: 0.6418 - val_loss: 0.6920 - val_acc: 0.7719\n",
      "Epoch 428/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.0649 - acc: 0.6272 - val_loss: 0.6735 - val_acc: 0.7690\n",
      "Epoch 429/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.0870 - acc: 0.6272 - val_loss: 0.6856 - val_acc: 0.7719\n",
      "Epoch 430/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.0268 - acc: 0.6374 - val_loss: 0.6770 - val_acc: 0.7836\n",
      "Epoch 431/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.0080 - acc: 0.6360 - val_loss: 0.6750 - val_acc: 0.7865\n",
      "Epoch 432/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9899 - acc: 0.6652 - val_loss: 0.6504 - val_acc: 0.7836\n",
      "Epoch 433/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.0586 - acc: 0.6111 - val_loss: 0.6633 - val_acc: 0.7807\n",
      "Epoch 434/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1056 - acc: 0.6257 - val_loss: 0.6580 - val_acc: 0.7719\n",
      "Epoch 435/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.0537 - acc: 0.6447 - val_loss: 0.6561 - val_acc: 0.7749\n",
      "Epoch 436/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.0714 - acc: 0.6272 - val_loss: 0.6500 - val_acc: 0.7865\n",
      "Epoch 437/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1022 - acc: 0.5906 - val_loss: 0.6496 - val_acc: 0.7865\n",
      "Epoch 438/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.0601 - acc: 0.6330 - val_loss: 0.6577 - val_acc: 0.7719\n",
      "Epoch 439/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.0636 - acc: 0.6272 - val_loss: 0.6498 - val_acc: 0.7719\n",
      "Epoch 440/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.0332 - acc: 0.6257 - val_loss: 0.6416 - val_acc: 0.7836\n",
      "Epoch 441/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9977 - acc: 0.6228 - val_loss: 0.6435 - val_acc: 0.7836\n",
      "Epoch 442/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.0253 - acc: 0.6345 - val_loss: 0.6353 - val_acc: 0.7895\n",
      "Epoch 443/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.0211 - acc: 0.6243 - val_loss: 0.6478 - val_acc: 0.7719\n",
      "Epoch 444/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.0645 - acc: 0.6345 - val_loss: 0.6603 - val_acc: 0.7807\n",
      "Epoch 445/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.0798 - acc: 0.6243 - val_loss: 0.6448 - val_acc: 0.7836\n",
      "Epoch 446/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.0648 - acc: 0.6126 - val_loss: 0.6520 - val_acc: 0.7836\n",
      "Epoch 447/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.0527 - acc: 0.6213 - val_loss: 0.6573 - val_acc: 0.7749\n",
      "Epoch 448/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1066 - acc: 0.5980 - val_loss: 0.6551 - val_acc: 0.7690\n",
      "Epoch 449/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.0576 - acc: 0.6199 - val_loss: 0.6587 - val_acc: 0.7632\n",
      "Epoch 450/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.0397 - acc: 0.6330 - val_loss: 0.6624 - val_acc: 0.7632\n",
      "Epoch 451/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9794 - acc: 0.6389 - val_loss: 0.6398 - val_acc: 0.7690\n",
      "Epoch 452/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0740 - acc: 0.6257 - val_loss: 0.6517 - val_acc: 0.7807\n",
      "Epoch 453/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9987 - acc: 0.6462 - val_loss: 0.6345 - val_acc: 0.7836\n",
      "Epoch 454/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.0760 - acc: 0.6447 - val_loss: 0.6637 - val_acc: 0.7836\n",
      "Epoch 455/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.0395 - acc: 0.6374 - val_loss: 0.6434 - val_acc: 0.7836\n",
      "Epoch 456/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.0479 - acc: 0.6447 - val_loss: 0.6383 - val_acc: 0.7807\n",
      "Epoch 457/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.9872 - acc: 0.6564 - val_loss: 0.6349 - val_acc: 0.7807\n",
      "Epoch 458/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9823 - acc: 0.6433 - val_loss: 0.6433 - val_acc: 0.7836\n",
      "Epoch 459/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9562 - acc: 0.6520 - val_loss: 0.6335 - val_acc: 0.7836\n",
      "Epoch 460/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.0140 - acc: 0.6491 - val_loss: 0.6409 - val_acc: 0.7778\n",
      "Epoch 461/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9603 - acc: 0.6462 - val_loss: 0.6374 - val_acc: 0.7953\n",
      "Epoch 462/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.1526 - acc: 0.6257 - val_loss: 0.6380 - val_acc: 0.8012\n",
      "Epoch 463/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.0305 - acc: 0.6433 - val_loss: 0.6504 - val_acc: 0.7778\n",
      "Epoch 464/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.0996 - acc: 0.6243 - val_loss: 0.6292 - val_acc: 0.7778\n",
      "Epoch 465/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9819 - acc: 0.6579 - val_loss: 0.6333 - val_acc: 0.7778\n",
      "Epoch 466/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.0368 - acc: 0.6404 - val_loss: 0.6285 - val_acc: 0.7865\n",
      "Epoch 467/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9390 - acc: 0.6754 - val_loss: 0.6243 - val_acc: 0.7865\n",
      "Epoch 468/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.0047 - acc: 0.6520 - val_loss: 0.6319 - val_acc: 0.7778\n",
      "Epoch 469/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.0877 - acc: 0.6257 - val_loss: 0.6413 - val_acc: 0.7807\n",
      "Epoch 470/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.0374 - acc: 0.6287 - val_loss: 0.6471 - val_acc: 0.7719\n",
      "Epoch 471/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.0438 - acc: 0.6491 - val_loss: 0.6346 - val_acc: 0.7778\n",
      "Epoch 472/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9891 - acc: 0.6447 - val_loss: 0.6421 - val_acc: 0.7719\n",
      "Epoch 473/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.0444 - acc: 0.6447 - val_loss: 0.6478 - val_acc: 0.7807\n",
      "Epoch 474/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9928 - acc: 0.6652 - val_loss: 0.6389 - val_acc: 0.7865\n",
      "Epoch 475/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.0124 - acc: 0.6550 - val_loss: 0.6506 - val_acc: 0.7807\n",
      "Epoch 476/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.0524 - acc: 0.6184 - val_loss: 0.6355 - val_acc: 0.7895\n",
      "Epoch 477/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.0051 - acc: 0.6608 - val_loss: 0.6228 - val_acc: 0.7953\n",
      "Epoch 478/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9453 - acc: 0.6404 - val_loss: 0.6346 - val_acc: 0.7865\n",
      "Epoch 479/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9710 - acc: 0.6389 - val_loss: 0.6269 - val_acc: 0.7924\n",
      "Epoch 480/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9739 - acc: 0.6564 - val_loss: 0.6218 - val_acc: 0.7865\n",
      "Epoch 481/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9960 - acc: 0.6360 - val_loss: 0.6249 - val_acc: 0.7865\n",
      "Epoch 482/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.0006 - acc: 0.6447 - val_loss: 0.6167 - val_acc: 0.7836\n",
      "Epoch 483/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9900 - acc: 0.6213 - val_loss: 0.6017 - val_acc: 0.7895\n",
      "Epoch 484/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9474 - acc: 0.6579 - val_loss: 0.6211 - val_acc: 0.7807\n",
      "Epoch 485/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.0529 - acc: 0.6360 - val_loss: 0.6274 - val_acc: 0.7749\n",
      "Epoch 486/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.0352 - acc: 0.6301 - val_loss: 0.5940 - val_acc: 0.7953\n",
      "Epoch 487/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9750 - acc: 0.6520 - val_loss: 0.5993 - val_acc: 0.7865\n",
      "Epoch 488/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9477 - acc: 0.6594 - val_loss: 0.6026 - val_acc: 0.7895\n",
      "Epoch 489/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9956 - acc: 0.6579 - val_loss: 0.6021 - val_acc: 0.7924\n",
      "Epoch 490/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.0119 - acc: 0.6594 - val_loss: 0.6216 - val_acc: 0.7836\n",
      "Epoch 491/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9574 - acc: 0.6608 - val_loss: 0.6113 - val_acc: 0.7865\n",
      "Epoch 492/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9318 - acc: 0.6550 - val_loss: 0.6023 - val_acc: 0.7953\n",
      "Epoch 493/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9926 - acc: 0.6287 - val_loss: 0.6035 - val_acc: 0.7895\n",
      "Epoch 494/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.9644 - acc: 0.6491 - val_loss: 0.6134 - val_acc: 0.7836\n",
      "Epoch 495/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.9557 - acc: 0.6652 - val_loss: 0.6237 - val_acc: 0.7778\n",
      "Epoch 496/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0018 - acc: 0.6711 - val_loss: 0.5975 - val_acc: 0.7895\n",
      "Epoch 497/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.9581 - acc: 0.6623 - val_loss: 0.5891 - val_acc: 0.7836\n",
      "Epoch 498/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.0282 - acc: 0.6623 - val_loss: 0.5863 - val_acc: 0.7953\n",
      "Epoch 499/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9605 - acc: 0.6798 - val_loss: 0.5790 - val_acc: 0.7924\n",
      "Epoch 500/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9518 - acc: 0.6594 - val_loss: 0.5891 - val_acc: 0.7924\n",
      "Epoch 501/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9828 - acc: 0.6594 - val_loss: 0.5997 - val_acc: 0.7836\n",
      "Epoch 502/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9879 - acc: 0.6477 - val_loss: 0.5892 - val_acc: 0.7836\n",
      "Epoch 503/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9526 - acc: 0.6594 - val_loss: 0.5867 - val_acc: 0.7865\n",
      "Epoch 504/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9615 - acc: 0.6769 - val_loss: 0.5992 - val_acc: 0.7778\n",
      "Epoch 505/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9925 - acc: 0.6550 - val_loss: 0.6043 - val_acc: 0.7836\n",
      "Epoch 506/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9635 - acc: 0.6345 - val_loss: 0.6020 - val_acc: 0.7807\n",
      "Epoch 507/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.0574 - acc: 0.6316 - val_loss: 0.6054 - val_acc: 0.7807\n",
      "Epoch 508/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.9424 - acc: 0.6404 - val_loss: 0.6110 - val_acc: 0.7865\n",
      "Epoch 509/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9946 - acc: 0.6579 - val_loss: 0.5979 - val_acc: 0.7895\n",
      "Epoch 510/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.9681 - acc: 0.6330 - val_loss: 0.6261 - val_acc: 0.7661\n",
      "Epoch 511/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.0022 - acc: 0.6550 - val_loss: 0.5861 - val_acc: 0.7778\n",
      "Epoch 512/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9555 - acc: 0.6681 - val_loss: 0.6062 - val_acc: 0.7895\n",
      "Epoch 513/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9322 - acc: 0.6813 - val_loss: 0.6133 - val_acc: 0.7778\n",
      "Epoch 514/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9641 - acc: 0.6623 - val_loss: 0.6037 - val_acc: 0.7865\n",
      "Epoch 515/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.0369 - acc: 0.6637 - val_loss: 0.5968 - val_acc: 0.7924\n",
      "Epoch 516/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.0364 - acc: 0.6345 - val_loss: 0.6109 - val_acc: 0.7924\n",
      "Epoch 517/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9382 - acc: 0.6842 - val_loss: 0.5993 - val_acc: 0.7924\n",
      "Epoch 518/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9554 - acc: 0.6740 - val_loss: 0.5979 - val_acc: 0.7865\n",
      "Epoch 519/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9750 - acc: 0.6652 - val_loss: 0.5875 - val_acc: 0.8012\n",
      "Epoch 520/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9995 - acc: 0.6404 - val_loss: 0.5914 - val_acc: 0.7953\n",
      "Epoch 521/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9686 - acc: 0.6623 - val_loss: 0.5987 - val_acc: 0.7807\n",
      "Epoch 522/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9515 - acc: 0.6462 - val_loss: 0.5915 - val_acc: 0.7953\n",
      "Epoch 523/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9665 - acc: 0.6652 - val_loss: 0.5927 - val_acc: 0.8041\n",
      "Epoch 524/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9817 - acc: 0.6477 - val_loss: 0.5857 - val_acc: 0.7895\n",
      "Epoch 525/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.0026 - acc: 0.6637 - val_loss: 0.5986 - val_acc: 0.7924\n",
      "Epoch 526/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9861 - acc: 0.6550 - val_loss: 0.6140 - val_acc: 0.7865\n",
      "Epoch 527/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9610 - acc: 0.6652 - val_loss: 0.5952 - val_acc: 0.7895\n",
      "Epoch 528/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9318 - acc: 0.6857 - val_loss: 0.6072 - val_acc: 0.7953\n",
      "Epoch 529/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9743 - acc: 0.6550 - val_loss: 0.6010 - val_acc: 0.7924\n",
      "Epoch 530/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9230 - acc: 0.6725 - val_loss: 0.5905 - val_acc: 0.7895\n",
      "Epoch 531/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9114 - acc: 0.6974 - val_loss: 0.6023 - val_acc: 0.8012\n",
      "Epoch 532/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.0389 - acc: 0.6404 - val_loss: 0.5986 - val_acc: 0.7865\n",
      "Epoch 533/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.9803 - acc: 0.6740 - val_loss: 0.5957 - val_acc: 0.7924\n",
      "Epoch 534/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9882 - acc: 0.6696 - val_loss: 0.5903 - val_acc: 0.7953\n",
      "Epoch 535/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 1.0358 - acc: 0.6404 - val_loss: 0.5951 - val_acc: 0.7865\n",
      "Epoch 536/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0048 - acc: 0.6608 - val_loss: 0.6005 - val_acc: 0.7895\n",
      "Epoch 537/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9693 - acc: 0.6623 - val_loss: 0.5896 - val_acc: 0.7924\n",
      "Epoch 538/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9208 - acc: 0.6535 - val_loss: 0.5917 - val_acc: 0.7982\n",
      "Epoch 539/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8885 - acc: 0.6798 - val_loss: 0.5861 - val_acc: 0.7895\n",
      "Epoch 540/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9199 - acc: 0.6813 - val_loss: 0.5754 - val_acc: 0.7982\n",
      "Epoch 541/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 1.0126 - acc: 0.6287 - val_loss: 0.5967 - val_acc: 0.7953\n",
      "Epoch 542/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9845 - acc: 0.6681 - val_loss: 0.5892 - val_acc: 0.8012\n",
      "Epoch 543/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9772 - acc: 0.6520 - val_loss: 0.6037 - val_acc: 0.7895\n",
      "Epoch 544/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9195 - acc: 0.6959 - val_loss: 0.5919 - val_acc: 0.7953\n",
      "Epoch 545/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9087 - acc: 0.6959 - val_loss: 0.5885 - val_acc: 0.7982\n",
      "Epoch 546/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9789 - acc: 0.6579 - val_loss: 0.5934 - val_acc: 0.8041\n",
      "Epoch 547/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.0340 - acc: 0.6330 - val_loss: 0.5997 - val_acc: 0.8041\n",
      "Epoch 548/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.9901 - acc: 0.6360 - val_loss: 0.6044 - val_acc: 0.7982\n",
      "Epoch 549/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9222 - acc: 0.6871 - val_loss: 0.5807 - val_acc: 0.7982\n",
      "Epoch 550/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9652 - acc: 0.6564 - val_loss: 0.5721 - val_acc: 0.8070\n",
      "Epoch 551/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8711 - acc: 0.6784 - val_loss: 0.5615 - val_acc: 0.8041\n",
      "Epoch 552/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.0139 - acc: 0.6389 - val_loss: 0.5826 - val_acc: 0.8012\n",
      "Epoch 553/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9333 - acc: 0.6915 - val_loss: 0.5664 - val_acc: 0.8012\n",
      "Epoch 554/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.0273 - acc: 0.6535 - val_loss: 0.5764 - val_acc: 0.8129\n",
      "Epoch 555/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9719 - acc: 0.6711 - val_loss: 0.5707 - val_acc: 0.8099\n",
      "Epoch 556/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9588 - acc: 0.6798 - val_loss: 0.5745 - val_acc: 0.7982\n",
      "Epoch 557/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9964 - acc: 0.6740 - val_loss: 0.5715 - val_acc: 0.8070\n",
      "Epoch 558/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8788 - acc: 0.6784 - val_loss: 0.5647 - val_acc: 0.8041\n",
      "Epoch 559/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9840 - acc: 0.6462 - val_loss: 0.5656 - val_acc: 0.8012\n",
      "Epoch 560/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9034 - acc: 0.6827 - val_loss: 0.5539 - val_acc: 0.8012\n",
      "Epoch 561/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9522 - acc: 0.6754 - val_loss: 0.5587 - val_acc: 0.7953\n",
      "Epoch 562/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9032 - acc: 0.6842 - val_loss: 0.5646 - val_acc: 0.8070\n",
      "Epoch 563/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.9078 - acc: 0.6930 - val_loss: 0.5449 - val_acc: 0.8041\n",
      "Epoch 564/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8675 - acc: 0.6813 - val_loss: 0.5626 - val_acc: 0.7895\n",
      "Epoch 565/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9298 - acc: 0.6564 - val_loss: 0.5610 - val_acc: 0.7982\n",
      "Epoch 566/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9216 - acc: 0.6827 - val_loss: 0.5704 - val_acc: 0.7924\n",
      "Epoch 567/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9722 - acc: 0.6564 - val_loss: 0.5728 - val_acc: 0.7924\n",
      "Epoch 568/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8948 - acc: 0.6871 - val_loss: 0.5730 - val_acc: 0.8012\n",
      "Epoch 569/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.9242 - acc: 0.6798 - val_loss: 0.5791 - val_acc: 0.7953\n",
      "Epoch 570/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9795 - acc: 0.6447 - val_loss: 0.5588 - val_acc: 0.7982\n",
      "Epoch 571/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8746 - acc: 0.6798 - val_loss: 0.5522 - val_acc: 0.7953\n",
      "Epoch 572/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.0019 - acc: 0.6681 - val_loss: 0.5748 - val_acc: 0.7924\n",
      "Epoch 573/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9101 - acc: 0.6798 - val_loss: 0.5705 - val_acc: 0.7982\n",
      "Epoch 574/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.9131 - acc: 0.6711 - val_loss: 0.5642 - val_acc: 0.7953\n",
      "Epoch 575/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9408 - acc: 0.6681 - val_loss: 0.5523 - val_acc: 0.8070\n",
      "Epoch 576/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.9658 - acc: 0.6550 - val_loss: 0.5699 - val_acc: 0.8012\n",
      "Epoch 577/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9818 - acc: 0.6769 - val_loss: 0.5564 - val_acc: 0.8012\n",
      "Epoch 578/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9178 - acc: 0.6974 - val_loss: 0.5764 - val_acc: 0.7982\n",
      "Epoch 579/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9533 - acc: 0.6754 - val_loss: 0.5623 - val_acc: 0.8012\n",
      "Epoch 580/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9372 - acc: 0.6608 - val_loss: 0.5671 - val_acc: 0.8041\n",
      "Epoch 581/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9539 - acc: 0.6813 - val_loss: 0.5804 - val_acc: 0.8012\n",
      "Epoch 582/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9370 - acc: 0.6769 - val_loss: 0.5505 - val_acc: 0.7924\n",
      "Epoch 583/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9070 - acc: 0.6725 - val_loss: 0.5542 - val_acc: 0.8041\n",
      "Epoch 584/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8759 - acc: 0.6827 - val_loss: 0.5573 - val_acc: 0.8012\n",
      "Epoch 585/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.9305 - acc: 0.6637 - val_loss: 0.5664 - val_acc: 0.7982\n",
      "Epoch 586/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9002 - acc: 0.6871 - val_loss: 0.5644 - val_acc: 0.8129\n",
      "Epoch 587/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9490 - acc: 0.6871 - val_loss: 0.5461 - val_acc: 0.8129\n",
      "Epoch 588/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.9054 - acc: 0.6769 - val_loss: 0.5704 - val_acc: 0.7982\n",
      "Epoch 589/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8805 - acc: 0.6901 - val_loss: 0.5621 - val_acc: 0.7982\n",
      "Epoch 590/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8726 - acc: 0.7003 - val_loss: 0.5636 - val_acc: 0.8012\n",
      "Epoch 591/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9607 - acc: 0.6813 - val_loss: 0.5706 - val_acc: 0.8012\n",
      "Epoch 592/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9518 - acc: 0.6857 - val_loss: 0.5707 - val_acc: 0.8070\n",
      "Epoch 593/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8775 - acc: 0.6944 - val_loss: 0.5660 - val_acc: 0.8070\n",
      "Epoch 594/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9081 - acc: 0.6930 - val_loss: 0.5725 - val_acc: 0.8041\n",
      "Epoch 595/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9180 - acc: 0.6798 - val_loss: 0.5604 - val_acc: 0.8070\n",
      "Epoch 596/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9139 - acc: 0.6813 - val_loss: 0.5667 - val_acc: 0.8012\n",
      "Epoch 597/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 1.0072 - acc: 0.6550 - val_loss: 0.5640 - val_acc: 0.8041\n",
      "Epoch 598/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9228 - acc: 0.6754 - val_loss: 0.5698 - val_acc: 0.8012\n",
      "Epoch 599/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.9329 - acc: 0.6696 - val_loss: 0.5650 - val_acc: 0.8099\n",
      "Epoch 600/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8716 - acc: 0.6886 - val_loss: 0.5486 - val_acc: 0.8246\n",
      "Epoch 601/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9420 - acc: 0.6711 - val_loss: 0.5470 - val_acc: 0.8187\n",
      "Epoch 602/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8724 - acc: 0.6871 - val_loss: 0.5506 - val_acc: 0.8129\n",
      "Epoch 603/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9131 - acc: 0.6842 - val_loss: 0.5462 - val_acc: 0.8041\n",
      "Epoch 604/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9556 - acc: 0.6594 - val_loss: 0.5582 - val_acc: 0.8129\n",
      "Epoch 605/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9114 - acc: 0.6842 - val_loss: 0.5592 - val_acc: 0.8099\n",
      "Epoch 606/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9457 - acc: 0.6667 - val_loss: 0.5598 - val_acc: 0.8187\n",
      "Epoch 607/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8805 - acc: 0.6740 - val_loss: 0.5475 - val_acc: 0.8158\n",
      "Epoch 608/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9280 - acc: 0.6711 - val_loss: 0.5513 - val_acc: 0.8216\n",
      "Epoch 609/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8878 - acc: 0.6754 - val_loss: 0.5402 - val_acc: 0.8099\n",
      "Epoch 610/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9319 - acc: 0.6798 - val_loss: 0.5519 - val_acc: 0.8187\n",
      "Epoch 611/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9525 - acc: 0.6667 - val_loss: 0.5488 - val_acc: 0.8129\n",
      "Epoch 612/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8569 - acc: 0.6827 - val_loss: 0.5585 - val_acc: 0.8099\n",
      "Epoch 613/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8389 - acc: 0.7105 - val_loss: 0.5358 - val_acc: 0.8129\n",
      "Epoch 614/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9525 - acc: 0.6564 - val_loss: 0.5454 - val_acc: 0.8187\n",
      "Epoch 615/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8619 - acc: 0.7076 - val_loss: 0.5473 - val_acc: 0.8070\n",
      "Epoch 616/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8375 - acc: 0.6988 - val_loss: 0.5387 - val_acc: 0.8099\n",
      "Epoch 617/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9040 - acc: 0.6886 - val_loss: 0.5449 - val_acc: 0.8129\n",
      "Epoch 618/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9459 - acc: 0.6667 - val_loss: 0.5470 - val_acc: 0.8129\n",
      "Epoch 619/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8537 - acc: 0.6988 - val_loss: 0.5330 - val_acc: 0.8070\n",
      "Epoch 620/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9603 - acc: 0.6842 - val_loss: 0.5501 - val_acc: 0.8129\n",
      "Epoch 621/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9168 - acc: 0.7003 - val_loss: 0.5387 - val_acc: 0.8129\n",
      "Epoch 622/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.8181 - acc: 0.7047 - val_loss: 0.5352 - val_acc: 0.8099\n",
      "Epoch 623/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8821 - acc: 0.6974 - val_loss: 0.5227 - val_acc: 0.8129\n",
      "Epoch 624/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9102 - acc: 0.6871 - val_loss: 0.5553 - val_acc: 0.8129\n",
      "Epoch 625/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8761 - acc: 0.6842 - val_loss: 0.5341 - val_acc: 0.8129\n",
      "Epoch 626/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.8911 - acc: 0.6842 - val_loss: 0.5348 - val_acc: 0.8158\n",
      "Epoch 627/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9102 - acc: 0.6944 - val_loss: 0.5356 - val_acc: 0.8158\n",
      "Epoch 628/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8987 - acc: 0.6857 - val_loss: 0.5399 - val_acc: 0.8129\n",
      "Epoch 629/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8594 - acc: 0.6944 - val_loss: 0.5245 - val_acc: 0.8129\n",
      "Epoch 630/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8892 - acc: 0.6944 - val_loss: 0.5253 - val_acc: 0.8158\n",
      "Epoch 631/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9006 - acc: 0.6711 - val_loss: 0.5488 - val_acc: 0.8187\n",
      "Epoch 632/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8242 - acc: 0.7047 - val_loss: 0.5348 - val_acc: 0.8158\n",
      "Epoch 633/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9078 - acc: 0.6784 - val_loss: 0.5376 - val_acc: 0.8041\n",
      "Epoch 634/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9377 - acc: 0.6798 - val_loss: 0.5243 - val_acc: 0.8158\n",
      "Epoch 635/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8091 - acc: 0.7222 - val_loss: 0.5180 - val_acc: 0.8187\n",
      "Epoch 636/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9410 - acc: 0.6623 - val_loss: 0.5275 - val_acc: 0.8012\n",
      "Epoch 637/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8745 - acc: 0.6813 - val_loss: 0.5314 - val_acc: 0.8099\n",
      "Epoch 638/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8376 - acc: 0.6988 - val_loss: 0.5335 - val_acc: 0.8099\n",
      "Epoch 639/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.8415 - acc: 0.6915 - val_loss: 0.5253 - val_acc: 0.8246\n",
      "Epoch 640/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.9384 - acc: 0.6915 - val_loss: 0.5292 - val_acc: 0.8070\n",
      "Epoch 641/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9170 - acc: 0.6959 - val_loss: 0.5305 - val_acc: 0.8099\n",
      "Epoch 642/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8833 - acc: 0.6769 - val_loss: 0.5187 - val_acc: 0.8187\n",
      "Epoch 643/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9377 - acc: 0.6784 - val_loss: 0.5361 - val_acc: 0.8275\n",
      "Epoch 644/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9303 - acc: 0.6842 - val_loss: 0.5281 - val_acc: 0.8216\n",
      "Epoch 645/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8335 - acc: 0.7032 - val_loss: 0.5213 - val_acc: 0.8216\n",
      "Epoch 646/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8348 - acc: 0.7047 - val_loss: 0.5252 - val_acc: 0.8158\n",
      "Epoch 647/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8744 - acc: 0.7032 - val_loss: 0.5200 - val_acc: 0.8158\n",
      "Epoch 648/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8666 - acc: 0.6798 - val_loss: 0.5227 - val_acc: 0.8216\n",
      "Epoch 649/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.8508 - acc: 0.6915 - val_loss: 0.5221 - val_acc: 0.8158\n",
      "Epoch 650/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8668 - acc: 0.6842 - val_loss: 0.5216 - val_acc: 0.8129\n",
      "Epoch 651/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8820 - acc: 0.7047 - val_loss: 0.5347 - val_acc: 0.8070\n",
      "Epoch 652/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8573 - acc: 0.6915 - val_loss: 0.5249 - val_acc: 0.8333\n",
      "Epoch 653/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.9622 - acc: 0.6915 - val_loss: 0.5147 - val_acc: 0.8246\n",
      "Epoch 654/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8783 - acc: 0.6886 - val_loss: 0.5183 - val_acc: 0.8158\n",
      "Epoch 655/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8497 - acc: 0.7178 - val_loss: 0.5212 - val_acc: 0.8187\n",
      "Epoch 656/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8415 - acc: 0.6974 - val_loss: 0.5170 - val_acc: 0.8246\n",
      "Epoch 657/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8824 - acc: 0.6754 - val_loss: 0.5190 - val_acc: 0.8363\n",
      "Epoch 658/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8341 - acc: 0.7091 - val_loss: 0.5065 - val_acc: 0.8275\n",
      "Epoch 659/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8312 - acc: 0.7120 - val_loss: 0.5179 - val_acc: 0.8333\n",
      "Epoch 660/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.8521 - acc: 0.7032 - val_loss: 0.5112 - val_acc: 0.8246\n",
      "Epoch 661/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8193 - acc: 0.7076 - val_loss: 0.5113 - val_acc: 0.8216\n",
      "Epoch 662/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8365 - acc: 0.6988 - val_loss: 0.5115 - val_acc: 0.8246\n",
      "Epoch 663/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8708 - acc: 0.6930 - val_loss: 0.5130 - val_acc: 0.8246\n",
      "Epoch 664/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8557 - acc: 0.6769 - val_loss: 0.5178 - val_acc: 0.8246\n",
      "Epoch 665/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7936 - acc: 0.7266 - val_loss: 0.5150 - val_acc: 0.8275\n",
      "Epoch 666/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8500 - acc: 0.7018 - val_loss: 0.5109 - val_acc: 0.8216\n",
      "Epoch 667/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8292 - acc: 0.7135 - val_loss: 0.5074 - val_acc: 0.8275\n",
      "Epoch 668/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9179 - acc: 0.6930 - val_loss: 0.5079 - val_acc: 0.8304\n",
      "Epoch 669/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8524 - acc: 0.6930 - val_loss: 0.5259 - val_acc: 0.8129\n",
      "Epoch 670/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9035 - acc: 0.6930 - val_loss: 0.5229 - val_acc: 0.8187\n",
      "Epoch 671/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8850 - acc: 0.6930 - val_loss: 0.5194 - val_acc: 0.8187\n",
      "Epoch 672/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9014 - acc: 0.6667 - val_loss: 0.5060 - val_acc: 0.8246\n",
      "Epoch 673/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8643 - acc: 0.7047 - val_loss: 0.5204 - val_acc: 0.8246\n",
      "Epoch 674/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8488 - acc: 0.7135 - val_loss: 0.5124 - val_acc: 0.8216\n",
      "Epoch 675/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8932 - acc: 0.6813 - val_loss: 0.5078 - val_acc: 0.8275\n",
      "Epoch 676/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8965 - acc: 0.6813 - val_loss: 0.5201 - val_acc: 0.8187\n",
      "Epoch 677/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9146 - acc: 0.7120 - val_loss: 0.5268 - val_acc: 0.8187\n",
      "Epoch 678/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8290 - acc: 0.6930 - val_loss: 0.5131 - val_acc: 0.8304\n",
      "Epoch 679/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8288 - acc: 0.6930 - val_loss: 0.5169 - val_acc: 0.8363\n",
      "Epoch 680/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9146 - acc: 0.6784 - val_loss: 0.5186 - val_acc: 0.8304\n",
      "Epoch 681/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9044 - acc: 0.6754 - val_loss: 0.5132 - val_acc: 0.8246\n",
      "Epoch 682/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8309 - acc: 0.6944 - val_loss: 0.4983 - val_acc: 0.8216\n",
      "Epoch 683/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8691 - acc: 0.7003 - val_loss: 0.5138 - val_acc: 0.8216\n",
      "Epoch 684/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8676 - acc: 0.6871 - val_loss: 0.5152 - val_acc: 0.8187\n",
      "Epoch 685/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8254 - acc: 0.7018 - val_loss: 0.5149 - val_acc: 0.8158\n",
      "Epoch 686/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8603 - acc: 0.7105 - val_loss: 0.5110 - val_acc: 0.8275\n",
      "Epoch 687/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8705 - acc: 0.7164 - val_loss: 0.5033 - val_acc: 0.8304\n",
      "Epoch 688/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8504 - acc: 0.7164 - val_loss: 0.5041 - val_acc: 0.8363\n",
      "Epoch 689/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9232 - acc: 0.6974 - val_loss: 0.5007 - val_acc: 0.8304\n",
      "Epoch 690/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9030 - acc: 0.7047 - val_loss: 0.5065 - val_acc: 0.8246\n",
      "Epoch 691/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8629 - acc: 0.6857 - val_loss: 0.5129 - val_acc: 0.8187\n",
      "Epoch 692/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8033 - acc: 0.7091 - val_loss: 0.5042 - val_acc: 0.8275\n",
      "Epoch 693/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8630 - acc: 0.6827 - val_loss: 0.5076 - val_acc: 0.8392\n",
      "Epoch 694/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8728 - acc: 0.7076 - val_loss: 0.5126 - val_acc: 0.8275\n",
      "Epoch 695/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8658 - acc: 0.7091 - val_loss: 0.5132 - val_acc: 0.8333\n",
      "Epoch 696/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.8663 - acc: 0.7105 - val_loss: 0.5240 - val_acc: 0.8246\n",
      "Epoch 697/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9339 - acc: 0.7047 - val_loss: 0.5098 - val_acc: 0.8333\n",
      "Epoch 698/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8606 - acc: 0.6959 - val_loss: 0.5129 - val_acc: 0.8304\n",
      "Epoch 699/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8562 - acc: 0.6988 - val_loss: 0.5076 - val_acc: 0.8363\n",
      "Epoch 700/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8319 - acc: 0.7149 - val_loss: 0.5021 - val_acc: 0.8304\n",
      "Epoch 701/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8471 - acc: 0.7091 - val_loss: 0.5044 - val_acc: 0.8363\n",
      "Epoch 702/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8693 - acc: 0.6959 - val_loss: 0.5129 - val_acc: 0.8158\n",
      "Epoch 703/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8806 - acc: 0.6886 - val_loss: 0.5190 - val_acc: 0.8333\n",
      "Epoch 704/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9018 - acc: 0.6930 - val_loss: 0.5126 - val_acc: 0.8246\n",
      "Epoch 705/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8306 - acc: 0.7047 - val_loss: 0.5012 - val_acc: 0.8275\n",
      "Epoch 706/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8696 - acc: 0.6959 - val_loss: 0.4947 - val_acc: 0.8333\n",
      "Epoch 707/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8584 - acc: 0.6857 - val_loss: 0.4986 - val_acc: 0.8275\n",
      "Epoch 708/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8939 - acc: 0.6944 - val_loss: 0.5006 - val_acc: 0.8304\n",
      "Epoch 709/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8786 - acc: 0.6813 - val_loss: 0.5046 - val_acc: 0.8304\n",
      "Epoch 710/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8543 - acc: 0.7266 - val_loss: 0.5105 - val_acc: 0.8275\n",
      "Epoch 711/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8309 - acc: 0.6871 - val_loss: 0.5094 - val_acc: 0.8304\n",
      "Epoch 712/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7952 - acc: 0.7076 - val_loss: 0.5009 - val_acc: 0.8333\n",
      "Epoch 713/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7527 - acc: 0.7427 - val_loss: 0.4982 - val_acc: 0.8275\n",
      "Epoch 714/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8935 - acc: 0.6886 - val_loss: 0.5081 - val_acc: 0.8246\n",
      "Epoch 715/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8850 - acc: 0.6798 - val_loss: 0.4999 - val_acc: 0.8216\n",
      "Epoch 716/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8116 - acc: 0.7091 - val_loss: 0.4917 - val_acc: 0.8333\n",
      "Epoch 717/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8909 - acc: 0.6974 - val_loss: 0.5020 - val_acc: 0.8216\n",
      "Epoch 718/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8352 - acc: 0.7149 - val_loss: 0.5003 - val_acc: 0.8333\n",
      "Epoch 719/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8833 - acc: 0.7018 - val_loss: 0.5079 - val_acc: 0.8216\n",
      "Epoch 720/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8102 - acc: 0.7222 - val_loss: 0.5023 - val_acc: 0.8187\n",
      "Epoch 721/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8750 - acc: 0.7178 - val_loss: 0.5079 - val_acc: 0.8246\n",
      "Epoch 722/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8618 - acc: 0.7047 - val_loss: 0.5041 - val_acc: 0.8246\n",
      "Epoch 723/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8278 - acc: 0.7061 - val_loss: 0.4993 - val_acc: 0.8275\n",
      "Epoch 724/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8076 - acc: 0.7032 - val_loss: 0.4979 - val_acc: 0.8246\n",
      "Epoch 725/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8671 - acc: 0.6915 - val_loss: 0.5035 - val_acc: 0.8275\n",
      "Epoch 726/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8456 - acc: 0.7076 - val_loss: 0.5147 - val_acc: 0.8158\n",
      "Epoch 727/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8970 - acc: 0.6886 - val_loss: 0.5142 - val_acc: 0.8275\n",
      "Epoch 728/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8652 - acc: 0.6886 - val_loss: 0.4976 - val_acc: 0.8275\n",
      "Epoch 729/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8858 - acc: 0.7222 - val_loss: 0.5076 - val_acc: 0.8216\n",
      "Epoch 730/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8747 - acc: 0.6915 - val_loss: 0.5153 - val_acc: 0.8216\n",
      "Epoch 731/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8819 - acc: 0.6901 - val_loss: 0.5154 - val_acc: 0.8216\n",
      "Epoch 732/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8011 - acc: 0.7120 - val_loss: 0.5096 - val_acc: 0.8333\n",
      "Epoch 733/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8107 - acc: 0.7076 - val_loss: 0.5001 - val_acc: 0.8246\n",
      "Epoch 734/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8062 - acc: 0.7178 - val_loss: 0.5085 - val_acc: 0.8304\n",
      "Epoch 735/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8008 - acc: 0.7076 - val_loss: 0.5017 - val_acc: 0.8275\n",
      "Epoch 736/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8734 - acc: 0.7047 - val_loss: 0.5000 - val_acc: 0.8275\n",
      "Epoch 737/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8059 - acc: 0.6901 - val_loss: 0.4933 - val_acc: 0.8275\n",
      "Epoch 738/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8342 - acc: 0.6944 - val_loss: 0.4898 - val_acc: 0.8275\n",
      "Epoch 739/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8805 - acc: 0.7149 - val_loss: 0.4916 - val_acc: 0.8392\n",
      "Epoch 740/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8601 - acc: 0.7061 - val_loss: 0.4933 - val_acc: 0.8392\n",
      "Epoch 741/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8825 - acc: 0.7208 - val_loss: 0.4962 - val_acc: 0.8392\n",
      "Epoch 742/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8373 - acc: 0.6974 - val_loss: 0.5035 - val_acc: 0.8275\n",
      "Epoch 743/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8569 - acc: 0.7091 - val_loss: 0.5082 - val_acc: 0.8304\n",
      "Epoch 744/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8660 - acc: 0.6988 - val_loss: 0.5058 - val_acc: 0.8333\n",
      "Epoch 745/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9283 - acc: 0.6988 - val_loss: 0.5132 - val_acc: 0.8275\n",
      "Epoch 746/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9083 - acc: 0.6886 - val_loss: 0.4990 - val_acc: 0.8333\n",
      "Epoch 747/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7934 - acc: 0.7325 - val_loss: 0.4954 - val_acc: 0.8509\n",
      "Epoch 748/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8466 - acc: 0.7149 - val_loss: 0.4914 - val_acc: 0.8450\n",
      "Epoch 749/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8472 - acc: 0.7120 - val_loss: 0.4993 - val_acc: 0.8363\n",
      "Epoch 750/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8756 - acc: 0.7135 - val_loss: 0.5008 - val_acc: 0.8363\n",
      "Epoch 751/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7778 - acc: 0.7222 - val_loss: 0.4928 - val_acc: 0.8421\n",
      "Epoch 752/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8551 - acc: 0.6974 - val_loss: 0.4869 - val_acc: 0.8450\n",
      "Epoch 753/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8883 - acc: 0.7164 - val_loss: 0.4925 - val_acc: 0.8304\n",
      "Epoch 754/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8773 - acc: 0.7003 - val_loss: 0.4863 - val_acc: 0.8421\n",
      "Epoch 755/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8286 - acc: 0.6988 - val_loss: 0.4902 - val_acc: 0.8363\n",
      "Epoch 756/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7986 - acc: 0.7149 - val_loss: 0.4995 - val_acc: 0.8333\n",
      "Epoch 757/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7852 - acc: 0.7178 - val_loss: 0.4816 - val_acc: 0.8333\n",
      "Epoch 758/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8066 - acc: 0.7222 - val_loss: 0.4867 - val_acc: 0.8421\n",
      "Epoch 759/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8437 - acc: 0.7018 - val_loss: 0.4851 - val_acc: 0.8304\n",
      "Epoch 760/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8081 - acc: 0.7383 - val_loss: 0.4808 - val_acc: 0.8333\n",
      "Epoch 761/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8391 - acc: 0.7208 - val_loss: 0.4837 - val_acc: 0.8333\n",
      "Epoch 762/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8071 - acc: 0.7091 - val_loss: 0.4821 - val_acc: 0.8392\n",
      "Epoch 763/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8286 - acc: 0.7178 - val_loss: 0.4777 - val_acc: 0.8421\n",
      "Epoch 764/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8015 - acc: 0.7310 - val_loss: 0.4811 - val_acc: 0.8392\n",
      "Epoch 765/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8842 - acc: 0.7222 - val_loss: 0.4847 - val_acc: 0.8392\n",
      "Epoch 766/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8510 - acc: 0.7193 - val_loss: 0.4846 - val_acc: 0.8450\n",
      "Epoch 767/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8700 - acc: 0.7135 - val_loss: 0.5027 - val_acc: 0.8392\n",
      "Epoch 768/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8799 - acc: 0.6930 - val_loss: 0.4855 - val_acc: 0.8450\n",
      "Epoch 769/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7993 - acc: 0.7354 - val_loss: 0.4845 - val_acc: 0.8392\n",
      "Epoch 770/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8536 - acc: 0.6944 - val_loss: 0.4887 - val_acc: 0.8392\n",
      "Epoch 771/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8653 - acc: 0.7061 - val_loss: 0.4811 - val_acc: 0.8450\n",
      "Epoch 772/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7977 - acc: 0.7237 - val_loss: 0.4808 - val_acc: 0.8363\n",
      "Epoch 773/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7783 - acc: 0.7164 - val_loss: 0.4932 - val_acc: 0.8363\n",
      "Epoch 774/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8306 - acc: 0.7018 - val_loss: 0.4986 - val_acc: 0.8392\n",
      "Epoch 775/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8380 - acc: 0.7135 - val_loss: 0.4819 - val_acc: 0.8246\n",
      "Epoch 776/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8242 - acc: 0.7237 - val_loss: 0.4865 - val_acc: 0.8275\n",
      "Epoch 777/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8344 - acc: 0.7105 - val_loss: 0.4800 - val_acc: 0.8363\n",
      "Epoch 778/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7984 - acc: 0.7208 - val_loss: 0.4853 - val_acc: 0.8333\n",
      "Epoch 779/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8538 - acc: 0.7018 - val_loss: 0.4821 - val_acc: 0.8304\n",
      "Epoch 780/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8159 - acc: 0.7237 - val_loss: 0.4858 - val_acc: 0.8275\n",
      "Epoch 781/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8175 - acc: 0.7237 - val_loss: 0.4835 - val_acc: 0.8333\n",
      "Epoch 782/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7988 - acc: 0.7281 - val_loss: 0.4842 - val_acc: 0.8275\n",
      "Epoch 783/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8116 - acc: 0.7251 - val_loss: 0.4752 - val_acc: 0.8333\n",
      "Epoch 784/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7754 - acc: 0.7281 - val_loss: 0.4843 - val_acc: 0.8275\n",
      "Epoch 785/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8177 - acc: 0.7178 - val_loss: 0.4871 - val_acc: 0.8304\n",
      "Epoch 786/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8170 - acc: 0.7222 - val_loss: 0.4848 - val_acc: 0.8333\n",
      "Epoch 787/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8432 - acc: 0.7047 - val_loss: 0.4767 - val_acc: 0.8363\n",
      "Epoch 788/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8437 - acc: 0.7061 - val_loss: 0.4843 - val_acc: 0.8246\n",
      "Epoch 789/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7982 - acc: 0.7149 - val_loss: 0.4718 - val_acc: 0.8363\n",
      "Epoch 790/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8480 - acc: 0.6959 - val_loss: 0.4614 - val_acc: 0.8333\n",
      "Epoch 791/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7488 - acc: 0.7281 - val_loss: 0.4710 - val_acc: 0.8450\n",
      "Epoch 792/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8858 - acc: 0.7076 - val_loss: 0.4732 - val_acc: 0.8275\n",
      "Epoch 793/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8415 - acc: 0.7105 - val_loss: 0.4802 - val_acc: 0.8363\n",
      "Epoch 794/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7830 - acc: 0.6930 - val_loss: 0.4855 - val_acc: 0.8421\n",
      "Epoch 795/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8258 - acc: 0.7251 - val_loss: 0.4846 - val_acc: 0.8392\n",
      "Epoch 796/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8438 - acc: 0.6974 - val_loss: 0.4791 - val_acc: 0.8421\n",
      "Epoch 797/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8564 - acc: 0.7076 - val_loss: 0.4769 - val_acc: 0.8450\n",
      "Epoch 798/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8444 - acc: 0.6974 - val_loss: 0.4784 - val_acc: 0.8392\n",
      "Epoch 799/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8230 - acc: 0.7135 - val_loss: 0.4753 - val_acc: 0.8509\n",
      "Epoch 800/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8471 - acc: 0.7149 - val_loss: 0.4817 - val_acc: 0.8421\n",
      "Epoch 801/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8886 - acc: 0.6813 - val_loss: 0.4834 - val_acc: 0.8480\n",
      "Epoch 802/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8553 - acc: 0.7047 - val_loss: 0.4834 - val_acc: 0.8392\n",
      "Epoch 803/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8064 - acc: 0.7310 - val_loss: 0.4862 - val_acc: 0.8480\n",
      "Epoch 804/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8603 - acc: 0.7091 - val_loss: 0.4822 - val_acc: 0.8421\n",
      "Epoch 805/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7885 - acc: 0.7295 - val_loss: 0.4782 - val_acc: 0.8480\n",
      "Epoch 806/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8294 - acc: 0.7091 - val_loss: 0.4783 - val_acc: 0.8392\n",
      "Epoch 807/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7845 - acc: 0.7208 - val_loss: 0.4783 - val_acc: 0.8392\n",
      "Epoch 808/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7245 - acc: 0.7325 - val_loss: 0.4779 - val_acc: 0.8509\n",
      "Epoch 809/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8055 - acc: 0.7032 - val_loss: 0.4750 - val_acc: 0.8509\n",
      "Epoch 810/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7725 - acc: 0.7178 - val_loss: 0.4769 - val_acc: 0.8450\n",
      "Epoch 811/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7905 - acc: 0.7251 - val_loss: 0.4808 - val_acc: 0.8421\n",
      "Epoch 812/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7540 - acc: 0.7266 - val_loss: 0.4771 - val_acc: 0.8421\n",
      "Epoch 813/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8423 - acc: 0.7018 - val_loss: 0.4799 - val_acc: 0.8450\n",
      "Epoch 814/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8502 - acc: 0.6974 - val_loss: 0.4757 - val_acc: 0.8450\n",
      "Epoch 815/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8044 - acc: 0.7339 - val_loss: 0.4742 - val_acc: 0.8421\n",
      "Epoch 816/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8302 - acc: 0.7120 - val_loss: 0.4808 - val_acc: 0.8450\n",
      "Epoch 817/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7850 - acc: 0.7105 - val_loss: 0.4751 - val_acc: 0.8450\n",
      "Epoch 818/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8059 - acc: 0.7339 - val_loss: 0.4724 - val_acc: 0.8421\n",
      "Epoch 819/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8438 - acc: 0.7061 - val_loss: 0.4901 - val_acc: 0.8304\n",
      "Epoch 820/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8167 - acc: 0.7032 - val_loss: 0.4916 - val_acc: 0.8275\n",
      "Epoch 821/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7737 - acc: 0.7208 - val_loss: 0.4820 - val_acc: 0.8333\n",
      "Epoch 822/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7668 - acc: 0.7193 - val_loss: 0.4783 - val_acc: 0.8363\n",
      "Epoch 823/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8350 - acc: 0.7047 - val_loss: 0.4823 - val_acc: 0.8363\n",
      "Epoch 824/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7686 - acc: 0.7325 - val_loss: 0.4805 - val_acc: 0.8363\n",
      "Epoch 825/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8909 - acc: 0.7018 - val_loss: 0.4776 - val_acc: 0.8363\n",
      "Epoch 826/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8477 - acc: 0.7091 - val_loss: 0.4750 - val_acc: 0.8392\n",
      "Epoch 827/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7520 - acc: 0.7412 - val_loss: 0.4848 - val_acc: 0.8421\n",
      "Epoch 828/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8337 - acc: 0.7368 - val_loss: 0.4821 - val_acc: 0.8333\n",
      "Epoch 829/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8437 - acc: 0.7032 - val_loss: 0.4806 - val_acc: 0.8363\n",
      "Epoch 830/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.7602 - acc: 0.7339 - val_loss: 0.4828 - val_acc: 0.8392\n",
      "Epoch 831/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8593 - acc: 0.7135 - val_loss: 0.4873 - val_acc: 0.8450\n",
      "Epoch 832/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7845 - acc: 0.7222 - val_loss: 0.4851 - val_acc: 0.8363\n",
      "Epoch 833/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7769 - acc: 0.7193 - val_loss: 0.4756 - val_acc: 0.8392\n",
      "Epoch 834/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7822 - acc: 0.7061 - val_loss: 0.4676 - val_acc: 0.8392\n",
      "Epoch 835/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7387 - acc: 0.7325 - val_loss: 0.4678 - val_acc: 0.8450\n",
      "Epoch 836/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.8109 - acc: 0.7091 - val_loss: 0.4689 - val_acc: 0.8480\n",
      "Epoch 837/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8145 - acc: 0.7237 - val_loss: 0.4799 - val_acc: 0.8392\n",
      "Epoch 838/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7728 - acc: 0.7164 - val_loss: 0.4715 - val_acc: 0.8538\n",
      "Epoch 839/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8013 - acc: 0.7032 - val_loss: 0.4766 - val_acc: 0.8509\n",
      "Epoch 840/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7282 - acc: 0.7471 - val_loss: 0.4799 - val_acc: 0.8450\n",
      "Epoch 841/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7800 - acc: 0.7193 - val_loss: 0.4758 - val_acc: 0.8304\n",
      "Epoch 842/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7983 - acc: 0.7354 - val_loss: 0.4743 - val_acc: 0.8304\n",
      "Epoch 843/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.7997 - acc: 0.7295 - val_loss: 0.4669 - val_acc: 0.8363\n",
      "Epoch 844/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8043 - acc: 0.7281 - val_loss: 0.4576 - val_acc: 0.8421\n",
      "Epoch 845/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8057 - acc: 0.7135 - val_loss: 0.4573 - val_acc: 0.8392\n",
      "Epoch 846/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7737 - acc: 0.7251 - val_loss: 0.4606 - val_acc: 0.8363\n",
      "Epoch 847/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8498 - acc: 0.7105 - val_loss: 0.4644 - val_acc: 0.8363\n",
      "Epoch 848/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8335 - acc: 0.7164 - val_loss: 0.4626 - val_acc: 0.8333\n",
      "Epoch 849/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7388 - acc: 0.7325 - val_loss: 0.4566 - val_acc: 0.8392\n",
      "Epoch 850/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7675 - acc: 0.7529 - val_loss: 0.4623 - val_acc: 0.8392\n",
      "Epoch 851/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8600 - acc: 0.7310 - val_loss: 0.4559 - val_acc: 0.8421\n",
      "Epoch 852/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8183 - acc: 0.7281 - val_loss: 0.4675 - val_acc: 0.8392\n",
      "Epoch 853/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8233 - acc: 0.7237 - val_loss: 0.4662 - val_acc: 0.8421\n",
      "Epoch 854/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7842 - acc: 0.7076 - val_loss: 0.4615 - val_acc: 0.8450\n",
      "Epoch 855/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7806 - acc: 0.7427 - val_loss: 0.4644 - val_acc: 0.8421\n",
      "Epoch 856/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8691 - acc: 0.7237 - val_loss: 0.4612 - val_acc: 0.8509\n",
      "Epoch 857/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7750 - acc: 0.7310 - val_loss: 0.4733 - val_acc: 0.8392\n",
      "Epoch 858/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8081 - acc: 0.7149 - val_loss: 0.4657 - val_acc: 0.8450\n",
      "Epoch 859/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8224 - acc: 0.7193 - val_loss: 0.4583 - val_acc: 0.8480\n",
      "Epoch 860/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7715 - acc: 0.7427 - val_loss: 0.4576 - val_acc: 0.8421\n",
      "Epoch 861/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7936 - acc: 0.7149 - val_loss: 0.4673 - val_acc: 0.8392\n",
      "Epoch 862/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7857 - acc: 0.7281 - val_loss: 0.4661 - val_acc: 0.8392\n",
      "Epoch 863/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8406 - acc: 0.7237 - val_loss: 0.4610 - val_acc: 0.8333\n",
      "Epoch 864/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7788 - acc: 0.7295 - val_loss: 0.4581 - val_acc: 0.8363\n",
      "Epoch 865/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7744 - acc: 0.7325 - val_loss: 0.4631 - val_acc: 0.8333\n",
      "Epoch 866/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8002 - acc: 0.7325 - val_loss: 0.4698 - val_acc: 0.8363\n",
      "Epoch 867/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7686 - acc: 0.7164 - val_loss: 0.4618 - val_acc: 0.8450\n",
      "Epoch 868/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8295 - acc: 0.6988 - val_loss: 0.4652 - val_acc: 0.8450\n",
      "Epoch 869/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7651 - acc: 0.7368 - val_loss: 0.4611 - val_acc: 0.8363\n",
      "Epoch 870/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7683 - acc: 0.7442 - val_loss: 0.4603 - val_acc: 0.8363\n",
      "Epoch 871/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7667 - acc: 0.7325 - val_loss: 0.4637 - val_acc: 0.8480\n",
      "Epoch 872/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7697 - acc: 0.7368 - val_loss: 0.4621 - val_acc: 0.8480\n",
      "Epoch 873/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7696 - acc: 0.7442 - val_loss: 0.4583 - val_acc: 0.8421\n",
      "Epoch 874/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7589 - acc: 0.7368 - val_loss: 0.4582 - val_acc: 0.8450\n",
      "Epoch 875/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8070 - acc: 0.6959 - val_loss: 0.4518 - val_acc: 0.8421\n",
      "Epoch 876/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7632 - acc: 0.7281 - val_loss: 0.4590 - val_acc: 0.8363\n",
      "Epoch 877/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7783 - acc: 0.7295 - val_loss: 0.4543 - val_acc: 0.8421\n",
      "Epoch 878/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7982 - acc: 0.7222 - val_loss: 0.4567 - val_acc: 0.8421\n",
      "Epoch 879/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7143 - acc: 0.7500 - val_loss: 0.4575 - val_acc: 0.8392\n",
      "Epoch 880/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8172 - acc: 0.7237 - val_loss: 0.4582 - val_acc: 0.8421\n",
      "Epoch 881/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7672 - acc: 0.7178 - val_loss: 0.4619 - val_acc: 0.8421\n",
      "Epoch 882/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7896 - acc: 0.7412 - val_loss: 0.4573 - val_acc: 0.8480\n",
      "Epoch 883/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8199 - acc: 0.7047 - val_loss: 0.4551 - val_acc: 0.8421\n",
      "Epoch 884/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7771 - acc: 0.7251 - val_loss: 0.4582 - val_acc: 0.8275\n",
      "Epoch 885/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8095 - acc: 0.7193 - val_loss: 0.4671 - val_acc: 0.8275\n",
      "Epoch 886/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7935 - acc: 0.7251 - val_loss: 0.4741 - val_acc: 0.8333\n",
      "Epoch 887/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7656 - acc: 0.7222 - val_loss: 0.4558 - val_acc: 0.8392\n",
      "Epoch 888/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7834 - acc: 0.7310 - val_loss: 0.4710 - val_acc: 0.8246\n",
      "Epoch 889/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8178 - acc: 0.7442 - val_loss: 0.4644 - val_acc: 0.8304\n",
      "Epoch 890/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7474 - acc: 0.7412 - val_loss: 0.4572 - val_acc: 0.8421\n",
      "Epoch 891/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7852 - acc: 0.7237 - val_loss: 0.4513 - val_acc: 0.8392\n",
      "Epoch 892/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7788 - acc: 0.7251 - val_loss: 0.4614 - val_acc: 0.8421\n",
      "Epoch 893/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8134 - acc: 0.7091 - val_loss: 0.4646 - val_acc: 0.8363\n",
      "Epoch 894/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8526 - acc: 0.7193 - val_loss: 0.4711 - val_acc: 0.8363\n",
      "Epoch 895/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8014 - acc: 0.7120 - val_loss: 0.4817 - val_acc: 0.8363\n",
      "Epoch 896/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7772 - acc: 0.7281 - val_loss: 0.4619 - val_acc: 0.8421\n",
      "Epoch 897/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8258 - acc: 0.7164 - val_loss: 0.4624 - val_acc: 0.8450\n",
      "Epoch 898/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8357 - acc: 0.7164 - val_loss: 0.4755 - val_acc: 0.8333\n",
      "Epoch 899/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7705 - acc: 0.7310 - val_loss: 0.4826 - val_acc: 0.8333\n",
      "Epoch 900/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7325 - acc: 0.7368 - val_loss: 0.4591 - val_acc: 0.8363\n",
      "Epoch 901/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8269 - acc: 0.7032 - val_loss: 0.4622 - val_acc: 0.8421\n",
      "Epoch 902/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7207 - acc: 0.7442 - val_loss: 0.4579 - val_acc: 0.8450\n",
      "Epoch 903/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.7519 - acc: 0.7281 - val_loss: 0.4580 - val_acc: 0.8392\n",
      "Epoch 904/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8637 - acc: 0.7032 - val_loss: 0.4542 - val_acc: 0.8480\n",
      "Epoch 905/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7526 - acc: 0.7412 - val_loss: 0.4545 - val_acc: 0.8480\n",
      "Epoch 906/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7869 - acc: 0.7281 - val_loss: 0.4548 - val_acc: 0.8480\n",
      "Epoch 907/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8471 - acc: 0.7251 - val_loss: 0.4589 - val_acc: 0.8363\n",
      "Epoch 908/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8273 - acc: 0.7222 - val_loss: 0.4630 - val_acc: 0.8304\n",
      "Epoch 909/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6946 - acc: 0.7617 - val_loss: 0.4671 - val_acc: 0.8480\n",
      "Epoch 910/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8801 - acc: 0.7018 - val_loss: 0.4671 - val_acc: 0.8450\n",
      "Epoch 911/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7749 - acc: 0.7310 - val_loss: 0.4702 - val_acc: 0.8363\n",
      "Epoch 912/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6770 - acc: 0.7412 - val_loss: 0.4620 - val_acc: 0.8363\n",
      "Epoch 913/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8065 - acc: 0.7266 - val_loss: 0.4558 - val_acc: 0.8392\n",
      "Epoch 914/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7775 - acc: 0.7383 - val_loss: 0.4650 - val_acc: 0.8450\n",
      "Epoch 915/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7993 - acc: 0.7105 - val_loss: 0.4721 - val_acc: 0.8421\n",
      "Epoch 916/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7656 - acc: 0.7354 - val_loss: 0.4763 - val_acc: 0.8450\n",
      "Epoch 917/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7167 - acc: 0.7485 - val_loss: 0.4605 - val_acc: 0.8450\n",
      "Epoch 918/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7094 - acc: 0.7485 - val_loss: 0.4544 - val_acc: 0.8509\n",
      "Epoch 919/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7303 - acc: 0.7398 - val_loss: 0.4627 - val_acc: 0.8480\n",
      "Epoch 920/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7827 - acc: 0.7325 - val_loss: 0.4615 - val_acc: 0.8480\n",
      "Epoch 921/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.8901 - acc: 0.7208 - val_loss: 0.4611 - val_acc: 0.8450\n",
      "Epoch 922/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.7718 - acc: 0.7208 - val_loss: 0.4635 - val_acc: 0.8450\n",
      "Epoch 923/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7916 - acc: 0.7295 - val_loss: 0.4655 - val_acc: 0.8480\n",
      "Epoch 924/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7746 - acc: 0.7354 - val_loss: 0.4543 - val_acc: 0.8509\n",
      "Epoch 925/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7722 - acc: 0.7281 - val_loss: 0.4510 - val_acc: 0.8567\n",
      "Epoch 926/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8105 - acc: 0.7222 - val_loss: 0.4668 - val_acc: 0.8421\n",
      "Epoch 927/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7988 - acc: 0.7383 - val_loss: 0.4687 - val_acc: 0.8450\n",
      "Epoch 928/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7829 - acc: 0.7412 - val_loss: 0.4690 - val_acc: 0.8450\n",
      "Epoch 929/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7933 - acc: 0.7354 - val_loss: 0.4651 - val_acc: 0.8450\n",
      "Epoch 930/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7172 - acc: 0.7602 - val_loss: 0.4642 - val_acc: 0.8450\n",
      "Epoch 931/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7809 - acc: 0.7251 - val_loss: 0.4627 - val_acc: 0.8392\n",
      "Epoch 932/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7587 - acc: 0.7222 - val_loss: 0.4490 - val_acc: 0.8450\n",
      "Epoch 933/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8112 - acc: 0.7237 - val_loss: 0.4526 - val_acc: 0.8480\n",
      "Epoch 934/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7642 - acc: 0.7398 - val_loss: 0.4601 - val_acc: 0.8450\n",
      "Epoch 935/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7844 - acc: 0.7529 - val_loss: 0.4693 - val_acc: 0.8480\n",
      "Epoch 936/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8161 - acc: 0.7120 - val_loss: 0.4490 - val_acc: 0.8480\n",
      "Epoch 937/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7719 - acc: 0.7354 - val_loss: 0.4544 - val_acc: 0.8450\n",
      "Epoch 938/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7390 - acc: 0.7398 - val_loss: 0.4519 - val_acc: 0.8421\n",
      "Epoch 939/1000\n",
      "684/684 [==============================] - 2s 4ms/step - loss: 0.7830 - acc: 0.7485 - val_loss: 0.4471 - val_acc: 0.8450\n",
      "Epoch 940/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7575 - acc: 0.7310 - val_loss: 0.4430 - val_acc: 0.8450\n",
      "Epoch 941/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7609 - acc: 0.7310 - val_loss: 0.4476 - val_acc: 0.8538\n",
      "Epoch 942/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7826 - acc: 0.7354 - val_loss: 0.4442 - val_acc: 0.8538\n",
      "Epoch 943/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7336 - acc: 0.7442 - val_loss: 0.4469 - val_acc: 0.8538\n",
      "Epoch 944/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7505 - acc: 0.7251 - val_loss: 0.4563 - val_acc: 0.8480\n",
      "Epoch 945/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6996 - acc: 0.7602 - val_loss: 0.4441 - val_acc: 0.8538\n",
      "Epoch 946/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7183 - acc: 0.7573 - val_loss: 0.4413 - val_acc: 0.8596\n",
      "Epoch 947/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7419 - acc: 0.7354 - val_loss: 0.4375 - val_acc: 0.8626\n",
      "Epoch 948/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7625 - acc: 0.7558 - val_loss: 0.4420 - val_acc: 0.8567\n",
      "Epoch 949/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8268 - acc: 0.7237 - val_loss: 0.4459 - val_acc: 0.8626\n",
      "Epoch 950/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7687 - acc: 0.7427 - val_loss: 0.4489 - val_acc: 0.8626\n",
      "Epoch 951/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7628 - acc: 0.7339 - val_loss: 0.4473 - val_acc: 0.8567\n",
      "Epoch 952/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6609 - acc: 0.7456 - val_loss: 0.4482 - val_acc: 0.8538\n",
      "Epoch 953/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7865 - acc: 0.7193 - val_loss: 0.4495 - val_acc: 0.8480\n",
      "Epoch 954/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7872 - acc: 0.7354 - val_loss: 0.4487 - val_acc: 0.8567\n",
      "Epoch 955/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7523 - acc: 0.7485 - val_loss: 0.4532 - val_acc: 0.8538\n",
      "Epoch 956/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.9296 - acc: 0.6857 - val_loss: 0.4556 - val_acc: 0.8480\n",
      "Epoch 957/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7945 - acc: 0.7193 - val_loss: 0.4474 - val_acc: 0.8538\n",
      "Epoch 958/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6946 - acc: 0.7456 - val_loss: 0.4478 - val_acc: 0.8480\n",
      "Epoch 959/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8164 - acc: 0.7164 - val_loss: 0.4507 - val_acc: 0.8480\n",
      "Epoch 960/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7511 - acc: 0.7398 - val_loss: 0.4368 - val_acc: 0.8567\n",
      "Epoch 961/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7159 - acc: 0.7368 - val_loss: 0.4457 - val_acc: 0.8480\n",
      "Epoch 962/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7363 - acc: 0.7412 - val_loss: 0.4436 - val_acc: 0.8567\n",
      "Epoch 963/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7320 - acc: 0.7398 - val_loss: 0.4438 - val_acc: 0.8450\n",
      "Epoch 964/1000\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.7881 - acc: 0.7120 - val_loss: 0.4505 - val_acc: 0.8538\n",
      "Epoch 965/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8080 - acc: 0.7061 - val_loss: 0.4405 - val_acc: 0.8567\n",
      "Epoch 966/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7774 - acc: 0.7398 - val_loss: 0.4458 - val_acc: 0.8596\n",
      "Epoch 967/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7201 - acc: 0.7485 - val_loss: 0.4366 - val_acc: 0.8626\n",
      "Epoch 968/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8723 - acc: 0.7105 - val_loss: 0.4406 - val_acc: 0.8596\n",
      "Epoch 969/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7560 - acc: 0.7573 - val_loss: 0.4393 - val_acc: 0.8480\n",
      "Epoch 970/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7780 - acc: 0.7383 - val_loss: 0.4345 - val_acc: 0.8480\n",
      "Epoch 971/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7524 - acc: 0.7383 - val_loss: 0.4358 - val_acc: 0.8567\n",
      "Epoch 972/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7222 - acc: 0.7383 - val_loss: 0.4330 - val_acc: 0.8509\n",
      "Epoch 973/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7585 - acc: 0.7485 - val_loss: 0.4328 - val_acc: 0.8538\n",
      "Epoch 974/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8108 - acc: 0.7281 - val_loss: 0.4325 - val_acc: 0.8480\n",
      "Epoch 975/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7091 - acc: 0.7500 - val_loss: 0.4417 - val_acc: 0.8480\n",
      "Epoch 976/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7033 - acc: 0.7544 - val_loss: 0.4392 - val_acc: 0.8480\n",
      "Epoch 977/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7373 - acc: 0.7500 - val_loss: 0.4377 - val_acc: 0.8509\n",
      "Epoch 978/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7352 - acc: 0.7398 - val_loss: 0.4402 - val_acc: 0.8509\n",
      "Epoch 979/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7727 - acc: 0.7339 - val_loss: 0.4350 - val_acc: 0.8538\n",
      "Epoch 980/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7496 - acc: 0.7412 - val_loss: 0.4337 - val_acc: 0.8538\n",
      "Epoch 981/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8241 - acc: 0.7091 - val_loss: 0.4305 - val_acc: 0.8567\n",
      "Epoch 982/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7204 - acc: 0.7427 - val_loss: 0.4386 - val_acc: 0.8538\n",
      "Epoch 983/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7486 - acc: 0.7295 - val_loss: 0.4361 - val_acc: 0.8538\n",
      "Epoch 984/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7601 - acc: 0.7485 - val_loss: 0.4372 - val_acc: 0.8567\n",
      "Epoch 985/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8454 - acc: 0.7281 - val_loss: 0.4392 - val_acc: 0.8538\n",
      "Epoch 986/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8001 - acc: 0.7295 - val_loss: 0.4497 - val_acc: 0.8538\n",
      "Epoch 987/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7091 - acc: 0.7471 - val_loss: 0.4458 - val_acc: 0.8538\n",
      "Epoch 988/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7496 - acc: 0.7193 - val_loss: 0.4356 - val_acc: 0.8567\n",
      "Epoch 989/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7196 - acc: 0.7412 - val_loss: 0.4331 - val_acc: 0.8567\n",
      "Epoch 990/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7493 - acc: 0.7339 - val_loss: 0.4365 - val_acc: 0.8567\n",
      "Epoch 991/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7366 - acc: 0.7251 - val_loss: 0.4245 - val_acc: 0.8538\n",
      "Epoch 992/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.8165 - acc: 0.7164 - val_loss: 0.4363 - val_acc: 0.8421\n",
      "Epoch 993/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7443 - acc: 0.7281 - val_loss: 0.4320 - val_acc: 0.8421\n",
      "Epoch 994/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7821 - acc: 0.7339 - val_loss: 0.4354 - val_acc: 0.8421\n",
      "Epoch 995/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7291 - acc: 0.7500 - val_loss: 0.4376 - val_acc: 0.8480\n",
      "Epoch 996/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6867 - acc: 0.7588 - val_loss: 0.4375 - val_acc: 0.8450\n",
      "Epoch 997/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.6808 - acc: 0.7690 - val_loss: 0.4337 - val_acc: 0.8450\n",
      "Epoch 998/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7201 - acc: 0.7529 - val_loss: 0.4264 - val_acc: 0.8509\n",
      "Epoch 999/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7840 - acc: 0.7178 - val_loss: 0.4300 - val_acc: 0.8480\n",
      "Epoch 1000/1000\n",
      "684/684 [==============================] - 2s 3ms/step - loss: 0.7084 - acc: 0.7485 - val_loss: 0.4317 - val_acc: 0.8480\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train_shuffle, Y_train_shuffle,validation_data=(x_test, Y_test), epochs=1000, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "342/342 [==============================] - 0s 246us/step\n",
      "Test score: 0.431700981848\n",
      "Test accuracy: 0.847953216026\n"
     ]
    }
   ],
   "source": [
    "score, acc = model.evaluate(x_test, Y_test)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# list all data in history\n",
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nM7Pc/wBteRltwg4BBQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x223746e5588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x223746e5b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
